Most (if not all) optical phenomena that materials exhibit can be replicated by simulating how the individual rays of light propagate and interact. This approach is referred in the scientific literature as **ray tracing**, and it is often too computationally expensive for any real-time application. Most modern engines rely on massive simplifications that, despite being unable to reproduce photorealism, can produce a believable approximation. This tutorial introduces a _fast, cheap and convincing_ solution that can be used to simulate translucent materials which exhibit subsurface scattering.  
ææ–™è¡¨ç°å‡ºçš„å¤§å¤šæ•°ï¼ˆå¦‚æœä¸æ˜¯å…¨éƒ¨çš„è¯ï¼‰å…‰å­¦ç°è±¡å¯ä»¥é€šè¿‡æ¨¡æ‹Ÿå•ä¸ªå…‰çº¿å¦‚ä½•ä¼ æ’­å’Œç›¸äº’ä½œç”¨æ¥å¤åˆ¶ã€‚è¿™ç§æ–¹æ³•åœ¨ç§‘å­¦æ–‡çŒ®ä¸­è¢«ç§°ä¸ºå°„çº¿è¿½è¸ªï¼Œå¯¹äºä»»ä½•å®æ—¶åº”ç”¨æ¥è¯´ï¼Œå®ƒçš„è®¡ç®—æˆæœ¬å¾€å¾€å¤ªé«˜ã€‚å¤§å¤šæ•°ç°ä»£å¼•æ“éƒ½ä¾èµ–äºå¤§è§„æ¨¡çš„ç®€åŒ–ï¼Œå°½ç®¡æ— æ³•å†ç°çœŸå®æ„Ÿï¼Œä½†å¯ä»¥äº§ç”Ÿå¯ä¿¡çš„è¿‘ä¼¼å€¼ã€‚æœ¬æ•™ç¨‹ä»‹ç»äº†ä¸€ç§å¿«é€Ÿã€å»‰ä»·ä¸”ä»¤äººä¿¡æœçš„è§£å†³æ–¹æ¡ˆï¼Œå¯ç”¨äºæ¨¡æ‹Ÿè¡¨ç°å‡ºæ¬¡è¡¨é¢æ•£å°„çš„åŠé€æ˜ææ–™ã€‚

This is a two part series:  
è¿™æ˜¯ä¸€ä¸ªç”±ä¸¤éƒ¨åˆ†ç»„æˆçš„ç³»åˆ—ï¼š

*   Part 1. [Fast Subsurface Scattering in Unity](https://www.alanzucconi.com/?p=7053)  
    ç¬¬1éƒ¨åˆ†ã€‚Unityä¸­çš„å¿«é€Ÿæ¬¡è¡¨é¢æ•£å°„
*   Part 2. [Fast Subsurface Scattering in Unity](https://www.alanzucconi.com/?p=7101)  
    ç¬¬2éƒ¨åˆ†ã€‚Unityä¸­çš„å¿«é€Ÿæ¬¡è¡¨é¢æ•£å°„

At the end of this post, you will find a link to **download** the **Unity project**.  
åœ¨è¿™ç¯‡æ–‡ç« çš„æœ€åï¼Œä½ ä¼šæ‰¾åˆ°ä¸€ä¸ªä¸‹è½½Unityé¡¹ç›®çš„é“¾æ¥ã€‚

#### Introduction

The Standard material in Unity comes with a Transparency mode, which allows rendering transparent materials. Transparency, in this context, is implemented with **alpha blending**. A transparent object is rendered on top of existing geometry, partially showing what is behind. While this works for many materials, transparency is a special case of a more general property, called **translucency** (sometimes also called **translucidity**). While transparent materials only affect the amount of light they let through (below, left), translucent ones can alter its path (below, right).  
Unityä¸­çš„â€œæ ‡å‡†â€æè´¨å¸¦æœ‰â€œé€æ˜åº¦â€æ¨¡å¼ï¼Œè¯¥æ¨¡å¼å…è®¸æ¸²æŸ“é€æ˜æè´¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€æ˜åº¦æ˜¯é€šè¿‡alphaæ··åˆæ¥å®ç°çš„ã€‚é€æ˜å¯¹è±¡åœ¨ç°æœ‰å‡ ä½•ä½“çš„é¡¶éƒ¨æ¸²æŸ“ï¼Œéƒ¨åˆ†æ˜¾ç¤ºåé¢çš„å†…å®¹ã€‚è™½ç„¶è¿™é€‚ç”¨äºè®¸å¤šæè´¨ï¼Œä½†é€æ˜åº¦æ˜¯ä¸€ç§æ›´ä¸ºæ™®éçš„ç‰¹æ€§çš„ç‰¹ä¾‹ï¼Œç§°ä¸ºåŠé€æ˜æ€§ï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸ºåŠé€æ˜æ€§ï¼‰ã€‚è™½ç„¶é€æ˜æè´¨åªå½±å“å®ƒä»¬é€šè¿‡çš„å…‰é‡ï¼ˆä¸‹å›¾ï¼Œå·¦ï¼‰ï¼Œä½†åŠé€æ˜æè´¨å¯ä»¥æ”¹å˜å…¶è·¯å¾„ï¼ˆä¸‹å›¾ï¼Œå³ï¼‰ã€‚

![](<images/1683794158290.png>)

The result of this behaviour should be clear: translucent materials diffuse the light rays they let through, blurring what was behind them. Such a behaviour is rarely seen in games,Â since it is significantly more complex to implement. Transparent materials can be implemented naively with alpha blending, without ray tracing. Translucent materials, on the other hand, require simulating the deviation of the light rays. Such a computation is very expensive and is rarely worth it in real time rendering.  
è¿™ç§è¡Œä¸ºçš„ç»“æœåº”è¯¥æ˜¯æ¸…æ¥šçš„ï¼šåŠé€æ˜ææ–™ä¼šæ•£å°„å®ƒä»¬æ‰€é€è¿‡çš„å…‰çº¿ï¼Œæ¨¡ç³Šå®ƒä»¬èƒŒåçš„ä¸œè¥¿ã€‚è¿™ç§è¡Œä¸ºåœ¨æ¸¸æˆä¸­å¾ˆå°‘å‡ºç°ï¼Œå› ä¸ºå®ƒçš„å®ç°è¦å¤æ‚å¾—å¤šã€‚é€æ˜æè´¨å¯ä»¥åœ¨ä¸è¿›è¡Œå…‰çº¿è·Ÿè¸ªçš„æƒ…å†µä¸‹é€šè¿‡alphaæ··åˆå¤©çœŸåœ°å®ç°ã€‚å¦ä¸€æ–¹é¢ï¼ŒåŠé€æ˜æè´¨éœ€è¦æ¨¡æ‹Ÿå…‰çº¿çš„åç§»ã€‚è¿™æ ·çš„è®¡ç®—éå¸¸æ˜‚è´µï¼Œå¹¶ä¸”åœ¨å®æ—¶æ¸²æŸ“ä¸­å¾ˆå°‘å€¼å¾—ã€‚

This often prevents from achieving otherÂ optical phenomena,Â such as **subsurface scattering**. When light hits the surface of a translucent material, a part propagates inside, bouncing between the molecules until it finds its way out. This often causes light absorbed at a specific point to be reemitted somewhere else. Subsurface scattering results in a diffuse glow that can be seen in materials such as skin, marble, and milk.  
è¿™é€šå¸¸ä¼šå¦¨ç¢å®ç°å…¶ä»–å…‰å­¦ç°è±¡ï¼Œä¾‹å¦‚æ¬¡è¡¨é¢æ•£å°„ã€‚å½“å…‰ç…§å°„åˆ°åŠé€æ˜ææ–™çš„è¡¨é¢æ—¶ï¼Œä¸€éƒ¨åˆ†åœ¨å†…éƒ¨ä¼ æ’­ï¼Œåœ¨åˆ†å­ä¹‹é—´åå¼¹ï¼Œç›´åˆ°æ‰¾åˆ°å‡ºè·¯ã€‚è¿™é€šå¸¸ä¼šå¯¼è‡´åœ¨ç‰¹å®šç‚¹è¢«å¸æ”¶çš„å…‰åœ¨å…¶ä»–åœ°æ–¹å†æ¬¡å‡ºç°ã€‚äºšè¡¨é¢æ•£å°„ä¼šäº§ç”Ÿæ¼«å°„è¾‰å…‰ï¼Œè¿™ç§è¾‰å…‰å¯ä»¥åœ¨çš®è‚¤ã€å¤§ç†çŸ³å’Œç‰›å¥¶ç­‰ææ–™ä¸­çœ‹åˆ°ã€‚

#### Real Time Translucency å®æ—¶åŠé€æ˜

There are two main obstacles that make translucency so expensive. The first one is that it requires simulating the scattering of light rays inside a material. Each ray can split in multiple ones, reflecting hundreds or even thousands of times inside a material. The second obstacle is that light received at one point is reemitted somewhere else. While this seems a minor issue, in reality, is a big deal.  
åŠé€æ˜ä¹‹æ‰€ä»¥å¦‚æ­¤æ˜‚è´µï¼Œä¸»è¦æœ‰ä¸¤ä¸ªéšœç¢ã€‚ç¬¬ä¸€ä¸ªæ˜¯å®ƒéœ€è¦æ¨¡æ‹Ÿå…‰çº¿åœ¨ææ–™å†…éƒ¨çš„æ•£å°„ã€‚æ¯æ¡å…‰çº¿å¯ä»¥åˆ†è£‚æˆå¤šæ¡ï¼Œåœ¨ä¸€ç§ææ–™å†…åå°„æ•°ç™¾ç”šè‡³æ•°åƒæ¬¡ã€‚ç¬¬äºŒä¸ªéšœç¢æ˜¯åœ¨ä¸€ä¸ªç‚¹ä¸Šæ¥æ”¶åˆ°çš„å…‰åœ¨å…¶ä»–åœ°æ–¹é‡æ–°å‘å°„ã€‚è™½ç„¶è¿™çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªå°é—®é¢˜ï¼Œä½†å®é™…ä¸Šå´æ˜¯ä¸€ä»¶å¤§äº‹ã€‚

To understand why, we first need to look at how most shaders work. In the realm of real-time rendering, GPUs expect a shader to be able to calculate the final colour of a material simply using local properties. For each vertex, shaders are designed to efficiently access only the properties that are local to that vertex. Reading the normal direction and albedo of a vertex is easy; retrieving the ones of its neighbours is not. Most real-time solution must work around these constraints, and find a way to _fake_ the propagation of light within a material without relying on non-local information.  
è¦äº†è§£åŸå› ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦äº†è§£å¤§å¤šæ•°ç€è‰²å™¨æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚åœ¨å®æ—¶æ¸²æŸ“é¢†åŸŸï¼ŒGPUå¸Œæœ›ç€è‰²å™¨èƒ½å¤Ÿç®€å•åœ°ä½¿ç”¨å±€éƒ¨å±æ€§æ¥è®¡ç®—æè´¨çš„æœ€ç»ˆé¢œè‰²ã€‚å¯¹äºæ¯ä¸ªé¡¶ç‚¹ï¼Œç€è‰²å™¨è¢«è®¾è®¡ä¸ºä»…æœ‰æ•ˆåœ°è®¿é—®è¯¥é¡¶ç‚¹çš„å±€éƒ¨å±æ€§ã€‚è¯»å–é¡¶ç‚¹çš„æ³•çº¿æ–¹å‘å’Œåç…§ç‡å¾ˆå®¹æ˜“ï¼›æ£€ç´¢å®ƒçš„é‚»å±…å¹¶ä¸æ˜¯ã€‚å¤§å¤šæ•°å®æ—¶è§£å†³æ–¹æ¡ˆå¿…é¡»ç»•è¿‡è¿™äº›é™åˆ¶ï¼Œå¹¶æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥ä¼ªé€ å…‰åœ¨ææ–™å†…çš„ä¼ æ’­ï¼Œè€Œä¸ä¾èµ–äºéå±€éƒ¨ä¿¡æ¯ã€‚

The approach described in this tutorial is based on the solution presented at GDC 2011 byÂ Colin BarrÃ©-Brisebois and Marc Bouchard in a talk called [Approximating Translucency for a Fast, Cheap and Convincing Subsurface Scattering Look](https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/). Their solution is integrated into the **Frostbite 2** engine, which was used for DICEâ€™s **Battlefield 3**. While not being physically accurate, the approach presented by Colin and Marc produces very believable results at a very small cost.  
æœ¬æ•™ç¨‹ä¸­æè¿°çš„æ–¹æ³•æ˜¯åŸºäºColin BarrÃ©-Briseboiså’ŒMarc Bouchardåœ¨2011å¹´GDCä¸Šå‘è¡¨çš„ä¸€ç¯‡é¢˜ä¸ºâ€œè¿‘ä¼¼åŠé€æ˜ä»¥å®ç°å¿«é€Ÿã€å»‰ä»·å’Œä»¤äººä¿¡æœçš„äºšè¡¨é¢æ•£å°„å¤–è§‚â€çš„æ¼”è®²ä¸­æå‡ºçš„è§£å†³æ–¹æ¡ˆã€‚ä»–ä»¬çš„è§£å†³æ–¹æ¡ˆé›†æˆåˆ°äº†ç”¨äºDICEçš„ã€Šæˆ˜åœ°3ã€‹çš„éœœå’¬2å‘åŠ¨æœºä¸­ã€‚è™½ç„¶åœ¨ç‰©ç†ä¸Šå¹¶ä¸å‡†ç¡®ï¼Œä½†Colinå’ŒMarcæå‡ºçš„æ–¹æ³•ä»¥éå¸¸å°çš„æˆæœ¬äº§ç”Ÿäº†éå¸¸å¯ä¿¡çš„ç»“æœã€‚

The idea behind their solution is very simple. In opaque materials, the light contribution comes directly from the light source. Vertices that are inclined more than 90 degrees in respects to the direction of the light,  
ä»–ä»¬çš„è§£å†³æ–¹æ¡ˆèƒŒåçš„æƒ³æ³•éå¸¸ç®€å•ã€‚åœ¨ä¸é€æ˜æè´¨ä¸­ï¼Œå…‰çš„è´¡çŒ®ç›´æ¥æ¥è‡ªå…‰æºã€‚ç›¸å¯¹äºå…‰çš„æ–¹å‘å€¾æ–œè¶…è¿‡90åº¦çš„é¡¶ç‚¹ï¼Œ

![](<images/1683794163163.png>)

, receive no light (bottom, left). According to the model proposed in the presentation, translucent materials have an additional light contribution which is related to  
ï¼Œä¸æ¥æ”¶ç¯å…‰ï¼ˆåº•éƒ¨ï¼Œå·¦ä¾§ï¼‰ã€‚æ ¹æ®æ¼”ç¤ºä¸­æå‡ºçš„æ¨¡å‹ï¼ŒåŠé€æ˜ææ–™å…·æœ‰é¢å¤–çš„å…‰è´¡çŒ®ï¼Œè¿™ä¸

![](<images/1683794164571.png>)

. Geometrically,

![](<images/1683794166037.png>)

can be seen as if some of the light actually passed through the material and made it to the other side (bottom, right).  
å¯ä»¥çœ‹åˆ°ï¼Œå°±å¥½åƒä¸€äº›å…‰å®é™…ä¸Šç©¿è¿‡äº†ææ–™å¹¶åˆ°è¾¾äº†å¦ä¸€ä¾§ï¼ˆåº•éƒ¨ï¼Œå³ä¾§ï¼‰ã€‚

![](<images/1683794168435.png>)

Each light now accounts for two, distinct reflectances contributions: the front and back illuminations. Since we want our materials to be as realistic as possible, we will use Unityâ€™s Standard PBR lighting models for the front illumination. What we need is to find a way to describe the contribution from  
ç°åœ¨ï¼Œæ¯ç§å…‰çº¿éƒ½æœ‰ä¸¤ç§ä¸åŒçš„åå°„ç‡è´¡çŒ®ï¼šå‰ç…§æ˜å’Œåç…§æ˜ã€‚ç”±äºæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ææ–™å°½å¯èƒ½é€¼çœŸï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Unityçš„æ ‡å‡†PBRç…§æ˜æ¨¡å‹è¿›è¡Œæ­£é¢ç…§æ˜ã€‚æˆ‘ä»¬éœ€è¦çš„æ˜¯æ‰¾åˆ°ä¸€ç§æ–¹å¼æ¥æè¿°

![](<images/1683794169267.png>)

, and render it in a way that somehow simulates the diffusion process which might have occurred inside the material.  
ï¼Œå¹¶ä»¥æŸç§æ–¹å¼æ¸²æŸ“å®ƒï¼Œä»¥æŸç§æ–¹å¼æ¨¡æ‹Ÿå¯èƒ½å‘ç”Ÿåœ¨æè´¨å†…éƒ¨çš„æ‰©æ•£è¿‡ç¨‹ã€‚

##### 

![](<images/1683794170042.png>)

Suggested Unity Assets  å»ºè®®çš„Unityèµ„äº§

![](<images/1683794170218.png>)

Unity is free, but you can upgrade to [**Unity Pro**](http://prf.hn/click/camref:1100l45Ay/destination:https://store.unity.com/products/unity-pro) or [**Unity Plus**](http://prf.hn/click/camref:1100l45Ay/destination:https://store.unity.com/products/unity-plus) subscriptions plans to get more functionality and training resources to power up your projects.  
Unityæ˜¯å…è´¹çš„ï¼Œä½†æ‚¨å¯ä»¥å‡çº§åˆ°Unity Proæˆ–Unity Plusè®¢é˜…è®¡åˆ’ï¼Œä»¥è·å¾—æ›´å¤šåŠŸèƒ½å’ŒåŸ¹è®­èµ„æºï¼Œä¸ºæ‚¨çš„é¡¹ç›®æä¾›åŠ¨åŠ›ã€‚

#### Back Translucency

As discussed before, the final colour of our pixels depend is the sum of two components. The first one is the â€œtraditionalâ€ lighting. The second one is the light contribution from a virtual light source illuminating the back of our model. This gives the impression that light from the original source actually passed through the material.  
å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬åƒç´ çš„æœ€ç»ˆé¢œè‰²å–å†³äºä¸¤ä¸ªåˆ†é‡çš„æ€»å’Œã€‚ç¬¬ä¸€ä¸ªæ˜¯â€œä¼ ç»Ÿâ€ç…§æ˜ã€‚ç¬¬äºŒä¸ªæ˜¯æ¥è‡ªç…§äº®æˆ‘ä»¬æ¨¡å‹èƒŒé¢çš„è™šæ‹Ÿå…‰æºçš„å…‰è´¡çŒ®ã€‚è¿™ç»™äººçš„å°è±¡æ˜¯ï¼Œæ¥è‡ªåŸå§‹å…‰æºçš„å…‰å®é™…ä¸Šç©¿è¿‡äº†ææ–™ã€‚

To understand how to model this mathematically, letâ€™s picture the following two scenarios (diagrams below). We are currently drawing the red point; since itâ€™s in the â€œdarkâ€ side of the material, it should be illuminated by  
ä¸ºäº†ç†è§£å¦‚ä½•å¯¹å…¶è¿›è¡Œæ•°å­¦å»ºæ¨¡ï¼Œè®©æˆ‘ä»¬æç»˜ä»¥ä¸‹ä¸¤ç§åœºæ™¯ï¼ˆä¸‹å›¾ï¼‰ã€‚æˆ‘ä»¬ç›®å‰æ­£åœ¨ç»˜åˆ¶çº¢ç‚¹ï¼›ç”±äºå®ƒä½äºææ–™çš„â€œæš—â€é¢ï¼Œå› æ­¤åº”è¯¥ç”±

![](<images/1683794170392.png>)

. From the perspective of an external viewer, letâ€™s analyse the two extreme cases. We can see that  
ã€‚è®©æˆ‘ä»¬ä»å¤–éƒ¨è§‚ä¼—çš„è§’åº¦æ¥åˆ†æè¿™ä¸¤ä¸ªæç«¯çš„æ¡ˆä¾‹ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°

![](<images/1683794171157.png>)

is perfectly aligned with  
ä¸å®Œå…¨ä¸€è‡´

![](<images/1683794172573.png>)

, meaning that the viewer  
ï¼Œæ„å‘³ç€è§‚ä¼—

![](<images/1683794173402.png>)

should see the back translucency at its fullest. On the other hand, viewer  
åº”è¯¥èƒ½çœ‹åˆ°èƒŒéƒ¨çš„åŠé€æ˜æ„Ÿã€‚å¦ä¸€æ–¹é¢ï¼Œè§‚ä¼—

![](<images/1683794174194.png>)

should see the least amount of backlight as it is perpendicular to  
åº”è¯¥çœ‹åˆ°æœ€å°‘çš„èƒŒå…‰ï¼Œå› ä¸ºå®ƒå‚ç›´äº

![](<images/1683794174916.png>)

.

![](<images/1683794175753.png>)

If you are not new to shader coding, this kind of reasoning should sound familiar. We have encountered something similar in the tutorial on [Physically Based Rendering and Lighting Models in Unity 5](https://www.alanzucconi.com/2015/06/24/physically-based-rendering/), where we showed how such a behaviour can be obtained using a mathematical operator called the **dot product**.  
å¦‚æœæ‚¨ä¸æ˜¯ç€è‰²å™¨ç¼–ç çš„æ–°æ‰‹ï¼Œé‚£ä¹ˆè¿™ç§æ¨ç†å¬èµ·æ¥åº”è¯¥å¾ˆç†Ÿæ‚‰ã€‚æˆ‘ä»¬åœ¨Unity 5ä¸­çš„åŸºäºç‰©ç†çš„æ¸²æŸ“å’Œç…§æ˜æ¨¡å‹æ•™ç¨‹ä¸­é‡åˆ°äº†ç±»ä¼¼çš„æƒ…å†µï¼Œæˆ‘ä»¬åœ¨æ•™ç¨‹ä¸­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ç§°ä¸ºç‚¹ç§¯çš„æ•°å­¦è¿ç®—ç¬¦æ¥è·å¾—è¿™ç§è¡Œä¸ºã€‚

As a first approximation, we can say that the amount of back lighting due to translucency  
ä½œä¸ºç¬¬ä¸€ä¸ªè¿‘ä¼¼å€¼ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ç”±äºåŠé€æ˜è€Œäº§ç”Ÿçš„èƒŒå…‰é‡

![](<images/1683794177386.png>)

is proportional to  ä¸æˆæ¯”ä¾‹

![](<images/1683794178813.png>)

. In a traditional diffuse shader, this would be  
ã€‚åœ¨ä¼ ç»Ÿçš„æ¼«åå°„ç€è‰²å™¨ä¸­

![](<images/1683794180233.png>)

. We can see that we have not included the **surface normal** in the calculation, as light is simply coming out of the material, not reflecting on it.  
ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æ²¡æœ‰å°†è¡¨é¢æ³•çº¿åŒ…æ‹¬åœ¨è®¡ç®—ä¸­ï¼Œå› ä¸ºå…‰åªæ˜¯ä»ææ–™ä¸­å‡ºæ¥ï¼Œè€Œä¸æ˜¯åœ¨ææ–™ä¸Šåå°„ã€‚

#### Subsurface Distortion åœ°ä¸‹å˜å½¢

However, the surface normal should have some influence, even if minor, on the angle at which the light is leaving the material. The authors of this technique introduced a parameter, called **subsurfaceÂ distortion**   
ä½†æ˜¯ï¼Œæ›²é¢æ³•çº¿åº”è¯¥å¯¹å…‰çº¿ç¦»å¼€æè´¨çš„è§’åº¦æœ‰ä¸€äº›å½±å“ï¼Œå³ä½¿å½±å“å¾ˆå°ã€‚è¿™é¡¹æŠ€æœ¯çš„ä½œè€…å¼•å…¥äº†ä¸€ä¸ªå‚æ•°ï¼Œç§°ä¸ºåœ°ä¸‹ç•¸å˜

![](<images/1683794182631.png>)

, which forces the vector  
ï¼Œå®ƒå¼ºåˆ¶çŸ¢é‡

![](<images/1683794183965.png>)

to point towards  æŒ‡å‘

![](<images/1683794184697.png>)

. Physically speaking, this the subsurface distortion controls how strongly the surface normal deflects the outgoing back light. Following the solution proposed, the intensity of the back translucency component becomes:  
ã€‚ä»ç‰©ç†ä¸Šè®²ï¼Œè¿™æ˜¯æ¬¡è¡¨é¢æ‰­æ›²æ§åˆ¶è¡¨é¢æ³•çº¿åè½¬å‡ºå°„èƒŒå…‰çš„å¼ºåº¦ã€‚æ ¹æ®æ‰€æå‡ºçš„è§£å†³æ–¹æ¡ˆï¼ŒèƒŒé¢åŠé€æ˜æˆåˆ†çš„å¼ºåº¦å˜ä¸ºï¼š

![](<images/1683794185461.png>)

Where

![](<images/1683794186945.png>)

is a unit vector that points in the same direction of  
æ˜¯æŒ‡å‘çš„åŒä¸€æ–¹å‘çš„å•ä½å‘é‡

![](<images/1683794188412.png>)

. If you are familiar with Cg/HLSL, that is the  
ã€‚å¦‚æœä½ ç†Ÿæ‚‰Cg/HLSLï¼Œé‚£å°±æ˜¯

normalize

`normalize`

function.

When

![](<images/1683794189860.png>)

, we return to the  
ï¼Œæˆ‘ä»¬è¿”å›

![](<images/1683794191317.png>)

derived in the previous paragraph. When  
æºè‡ªä¸Šä¸€æ®µã€‚ä»€ä¹ˆæ—¶å€™

![](<images/1683794192742.png>)

, however, we are calculating the dot product between the view direction and  
ç„¶è€Œï¼Œæˆ‘ä»¬æ­£åœ¨è®¡ç®—è§†å›¾æ–¹å‘å’Œ

![](<images/1683794193544.png>)

. If you are familiar with the **Blinn-Phong reflectance**, you should know that  
ã€‚å¦‚æœä½ ç†Ÿæ‚‰Blinn Phongåå°„ç‡ï¼Œä½ åº”è¯¥çŸ¥é“

![](<images/1683794194988.png>)

is the vector â€œin betweenâ€  
æ˜¯â€œä»‹äºâ€ä¹‹é—´çš„çŸ¢é‡

![](<images/1683794196369.png>)

and

![](<images/1683794197139.png>)

. For this reason, we will call it as the **halfway direction**  
ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºä¸­é€”æ–¹å‘

![](<images/1683794198619.png>)

.

![](<images/1683794199381.png>)

The diagram above shows all the directions used so far.  
ä¸Šå›¾æ˜¾ç¤ºäº†è¿„ä»Šä¸ºæ­¢ä½¿ç”¨çš„æ‰€æœ‰æ–¹å‘ã€‚

![](<images/1683794200862.png>)

is indicated in purple, and you can see that it rests in between  
ç”¨ç´«è‰²è¡¨ç¤ºï¼Œä½ å¯ä»¥çœ‹åˆ°å®ƒä½äºä¸­é—´

![](<images/1683794202400.png>)

and

![](<images/1683794203797.png>)

. Geometrically speaking, varying  
ä»å‡ ä½•è§’åº¦æ¥è¯´ï¼Œå˜åŒ–

![](<images/1683794204568.png>)

from

![](<images/1683794205309.png>)

to

![](<images/1683794206141.png>)

causes a shift in the perceived direction of the light  
å¯¼è‡´å…‰çš„æ„ŸçŸ¥æ–¹å‘å‘ç”Ÿåç§»

![](<images/1683794207518.png>)

. The light shaded area shows the range of directions the backlight will come from. In the image below you can see that with  
æµ…è‰²é˜´å½±åŒºåŸŸæ˜¾ç¤ºèƒŒå…‰å°†æ¥è‡ªçš„æ–¹å‘èŒƒå›´ã€‚åœ¨ä¸‹å›¾ä¸­ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°

![](<images/1683794208284.png>)

, the object seems to be illuminated from the purple light source. When  
ï¼Œç‰©ä½“ä¼¼ä¹æ˜¯ç”±ç´«è‰²å…‰æºç…§äº®çš„ã€‚ä»€ä¹ˆæ—¶å€™

![](<images/1683794210136.png>)

moved towards

![](<images/1683794210942.png>)

, the perceived direction of the light source shifts towards the purple one.  
ï¼Œå…‰æºçš„æ„ŸçŸ¥æ–¹å‘å‘ç´«è‰²æ–¹å‘ç§»åŠ¨ã€‚

![](<images/1683794211766.png>)

The purpose of  ç›®çš„

![](<images/1683794212519.png>)

is to simulate the tendency of certain translucent materials to diffuse the backlight with different intensities. Higher values of  
æ˜¯æ¨¡æ‹ŸæŸäº›åŠé€æ˜ææ–™ä»¥ä¸åŒå¼ºåº¦æ•£å°„èƒŒå…‰çš„è¶‹åŠ¿ã€‚çš„è¾ƒé«˜å€¼

![](<images/1683794213276.png>)

will cause the back light to scatter more.  
å°†å¯¼è‡´èƒŒå…‰æ•£å°„æ›´å¤šã€‚

![](<images/1683794214121.png>)

Is this H the same H used in the Blinn-Phong Reflectance?  
è¿™ä¸ªHä¸â€œBlinn Phong Reflectanceâ€ä¸­ä½¿ç”¨çš„Hç›¸åŒå—ï¼Ÿ

![](<images/1683794214295.png>)

Is ğ›¿ really interpolating between L and L+N?  
æ˜¯ğ›¿ çœŸçš„åœ¨Lå’ŒL+Nä¹‹é—´æ’å€¼å—ï¼Ÿ

![](<images/1683794214456.png>)

How come the authors did not normalise L+N?  
ä¸ºä»€ä¹ˆä½œè€…æ²¡æœ‰å°†L+Næ ‡å‡†åŒ–ï¼Ÿ

#### Back Light Diffusion èƒŒå…‰æ¼«å°„

At this point in the tutorial, we already have an equation that we can use simulate translucent materials. The quantity  
åœ¨æœ¬æ•™ç¨‹çš„è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªå¯ä»¥ç”¨æ¥æ¨¡æ‹ŸåŠé€æ˜æè´¨çš„æ–¹ç¨‹ã€‚æ•°é‡

![](<images/1683794214606.png>)

can not be used to calculate the final light contribution.  
ä¸èƒ½ç”¨äºè®¡ç®—æœ€ç»ˆçš„å…‰è´¡çŒ®ã€‚

There are two main approaches that can be used. The first oneÂ relies on a texture. If you want to have full artistic control on the way light diffuses in the material, you should clamp  
å¯ä»¥ä½¿ç”¨ä¸¤ç§ä¸»è¦æ–¹æ³•ã€‚ç¬¬ä¸€ä¸ªä¾èµ–äºçº¹ç†ã€‚å¦‚æœä½ æƒ³å¯¹å…‰çº¿åœ¨æè´¨ä¸­çš„æ¼«å°„æ–¹å¼æœ‰å®Œå…¨çš„è‰ºæœ¯æ§åˆ¶ï¼Œä½ åº”è¯¥å¤¹ç´§

![](<images/1683794215442.png>)

between

![](<images/1683794218612.png>)

and

![](<images/1683794220097.png>)

, and use it to sample the final intensity of the back light. Different ramp textures will simulate the light transport within different materials. We will see in the next part of this tutorial how this can be used to change the result of this shader dramatically.  
ï¼Œå¹¶ä½¿ç”¨å®ƒå¯¹èƒŒå…‰çš„æœ€ç»ˆå¼ºåº¦è¿›è¡Œé‡‡æ ·ã€‚ä¸åŒçš„æ¸å˜çº¹ç†å°†æ¨¡æ‹Ÿä¸åŒæè´¨ä¸­çš„å…‰ä¼ è¾“ã€‚æˆ‘ä»¬å°†åœ¨æœ¬æ•™ç¨‹çš„ä¸‹ä¸€éƒ¨åˆ†ä¸­çœ‹åˆ°å¦‚ä½•ä½¿ç”¨å®ƒæ¥æ˜¾è‘—æ›´æ”¹æ­¤ç€è‰²å™¨çš„ç»“æœã€‚

The approach used by the author of this technique, however, does not rely on a texture. It creates a curve using Cg code only:  
ç„¶è€Œï¼Œè¿™é¡¹æŠ€æœ¯çš„ä½œè€…æ‰€ä½¿ç”¨çš„æ–¹æ³•å¹¶ä¸ä¾èµ–äºçº¹ç†ã€‚å®ƒä»…ä½¿ç”¨Cgä»£ç åˆ›å»ºæ›²çº¿ï¼š

![](<images/1683794221814.png>)

The two new parameters,  è¿™ä¸¤ä¸ªæ–°å‚æ•°ï¼Œ

![](<images/1683794222614.png>)

(_power_) and

![](<images/1683794224046.png>)

(_scale_) are used to change the properties of the curve.  
ï¼ˆæ¯”ä¾‹ï¼‰ç”¨äºæ›´æ”¹æ›²çº¿çš„å±æ€§ã€‚

#### Conclusion

This post explains the technical challenges in rendering translucent materials. An approximate solution is introduced, followed the approach presented by [Approximating Translucency for a Fast, Cheap and Convincing Subsurface Scattering Look](https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/). The next part of this tutorial will focus on how to actually implement this effect in a shader in Unity.  
è¿™ç¯‡æ–‡ç« è§£é‡Šäº†æ¸²æŸ“åŠé€æ˜æè´¨çš„æŠ€æœ¯æŒ‘æˆ˜ã€‚ä»‹ç»äº†ä¸€ç§è¿‘ä¼¼è§£ï¼Œéµå¾ªè¿‘ä¼¼åŠé€æ˜çš„æ–¹æ³•ï¼Œè·å¾—å¿«é€Ÿã€å»‰ä»·å’Œä»¤äººä¿¡æœçš„äºšè¡¨é¢æ•£å°„å¤–è§‚ã€‚æœ¬æ•™ç¨‹çš„ä¸‹ä¸€éƒ¨åˆ†å°†é‡ç‚¹ä»‹ç»å¦‚ä½•åœ¨Unityä¸­çš„ç€è‰²å™¨ä¸­å®é™…å®ç°æ­¤æ•ˆæœã€‚

*   Part 1. **Fast Subsurface Scattering in Unity**  
    ç¬¬1éƒ¨åˆ†ã€‚Unityä¸­çš„å¿«é€Ÿæ¬¡è¡¨é¢æ•£å°„
*   Part 2. [Fast Subsurface Scattering in Unity](https://www.alanzucconi.com/?p=7101)  
    ç¬¬2éƒ¨åˆ†ã€‚Unityä¸­çš„å¿«é€Ÿæ¬¡è¡¨é¢æ•£å°„

If you are interested in more sophisticated approaches to simulate subsurface scattering for real time applications, [GPU Gems](https://developer.nvidia.com/gpugems/gpugems/part-iii-materials/chapter-16-real-time-approximations-subsurface-scattering) provides one of the best tutorials you can find.  
å¦‚æœæ‚¨å¯¹æ›´å¤æ‚çš„æ–¹æ³•æ„Ÿå…´è¶£ï¼Œå¯ä»¥ä¸ºå®æ—¶åº”ç”¨ç¨‹åºæ¨¡æ‹Ÿæ¬¡è¡¨é¢æ•£å°„ï¼ŒGPU Gemsæä¾›äº†æ‚¨èƒ½æ‰¾åˆ°çš„æœ€å¥½çš„æ•™ç¨‹ä¹‹ä¸€ã€‚

  
You can download all the necessary files to run this project (shader, textures, models, scenes) on [**Patreon**](https://www.patreon.com/posts/14122322).  
æ‚¨å¯ä»¥ä¸‹è½½åœ¨Patreonä¸Šè¿è¡Œæ­¤é¡¹ç›®æ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆç€è‰²å™¨ã€çº¹ç†ã€æ¨¡å‹ã€åœºæ™¯ï¼‰ã€‚

##### 

![](<images/1683794225514.png>)

Support this blog  æ”¯æŒæ­¤åšå®¢

This websites exists thanks to the contribution of patrons on Patreon. If you think these posts have either helped or inspired you, please consider supporting this blog.  
è¿™ä¸ªç½‘ç«™çš„å­˜åœ¨è¦å½’åŠŸäºPatreonä¸Šé¡¾å®¢çš„è´¡çŒ®ã€‚å¦‚æœä½ è®¤ä¸ºè¿™äº›å¸–å­å¯¹ä½ æœ‰å¸®åŠ©æˆ–å¯å‘ï¼Œè¯·è€ƒè™‘æ”¯æŒè¿™ä¸ªåšå®¢ã€‚

[![](https://www.alanzucconi.com/wp-content/uploads/2017/07/patreon_logo.png)](https://www.patreon.com/AlanZucconi)

[![](https://www.alanzucconi.com/wp-content/uploads/2020/03/youtube_logo_square.png)](https://www.youtube.com/c/AlanZucconi)

##### 

![](<images/1683794267859.png>)

Stay updated

You will be notified when a new tutorial is relesed!  
å½“æ–°æ•™ç¨‹å‘å¸ƒæ—¶ï¼Œæ‚¨å°†æ”¶åˆ°é€šçŸ¥ï¼

##### 

![](<images/1683794268049.png>)

Licensing

You are free to use, adapt and build upon this tutorial for your own projects (even commercially) as long as you credit me.  
åªè¦ä½ ç›¸ä¿¡æˆ‘ï¼Œä½ å°±å¯ä»¥è‡ªç”±åœ°ä½¿ç”¨ã€æ”¹ç¼–å’Œæ„å»ºæœ¬æ•™ç¨‹ï¼Œç”¨äºä½ è‡ªå·±çš„é¡¹ç›®ï¼ˆç”šè‡³æ˜¯å•†ä¸šé¡¹ç›®ï¼‰ã€‚

You are not allowed to redistribute the content of this tutorial on other platforms. Especially the parts that are only available on Patreon.  
æ‚¨ä¸å…è®¸åœ¨å…¶ä»–å¹³å°ä¸Šé‡æ–°åˆ†å‘æœ¬æ•™ç¨‹çš„å†…å®¹ã€‚å°¤å…¶æ˜¯Patreonä¸Šä»…æœ‰çš„é›¶ä»¶ã€‚

If the knowledge you have gained had a significant impact on your project, a mention in the credit would be very appreciated.  
å¦‚æœä½ æ‰€è·å¾—çš„çŸ¥è¯†å¯¹ä½ çš„é¡¹ç›®äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œè¯·åœ¨å­¦åˆ†ä¸­æåŠã€‚

![](<images/1683794268200.png>)

![](<images/1683794268351.png>)