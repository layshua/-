
---
title: 03 深度缓冲
aliases: []
tags: []
create_time: 2023-07-08 14:23
uid: 202307081423
banner: "![[Pasted image 20230708142421.png]]"
---


> [!note]  约定
> 本文采用 OpenGL 标准进行推导
> 1. 列向量
> 2. 模型空间、世界空间、观察空间是右手坐标系，而裁剪空间与 NDC 是左手坐标系
> 3. Camera 的 LookAt （Forward）方向为 $- z$ 轴方向
> 4. **NDC 空间范围** $[-1,1]^3$ 
> 5.  OpenGL 使用**距离值**表示 $n、f$。$n$ 被映射到 $-1$，$f$ 被映射到 $1$


> [!note] 深度纹理
> Depth Texture = 深度纹理 = 深度图
> 上面保存了深度缓冲区的值，是非线性深度，使用时要先转换成线性深度

深度是指像素到摄像机的距离，观察空间的深度为**线性深度**，NDC 空间的深度为**非线性深度**。
引擎通常帮我们收集 NDC 空间空间的深度信息保存在一张 Depth Texture 中，其中寸的也是**非线性深度**。
当我们想要精确表达物体的深度差异或者重建像素世界坐标位置，就需要使用将非线性深度转化为线性深度。
# 理论与推导
## 非线性深度

假如在 MV 变换后，**观察空间（View Space）** 下的某个点对应的齐次坐标为 $(x,y,z,1)$，那么经过透视投影变换和 GPU 裁剪后转换到**齐次裁剪空间（Clip Space）**，变换过程如下：（该变换同样适用于 Unity，Unity 与 OpenGL 投影矩阵相同）

![[02 视图变换#^bgahra]]

我们只关注深度，即 $\displaystyle z'=-(\frac{f+n}{f-n})z-\frac{2fn}{f-n}$

然后进行**齐次除法**转换到**NDC 空间**
$$ z''=\frac{z'}{w'}=(\frac{f+n}{f-n})+\frac{2fn}{(f-n)z}\tag{1}$$
$z''$ 值范围为 $[-1,1]$ ，而 ZBuffer 中存储的值应该为 $[0,1]$，所以我们将 NDC 空间的 $Z$ 值范围转换到 $[0,1]$：（$NonLinearDepth$ 与 $\displaystyle \frac{1}{z}$ 相关，是非线性的，即**非线性深度**）
$$NonLinearDepth = z''\times0.5+0.5=\frac f{f-n}+\frac{2fn}{(f-n)\color\red{z}}$$
带入 $z=n, z=f$ 可得近平面 $NonLinearDepth$ 为 $1$，远平面 $NonLinearDepth$ 为 $0$

![[Pasted image 20230708123806.png]]
>范围转换前后对比，横轴为 z 值。可以看出靠近摄像机的十个单位占了 90%的深度缓冲区精度，故离摄像机越远的值精度越低

## 线性深度
![[Pasted image 20230708110316.png]]
>观察空间的深度为**线性深度**


![[Pasted image 20230708152129.png]]
>线性深度受 far 的影响

**线性深度分为两种：**
1. $LinearEyeDepth$：观察空间下的线性深度值，取值范围$[n, f]$
2. $Linear01Depth$：把线性深度归一化到$[0,1]$，我们通常会使用这个线性深度
$$
\begin{aligned}&LinearEyeDepth=-Pview.z\\\\&Linear01Depth=\frac{-Pview.z-n}{f-n}or\frac{-Pview.z}{f}\end{aligned}
$$

由方程（1）（2）可得：
$$ \begin{cases}z''=(\frac{f+n}{f-n})+\frac{2fn}{(f-n)z}  \\
z'' = NonLinearDepth\times2-1\end{cases}$$
联立可以求出 
$$z=\frac1{(\frac{f-n}{fn}*NonlinearDepth-\frac1n)}$$
由于世界空间以 $-Z$ 为正反向，所以求深度需要取反得到正数：
$$LinearEyeDepth=\frac{1}{(\frac{n-f}{fn}*NonlinearDepth+\frac1n)}$$

然后将 $LinearEyeDepth$ 除以 $f$ 即可得到归一化的线性深度 $Linear01Depth$
$$
\begin{aligned}Linear01Depth&=(\frac{1}{(\frac{n-f}{fn}*NonlinearDepth+\frac{1}{n})}\text{-n})/(f\text{-n})\\\\or&=\frac{1}{(\frac{n-f}{n}*NonlinearDepth+\frac{f}{n})}\end{aligned}
$$ 

![[Pasted image 20230708152153.png]]
>曲线对比图

## 深度纹理重建像素的世界空间坐标
### 使用 VP 逆矩阵重建
设 NDC 空间上的点 $P_{ndc}$ 映射到屏幕空间上为点 $P(x, y)$
设 ${P.x=u}*{Width}, {P.y=v}*{Height}$

首先将屏幕空间坐标转换到 NDC 空间，从 NDC 空间到屏幕空间，点 P 相对于左下角坐标的比例是不变的，可以列出等式：

![[Pasted image 20230708152930.png]]

由前文可知,  $P_{ndc}.z=2*NonlinearDepth-1$
则：
$$
\begin{array}{lcr}P_{ndc}.x=2*u-1\\ P_{ndc}.y=2*v-1\\ P_{ndc}.z=2*NonlinearDepth-1\\ P_{ndc}.w=1.0\end{array}
$$ 
由齐次除法可知 $\displaystyle \frac{Pclip}{Pclip.w}=Pndc$，则 
$$\displaystyle P_{clip}=P_{ndc}*P_{clip}.w \tag{1}$$

因为 $P_{clip}$ 是由 $P_{world}$ 经过 $VP$ 矩阵变换的来，我们将 $VP$ 矩阵写作 $M$ ，则 $MP_{world} = P_{clip}$，带入（1）
$$P_{world}=M^{-1}P_{clip}=M^{-1}P_{ndc}*P_{clip}.w\tag{2}$$

因为 $P_{world}=(x,y,z,1)$ ，我们将其 $w$ 分量分量带入（2）
$$
P_{world}.w=({M^{-1}}P_{ndc}).w*P_{clip}.w=1
$$
$$
P_{clip}.w={\frac1{(M^{-1}P_{ndc}).w}}\tag{3}
$$
将（3）带入（2）即可得出世界空间坐标：
 $$P_{world}=\frac{M^{-1}P_{ndc}\tag{2}}{{(M^{-1}P_{ndc}).w}}$$
### 使用摄像机射线构建
利用方向向量重建，在脚本中计算视锥体四个角的向量然后利用顶点到片段的插值获取每个屏幕空间 uv 对应的方向向量
见冯乐乐 13.3 全局雾效全局雾效
# Unity 深度最佳实践
## 深度纹理
### 获取深度纹理
Unity 深度纹理深度纹理存储了高精度的深度值，范围是 $[0,1]$，通常是非线性分布。
![[Pasted image 20230707140918.png|450]]

`_CameraDepthTexture`：深度纹理
`_ZBufferParams`：用于线性化 Z 缓冲区值。`x` 是 (1-near/far)，`y` 是 (far/near)，`z` 是 (x/far)，`w` 是 (y/far)。
`Linear01Depth`：返回范围在 $[0,1]$ 的线性深度值
`LinearViewDepth`: 返回范围在 $[near, far]$ 的线性深度值

```cs
//声明深度纹理
TEXTURE2D(_CameraDepthTexture);  
SAMPLER(sampler_CameraDepthTexture);

//获取屏幕空间UV
float2 uvSS = i.positionoCS.xy / _ScreenParams.xy;

//用屏幕采样屏幕深度纹理得到非线性深度，转换成0-1线性深度图
float depthColor = SAMPLE_TEXTURE2D(_CameraDepthTexture, sampler_CameraDepthTexture, uvSS).r;
float linearDepthColor = Linear01Depth(depthColor,_ZBufferParams);

//计算模型深度，转换成线性深度图
float depth = i.positionoCS.z;
linearDepth = Linear01Depth(depth,_ZBufferParams);
```

### 脚本获取（未试验）
在 C# 端利用 **Shader. GetGlobalTexture** 来获取深度图，然后用 **Blit** 方法将其复制到 RenderTexture 上（这也是做 Hiz 剔除时重要的一环）。

这里需要注意的是，在 Unity 的生命周期中有很多的事件函数，例如 Start，Update，OnRenderObject 等等，那么我们应该在哪个事件中获取_CameraDepthTexture 才能保证是当前帧的深度图呢？
经过测试，**建议在 OnPostRender 中获得到当前帧的深度图**，如下：

```
void OnPostRender() {
    Graphics.Blit(Shader.GetGlobalTexture("_CameraDepthTexture"), renderTexture);
}
```

![[f0a1eb5076c260137185e5717bb453f5_MD5.jpg]]

注：有时在 OnPreRender 或者 Update 函数中获取_CameraDepthTexture，那么得到的深度图将会是 Scene 窗口下的深度图，具体原因暂时不明~

## 深度纹理重建像素的世界空间位置
![[202377141633.gif]]
### 步骤
1. 包含文件：DeclareDepthTexture. hlsl 文件包含用于对摄像机深度纹理进行采样的实用程序： `SampleSceneDepth` 返回 `[0, 1]` 范围内的 $Z$ 值。
```cs file:包含文件
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl"

//包含如下：已经声明了相机深度纹理，我们只需要传入屏幕空间uv调用采样函数
TEXTURE2D_X_FLOAT(_CameraDepthTexture);  
SAMPLER(sampler_CameraDepthTexture);

float SampleSceneDepth(float2 uv)  
{  
    return SAMPLE_TEXTURE2D_X(_CameraDepthTexture, sampler_CameraDepthTexture, UnityStereoTransformScreenSpaceTex(uv)).r;  
}  
  
float LoadSceneDepth(uint2 uv)  
{  
    return LOAD_TEXTURE2D_X(_CameraDepthTexture, uv).r;  
}
```

2. 在片元着色器中计算用于采样深度纹理的屏幕空间 UV 坐标，像素位置除以渲染目标分辨率 `_ScaledScreenParams`。`_ScaledScreenParams.xy` 属性会考虑渲染目标的任何缩放，例如动态分辨率。
```c file:用深度纹理和屏幕空间uv重建像素的世界空间位置  
//屏幕空间uv  
float2 uvSS = i.positionCS.xy / _ScaledScreenParams.xy;
```

3. 在片元着色器中，使用 `SampleSceneDepth` 函数对深度缓冲区进行采样。
```c file:从深度纹理中采样深度
#if UNITY_REVERSED_Z
    // 具有 REVERSED_Z 的平台（如 D3D）的情况。
    //返回[1,0]的深度值
    real depth = SampleSceneDepth(uvSS);
#else
    // 没有 REVERSED_Z 的平台（如 OpenGL）的情况。
    // 调整 Z 以匹配 OpenGL 的 NDC
    real depth = lerp(UNITY_NEAR_CLIP_VALUE, 1, SampleSceneDepth(uvSS));
#endif
```

4. 用像素的 UV 和 Z 坐标重建世界空间位置。
```c file:重建世界空间位置
float3 rebuildPosWS = ComputeWorldSpacePosition(uvSS, depth, UNITY_MATRIX_I_VP);
```
`ComputeWorldSpacePosition` ：根据屏幕空间 UV 和深度 ($Z$) 值计算世界空间位置
`UNITY_MATRIX_I_VP` 是一个逆视图投影矩阵，可将点从裁剪空间变换为世界空间。

5. 对于未渲染几何图形的区域，深度缓冲区可能没有任何有效值。以下代码会在这些区域绘制黑色。
```c
//在远裁剪面附近将颜色设置为黑色。
#if UNITY_REVERSED_Z
    if(depth < 0.0001)
        return half4(0,0,0,1);
#else
    if(depth > 0.9999)
        return half4(0,0,0,1);
#endif
```
不同的平台对远裁剪面使用不同的 Z 值（0 == far，或 1 == far）。`UNITY_REVERSED_Z` 常量让代码可以正确处理所有平台。

### 代码
```c fold file:使用深度纹理和屏幕空间UV坐标来重建像素的世界空间位置
Shader "Custom/RebuildPixelWorldPos from DepthTexture"
{
    Properties
    {
        _MainTex ("MainTex", 2D) = "white" {}
        _BaseColor("BaseColor", Color) = (1,1,1,1)
        [Normal] _NormalMap("NormalMap", 2D) = "bump" {}
        _NormalScale("NormalScale", Range(0, 10)) = 1

        [Header(Specular)]
        _SpecularExp("SpecularExp", Range(1, 100)) = 32
        _SpecularStrength("SpecularStrength", Range(0, 10)) = 1
        _SpecularColor("SpecularColor", Color) = (1,1,1,1)
    }
    
    HLSLINCLUDE

    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/lighting.hlsl"
    #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl"
    
    CBUFFER_START (UnityPerMateiral)
    float4 _MainTex_ST;
    float4 _BaseColor;
    float _NormalScale;
    float _SpecularExp;
    float _SpecularStrength;
    float4 _SpecularColor;
    CBUFFER_END

    TEXTURE2D(_MainTex);
    SAMPLER(sampler_MainTex);
    TEXTURE2D(_NormalMap);
    SAMPLER(sampler_NormalMap);
    struct Attributes
    {
        float4 positionOS : POSITION;
        float4 color : COLOR;
        float3 normalOS : NORMAL;
        float4 tangentOS : TANGENT;
        float2 uv : TEXCOORD0;
    };

    struct Varyings
    {
        float4 positionCS : SV_POSITION;
        float4 color : COLOR0;
        float2 uv : TEXCOORD0;
        float3 positionWS: TEXCOORD1;
        float3 normalWS : TEXCOORD2;
        float4 tangentWS : TEXCOORD3;
        float3 bitangentWS : TEXCOORD4;
        float3 viewDirWS : TEXCOORD5;
        float3 lightDirWS : TEXCOORD6;
    };
    ENDHLSL
    
    SubShader
    {
        Tags
        {
            "RenderPipeline" = "UniversalPipeline"
            "RenderType"="Opaque" 
        }

        Pass
        {
            Tags
            {
                "LightMode"="UniversalForward"
            }
            
            HLSLPROGRAM
            #pragma vertex vert
            #pragma fragment frag

            Varyings vert (Attributes i)
            {
                Varyings o = (Varyings)0;

                o.positionCS = TransformObjectToHClip(i.positionOS.xyz);
                o.uv = i.uv.xy * _MainTex_ST.xy + _MainTex_ST.zw;
                // output.uv = TRANSFORM_TEX(input.uv, _MainTex);
                o.positionWS = TransformObjectToWorld(i.positionOS.xyz);
                o.normalWS = TransformObjectToWorldNormal(i.normalOS);
                o.tangentWS.xyz = TransformObjectToWorldDir(i.tangentOS.xyz);
                //o.bitangentWS = cross(o.normalWS, o.tangentWS.xyz) * i.tangentOS.w * GetOddNegativeScale();
                o.viewDirWS = normalize(_WorldSpaceCameraPos.xyz - o.positionWS);

                return o;
            }

            float4 frag(Varyings i) : SV_Target
            {
                //主光源
                Light mainLight = GetMainLight();

                //纹理采样
                float4 MainTex = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv);
                float3 normalMap = UnpackNormalScale(
                    SAMPLE_TEXTURE2D(_NormalMap, sampler_NormalMap, i.uv), _NormalScale);

                //用深度纹理和屏幕空间uv重建像素的世界空间位置
                //屏幕空间uv
                float2 uvSS = i.positionCS.xy / _ScaledScreenParams.xy;
                //从深度纹理中采样深度
                #if UNITY_REVERSED_Z
                    // 具有 REVERSED_Z 的平台（如 D3D）的情况。
                    float depth = SampleSceneDepth (uvSS);
                #else
                    // 没有 REVERSED_Z 的平台（如 OpenGL）的情况。
                    // 调整 Z 以匹配 OpenGL 的 NDC ([-1, 1])
                    float depth = lerp(UNITY_NEAR_CLIP_VALUE, 1, SampleSceneDepth(uvSS));
                #endif
                // 重建世界空间位置
               float3 rebuildPosWS = ComputeWorldSpacePosition(uvSS, depth, UNITY_MATRIX_I_VP);
                
                //在远裁剪面附近将颜色设置为黑色。
                // #if UNITY_REVERSED_Z
                //     if(depth < 0.0001)
                //         return half4(0,0,0,1);
                // #else
                //     if(depth > 0.9999)
                //         return half4(0,0,0,1);
                // #endif
                return float4(normalize(rebuildPosWS), 1);
                
                //向量计算
                float3x3 TBN = CreateTangentToWorld(i.normalWS, i.tangentWS.xyz, i.tangentWS.w);
                float3 N = TransformTangentToWorld(normalMap, TBN, true);
                float3 L = normalize(mainLight.direction);
                float3 V = normalize(i.viewDirWS);
                float3 H = normalize(L + V);
                float NdotL = dot(N, L);
                float NdotH = dot(N, H);
                
                //颜色计算
                float3 diffuse = (0.5 * NdotL + 0.5) * _BaseColor.rgb * mainLight.color;
                float3 specular = pow(max(0, NdotH), _SpecularExp) * _SpecularStrength * _SpecularColor.rgb * mainLight.color;

                float4 finalColor = MainTex * float4((diffuse + _GlossyEnvironmentColor.rgb) + specular, 1);
                
                return finalColor;
            }
            
            ENDHLSL
        }
    }
    FallBack "Packages/com.unity.render-pipelines.universal/FallbackError"
}
```
