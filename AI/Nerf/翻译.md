[(22条消息) 深度学习(20):nerf论文翻译与学习_deepvoxel数据集_biter0088的博客-CSDN博客](https://blog.csdn.net/BIT_HXZ/article/details/128055763)


摘要。
  
我们提出了一种方法，通过使用稀疏的输入视图集优化底层的连续体积场景函数，在合成复杂场景的新视图方面取得了最先进的成果。
  
 我们的算法使用一个完全连接的（非卷积）深度网络来表示一个场景，其输入是一个单一的连续5D坐标（空间位置（x；y；z）和观察方向（θ；φ）），其输出是该空间位置的体积密度和依赖于视图的发射辐射度。
  
我们通过沿相机射线查询5D坐标来合成视图，并使用经典的体积渲染技术将输出的颜色和密度投影到图像中。
  
 由于体积渲染是自然可分的，优化我们的表述所需的唯一输入是一组具有已知相机姿势的图像。
  
 我们描述了如何有效地优化神经辐射场来渲染具有复杂几何和外观的场景的逼真的新视图，并展示了优于先前神经渲染和视图合成工作的结果。
  
视图合成的结果最好以视频的形式观看，所以我们敦促读者观看我们的补充视频，以获得令人信服的比较。
  