
本章将介绍实时图形的核心组件，即**图形渲染管线（graphics rendering pipeline）**，也被**简称为 “管线”（the pipeline）**。
管线的主要功能是在给定一个虚拟相机、 三维物体、光源等等的情况下生成或渲染二维图像。因此，渲染管线是用于实时渲染的基础工具。使用管线的过程如图 2.1 所示。图像中对象的位置和形状取决于它们的几何结构、环境特征以及相机在该环境中的位置。对象的外观受材质属性、光源、纹理（即应用于表面的图像）和着色方程（shading equations）的影响。

![](<images/1685518836027.png>)

**图 2.1.** 在左图中，一个虚拟相机位于锥体的顶端（四条线汇合处）。只有视景体内的图元会被渲染。对于以透视方式渲染的图像（此处就是这种情况），视景体为视锥体（frustum ，复数 ：frusta），即具有矩形底面的截顶锥体。右图显示了相机所 “看到” 的内容。请注意，左图中的红色甜甜圈形状物体不在右图中，因为它位于视锥体外部。左图中扭曲的蓝色棱柱也被裁剪于视锥体的顶面上。

我们将解释渲染管线的不同阶段，但重点是功能而不是实现。具体该如何应用这些阶段，将在后面的章节中详细介绍。

## **2.1 体系结构 Architecture**

在现实世界中，管线的概念以许多不同的形式体现出来，从工厂装配线到快餐厨房都有管线存在（译者注：**在现实世界中通常叫流水线，是同一个单词 pipeline，不过为了避免混淆，只使用一种翻译，都会称作 “管线”**）。管线的概念同样也适用于图形渲染领域。一条管线由几个阶段组成 **[715]**，每个阶段执行较大任务的其中一部分。

管线的各阶段是并行执行的，每个阶段都取决于上一阶段的结果。理想情况下，将非管线系统划分为 n 个管线阶段，可以使速度提高 n 倍。因此提升性能是使用管线的主要原因。举个例子，三个人以管线方式工作，快速制作大量的三明治：第一个准备面包，第二个加肉，第三个加佐料。每个人都将完成后的结果传递给下一个人，并立即开始处理下一个三明治。如果每个人都是花 20 秒执行他所在阶段的任务，那么每 20 秒就可以制作 1 个三明治，一分钟就能做 3 个三明治。管线的各阶段是并行执行的，但是如果最慢的阶段没有完成，其对应的下一个阶段就会等待。举个例子，假设情况有变，三明治的加肉阶段变得更加复杂，耗时变为 30 秒。那么整个三明治生产管线可以达到的最快速度就是每分钟 2 个三明治。那么对于这个管线来说，加肉阶段就是它的瓶颈（bottleneck），因为它决定了整个管线的生产速度。由于加肉阶段耗时较多，加佐料阶段必须等待加肉阶段完成才能继续工作，就这么干等着，顾客此时大概已经在挨饿了。

在实时计算机图形的领域中也可以找到这种管线构造。实时渲染管线（real-time rendering pipeline）大致分为四个主要阶段：应用程序阶段（application），几何处理阶段（geometry processing），光栅化阶段（rasterization）和像素处理阶段（pixel processing），如图 2.2 所示。这种结构是渲染管线的核心，它是实时计算机图形实际应用程序中所使用的，因此是后续各章讨论的重要基础。

![](<images/1685518836211.png>)

**图 2.2.** 渲染管线的基本构造包括四个阶段：应用程序阶段（application），几何处理阶段（geometry processing），光栅化阶段（rasterization）和像素处理阶段（pixel processing）。这些阶段中的每个阶段本身也可以是一条管线，如在几何处理阶段下方所示。这些阶段也可以是（部分的）并行化阶段，如像素处理阶段下方所示。在此示例中，应用程序阶段是单个过程，但是该阶段也可以进行管线化或并行化。需要注意的是，光栅化阶段可以调用到图元（如三角形）内部的像素。

这些阶段中的每个阶段通常本身就是一条管线，这意味着它会由几个子阶段组成。在这里我们要注意一下显示的功能阶段（functional stages）和其实现的结构（structure of implementation）之间的区别。功能阶段（a functional stage）具有要执行的特定任务，但没有指定在管线中执行任务的方式。给定的实现（a given implementation）可以将两个功能阶段组合到一个单元中，或着也可使用可编程内核执行，同时将另一个耗时的功能阶段划分为几个硬件单元。

渲染速度可以表示为每秒帧数（FPS），即每秒渲染的图像个数。也可以使用赫兹（Hz）来表示，它是单位 1 / 秒 的一种表示方法，即更新频率。我们通常也只列出渲染图像所花费的时间，以毫秒（ms）为单位。生成图像所花费的时间通常会有所不同，具体取决于每帧中执行计算的复杂度。每秒帧数（FPS）用于表示特定的帧速率，或表示在使用期间的平均性能。赫兹用于描述硬件的固定速率设置，例如显示器刷新率。

顾名思义，应用程序阶段（application）由应用程序驱动，因此通常由在通用 CPU 上运行的软件实现。这些 CPU 通常包括多个内核，这些内核能够并行处理多个线程。这使 CPU 可以有效地运行应用程序阶段负责的各种任务。传统上通常在 CPU 执行包括碰撞检测、全局加速算法、动画、物理模拟还有许多其他任务，任务具体取决于应用程序的类型。

下一个主要阶段是几何处理阶段（geometry processing），此阶段会处理变换，投影以及所有其他类型的几何处理。另外，此阶段会计算所需要绘制的内容，并判断应如何绘制以及应在何处绘制。几何处理阶段通常在包含许多可编程内核以及固定操作硬件的图形处理单元（GPU）上执行。光栅化阶段（rasterization）通常会依次将三个顶点输入，形成三角形，然后找到该三角形内所有需要计算的像素，将它们发送到下一个阶段。像素处理阶段（pixel processing）为每个像素执行一段程序以确定其颜色，并可以进行深度测试，以判断该像素是否可见。它还可以对每个像素进行操作，例如将新计算的颜色与之前的颜色混合。光栅化和像素处理阶段都是完全在 GPU 上进行处理。所有这些阶段及其内部管线将在接下来的四个小节中详细讨论。有关 GPU 如何处理这些阶段的更多详细信息，请参阅第 3 章。

**引用：**

**[715]** Hennessy, John L., and David A. Patterson, Computer Architecture: A Quantitative Approach, Fifth Edition, Morgan Kaufmann, 2011. Cited on p. 12, 30, 783, 789, 867, 1007, 1040

## **2.2** 应用程序阶段 **The Application Stage**

因为应用程序阶段通常在 CPU 上执行，所以开发者可以完全控制该阶段所发生的事情。因此，开发者可以完全掌控该阶段的具体实现，并且可以在之后对它进行修改以提高性能表现。另外，此处的修改也会影响后续阶段的性能表现。例如使用合适的算法或设置就可以减少所需渲染的三角形的数量。

综上所述，某些应用程序工作可以由 GPU 执行，使用一种被称为计算着色器（compute shader）的单独模式。此模式会将 GPU 视为高度并行的通用处理器，而忽略它专门用于渲染图形的特殊功能。

在应用程序阶段结束时，要渲染的几何图形被移交到几何处理阶段。这些几何图形就是之前提到的渲染图元（primitives），即点，线和三角形，它们最终会出现在屏幕上（或其他的输出设备）。这是应用程序阶段最重要的任务。

因为此阶段是基于软件的实现，所以它不像几何处理阶段、光栅化阶段和像素处理阶段**（1）**那样能够划分为多个子阶段（从而提升处理效率）。但是，为了提高性能表现，应用程序阶段通常会在多个处理器核心上并行执行。在 CPU 设计中，这被称为超标量构造（superscalar construction），因为它能在同一阶段同时执行多个进程。第 18.5 节介绍了使用多个处理器内核的各种方法。

应用程序阶段还会执行碰撞检测（collision detection）。在两个物体之间检测到碰撞之后，会生成响应并将其发送回碰撞的物体与力反馈设备。此外，应用程序阶段还会处理外部输入，如键盘、鼠标、头戴式显示器。根据不同的输入，会有不同的动作反馈。一些加速算法，例如特定的剔除算法（第 19 章），也会在此阶段进行实现。另外还有一些管线等其余部分无法处理的事情，也会在应用程序阶段进行处理。

**作者注：**

**(1)** 由于 CPU 本身的流水线规模要小得多，因此可以说应用程序阶段可进一步细分为几个流水线阶段，但这与此处无关。

## **2.3** 几何处理阶段 **Geometry Processing**

GPU 上的几何处理阶段（Geometry Processing）负责大部分的逐三角形和逐顶点的操作。该阶段进一步分为以下功能阶段（functional stages）：顶点着色（vertex shading），投影（projection），裁剪（clipping）和屏幕映射（screen mapping）（图 2.3）。

![](<images/1685518836293.png>)

**图 2.3.** 几何处理阶段中的功能阶段管线。

### **2.3.1 顶点着色 Vertex Shading**

顶点着色 (Vertex Shading) 有两个主要任务，一是计算顶点位置，二是评估程序员可能希望作为顶点数据输出的任何东西，如法线和纹理坐标。传统上，对象的大部分着色过程是这样的：将光源应用于每个顶点的位置和法线，计算出每个顶点的颜色，然后将这些颜色插值到整个三角形上。因此，这个可编程的顶点处理单元被称为顶点着色器（vertex shader）**[1049]**。随着现代 GPU 的出现，一些，甚至所有的着色任务都会去逐像素地进行，因此顶点着色阶段变得更加通用，已经不常会去计算任何着色方程，当然具体做法会取决于程序员的意图。如今顶点着色器是一个更加通用的单元，专用于设置与每个顶点相关的数据。例如，顶点着色器可以使用第 4.4 节和第 4.5 节中的方法对对象进行动画处理。

我们从描述如何计算顶点位置开始，顶点位置是我们始终需要的一组坐标。模型在顶点着色阶段会经过一系列不同的坐标和空间变换。最初，模型在自身的模型空间（model space）中，这表示该模型没有进行变换。每个模型都可以进行模型变换（model transform），用于调整其位置与方向。单个模型可以关联多个模型变换的操作。这就允许同一模型的多个副本（称为实例，instance）在同一场景中具有不同的位置，方向和大小，而无需去复制基本几何图形。

模型变换中所变换的是模型的顶点和法线。变换前，对象的坐标称为模型坐标（model coordinates），这些坐标经过模型变换后，就可以说模型位于世界坐标（world coordinates）或世界空间（world space）中。世界空间是唯一的，在对模型进行了各自的模型变换后，所有模型都存在于该同一空间中。

前面有提到，只有相机（或观察者）看到的模型才会被渲染。相机在世界空间中是有位置与朝向数据的，这些数据用于放置和对准相机。为了便于投影和裁剪，相机和所有模型都会进行观察变换（view transform）。观察变换的目的是将相机放置在原点并将其对准目标，使其沿负 z 轴方向看，y 轴指向上方，x 轴指向右侧。我们使用 -z 轴约定； 有些书籍会更偏向使用 +z 轴。区别主要是语义上的，因此彼此之间的转换很简单。应用观察变换后的实际位置和方向取决于底层应用程序编程接口（API）。如此划定的空间称为相机空间（camera space），或更普遍地称为观察空间（view space）或眼空间（eye space）。观察变换影响相机和模型的方式示例如图 2.4 所示。模型变换和观察变换的操作都可以用 4×4 矩阵进行计算，这是第 4 章的主题。但是，重要的是要认识到——可以用程序员喜欢的任何方式来计算顶点的位置和法线。

![](<images/1685518836401.png>)

**图 2.4.** 左边的俯视图显示了在 +z 轴朝上的世界中，用户自定义摆放的相机。观察变换可使世界重定向，以使相机位于其原点，沿其负 z 轴看，而相机的 +y 轴朝上，如右图所示。这样做是为了使裁剪（clipping）和投影（projection）操作更简单，更快捷。浅蓝色区域是视景体（view volume）。因为视景体即为视锥体（frustum），所以这里假定为透视视图。类似的技术适用于任何类型的投影。

接下来，我们描述来自顶点着色的第二种输出。为了制造一个真实的场景，仅渲染对象的形状和位置是不够的，还必须对它们的外观表现进行数学建模。 此描述包括每个对象的材质，以及任意光源照射在该对象上的效果。材质和灯光可以采用多种方式进行数学建模，包括从简单的颜色到物理描述的详尽表示。

这种确定光照在某种材质上产生的具体效果的过程，我们称之为着色 (shading)。它包括了在各种模型顶点上计算着色方程的过程。通常，其中一些计算是在模型顶点的几何处理阶段（geometry processing）执行的，而其他一些计算可在逐像素处理阶段（per-pixel processing）执行。我们可以在每个顶点存储各种材质数据，例如点的位置，法线，颜色或计算着色方程所需的任何其他数值信息。然后将顶点着色结果（可以是颜色，向量，纹理坐标以及任何其他种类的着色数据）发送到光栅化阶段和像素处理阶段以进行插值，并用于计算表面的着色。

在本书中，尤其是在第 3 章和第 5 章，将更深入地讨论 GPU 顶点着色器形式的顶点着色。

作为顶点着色的一部分，渲染系统先进行投影变换，然后进行裁剪，这会将视景体（View Volume）变换为单位立方体（a unit cube），其极点位于（-1，-1，-1）和（1、1、1）。我们可以定义相同体积的不同范围，例如 0 ≤ z ≤ 1。此单位立方称为规范视景体（the canonical view volume）。投影是最先完成的，并且在 GPU 上它是由顶点着色器完成。有两种常用的投影方法，即正交投影（orthographic，也称为平行投影，parallel）和透视投影（perspective）。参见图 2.5。事实上，正交投影只是平行投影的一种。还有一些其他投影在建筑领域会特别用到，例如斜投影（oblique）和轴测投影（axonometric）。有一个老的街机游戏 Zaxxon 的名字就来源于后者。

![](<images/1685518836483.png>)

**图 2.5.** 左边是正交投影或平行投影； 右边是透视投影。

请注意，投影操作可以表示为矩阵（第 4.7 节），因此有时可以将它与其余的几何变换连接在一起。

正交视图的视景体（view volume）通常是一个矩形框，而正交投影会将此视景体变换为单位立方体。正交投影的主要特征是平行线在变换后仍然保持平行。这种变换是平移和缩放的组合。

透视投影就有点复杂了，在这种投影中，物体离相机越远，投影后它就越小。另外，平行线会在地平线上汇聚。因此透视变换实际上是模仿我们人类感知物体尺寸的方式。从几何学上来说，视景体，又称视锥体（frustum），是具有矩形底面的截顶锥体。视锥体也将变换为单位立方体。正交变换和透视变换都可以使用 4×4 矩阵来构造（第 4 章），并且在进行两者中任一变换之后，我们都将模型所处坐标称为裁剪坐标（clip coordinates）。这些坐标实际上是齐次坐标（homogeneous coordinates），我们将在第 4 章中进行讨论，所以我们可以知道此操作发生在用 w 做除法之前。GPU 的顶点着色器必须始终输出此类型的坐标，以使下一个功能阶段——裁剪（clipping）能够正常工作。

尽管这些矩阵似乎只是将一个几何体变换为另一个几何体，但是它们被称作投影，因为在显示之后，z 坐标不会存储在生成的图像中，而是存储在 z 缓冲区中，正如第 2.5 节 所述。这样下来，模型就从三维投影到二维了。

**引用：**

**[1049]** Lindholm, Erik, Mark Kilgard, and Henry Moreton, “A User-Programmable Vertex Engine,” in SIGGRAPH ’01 Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques, ACM, pp. 149–158, Aug. 2001. Cited on p. 15, 38

### **2.3.2 可选顶点处理 Optional Vertex Processing**

每个管线都有刚才所描述的顶点处理过程。完成此处理后，在 GPU 上可以按照以下顺序进行几个可选阶段：曲面细分（tessellation），几何着色（geometry shading）和流输出（stream output）。它们取决于硬件的能力——并非所有 GPU 都具有这些可选功能——也取决于程序员的意图。它们彼此独立，并且一般来说不常用。 在第 3 章中将对每一项进行更多说明。

第一个可选阶段是曲面细分（tessellation）。假设你有一个弹跳的球体。如果直接用一组三角形表示它，则可能会遇到质量或性能问题。你的球体从 5 米远处看起来可能不错，似乎是光滑曲面，但近距离就可以清晰地看到组成球体的各个三角形，尤其是沿着轮廓的三角形。如果用更多的三角形制作球体以提高质量，则当球体太远且仅会覆盖屏幕上的几个像素时，可能会浪费大量的处理时间和内存。此时通过曲面细分，就可以生成具有适当数量的三角形的曲面。

我们已经讨论了一些三角形，但是到目前为止，在管线中我们只处理了顶点。这些顶点可用来表示点、线、三角形或其他对象。顶点可用于描述曲面，例如球体。这样的表面可以由一组面片来指定，其中每个面片由一组顶点组成。曲面细分阶段本身包含一系列阶段——外壳着色器阶段（Hull Shader Stage），细分阶段 (Tesselation Stage) 和域着色器阶段（Domain Shader Stage），这些阶段将这些面片的顶点集合转换为（通常是）更大的顶点集合，然后用于创建新的三角形集合。场景相机会动态地确定要生成多少个三角形：面片靠近时会产生很多三角形，面片很远时会产生很少的三角形。

下一个可选阶段是几何着色器（geometry shader）。该着色器的诞生早于曲面细分着色器，因此在 GPU 上更常见。就像曲面细分着色器一样，它可以读取各种图元并可以产生新的顶点。这是一个非常简单的阶段，因为此阶段不仅是创建的范围受到限制，而且输出图元的类型也受到了更多的限制。几何着色器有多种用途，其中最广泛使用的一种是粒子生成。想象一下模拟烟花爆炸吧。每个火球都可以由一个点（point），即单个顶点（vertex）来表示。几何着色器可以获取每个点并将其变成正方形（由两个三角形组成），这个正方形面向观察者并且覆盖多个像素，从而为我们提供了视觉上更可信的图元以进行着色。

最后一个可选阶段称为流输出（stream output）。在此阶段，我们可以将 GPU 当做几何引擎使用。此时，我们可以选择将其输出到数组以进行进一步处理，而不是将处理后的顶点向下发送到那些需要渲染到屏幕的其余管线中。这些数据可以在以后的过程中由 CPU 或 GPU 本身使用。此阶段通常用于粒子模拟，例如我们的烟花案例。

这三个阶段按此顺序执行——细分，几何体着色和流输出，并且每个阶段都是可选的。不管使用哪个（如果有的话）选项，如果我们继续沿管线向前移动，我们都会得到一组具有齐次坐标的顶点，之后我们将检查它们在相机中是否可见。

### **2.3.3 裁剪 Clipping**

只有那些全部或部分位于视景体（view volume）内的图元（primitives）才需要传递到光栅化阶段（以及随后的像素处理阶段），然后将其绘制在屏幕上。完全位于视景体内的图元将保持原样并传递到下一个阶段。完全不在视景体之内的图元不会进一步传递，因为它们不会被渲染。部分位于视景体内的图元只需要裁剪后的那部分。举个例子，在视景体内有一条线段，线段的一个顶点在视景体外部，那么这条线段就应该相对于视景体进行裁剪，以便将外部顶点替换为位于该线段和视景体交点处的新顶点。投影矩阵的使用意味着将变换后的图元裁剪到单位立方体上。在裁剪之前执行观察变换和投影变换的优点是可以使它们的裁剪问题保持一致，同时进行；另外的优点是，图元总是被裁剪到单位立方体上。

裁剪过程如图 2.6 所示。除了视景体的六个裁剪平面之外，用户还可以定义其他的裁剪平面以可视方式裁剪对象。这种可视化的操作被称作切片（sectioning），见第 818 页的图 19.1。

![](<images/1685518836632.png>)

**图 2.6.** 投影变换后，只有单位立方体内的图元（对应视锥体内的图元）需要进行后续处理。因此，单位立方体外部的图元将被丢弃，完全位于内部的图元将被保留。与单位立方体相交的图元将被裁剪到单位立方体上，并且因此生成新的顶点，丢弃旧的顶点。

裁剪步骤使用投影产生的 4 值齐次坐标执行裁剪。在透视空间中，值通常不会跨单个三角形进行线性插值。我们需要第四个坐标，以便在使用透视投影时能够正确地进行插值和裁剪。最后，执行透视划分（perspective division），将所得三角形的位置放入三维归一化的设备坐标中（three-dimensional normalized device coordinates）。正如之前提到的，此视景体的范围是从（-1，-1，-1）到（1、1、1）。几何阶段的最后一步是从该空间转换为窗口坐标（window coordinates）。

### **2.3.4 屏幕映射 Screen Mapping**

只有视景体内的（裁剪）图元会被传递到屏幕映射阶段（screen mapping stage），并且当进入该阶段时坐标仍然是三维的。每个图元的 x 坐标和 y 坐标都将转换为屏幕坐标（screen coordinates）。屏幕坐标和 z 坐标也称为窗口坐标（window coordinates）。假设场景应被渲染到窗口中，窗口边角坐标最小在（x1，y1）处，最大在（x2，y2）处，其中 x1 <x2 并且 y1 < y2。然后，进行屏幕映射，即一个平移操作后接一个缩放操作。得出的新的 x 和 y 坐标被称为屏幕坐标。z 坐标（OpenGL 中为 [−1，+1]，DirectX 中为 [0，1]）也映射到 [z1，z2]，其中 z1 = 0 和 z2 = 1 作为默认值。但是这些是可以使用 API 进行更改的。之后窗口坐标以及这个重新映射的 z 值将传递到光栅化阶段。屏幕映射的过程如图 2.7 所示。

![](<images/1685518836712.png>)

**图 2.7.**  图元位于投影变换后的单位立方体中，屏幕映射过程负责在屏幕上找到相应坐标。

接下来，我们将描述整数、浮点值与像素（以及纹理坐标）的关系。给定一个水平像素数组并使用笛卡尔坐标系，那么最左像素的左边缘在浮点坐标系中为 0.0。OpenGL 一直使用此方案，DirectX 10 及其后续版本使用此方案。 该最左像素的中心为 0.5。 因此，像素 [0，9] 的范围覆盖了 [0.0，10.0）的范围。这个转换很简单：

![](<images/1685518836785.png>)

![](<images/1685518837526.png>)

其中 

![](<images/1685518838268.png>)

 是像素的离散（整数）索引，

![](<images/1685518839990.png>)

 是像素内的连续（浮点）值。

尽管所有 API 的像素位置值都是从左到右增加的，但是在某些情况下，OpenGL 和 DirectX**（2）**中上下边缘的零的位置不一致。整个 OpenGL 都偏爱笛卡尔系统，将左下角视为最小值，而 DirectX 有时会根据上下文将左上角定义为最小值。这两种方式都有逻辑可循，两者间并没有正确答案。举个例子，（0，0）位于 OpenGL 中图像的左下角，而在 DirectX 中则位于左上角。 因此，当我们从一个 API 迁移到另一个 API 时，必须考虑到这一差异。

**作者注：**

**(2)** “Direct3D”是 DirectX 的三维图形 API 组件。DirectX 包括其他 API 元素，例如输入和音频控件。除了在指定特定版本时编写 “ DirectX” 和在讨论该特定 API 时编写 “ Direct3D” 之间，我们没有区别，而是通篇编写 “ DirectX” 来遵循常用用法。

**P11**

depicted  v.    描绘; 描述; 

characteristics  n.    特征; 特点; 品质;

View Volume，视景体，可视区域，有时候叫做 View Frustum，也就是视锥体。

注：OpenGL 技术之 View Volume, Viewport, Screen 的关系

[https://blog.csdn.net/fu_shuwu/article/details/73065528](https://blog.csdn.net/fu_shuwu/article/details/73065528)

truncated  adj.    (版本) 缩减的，删节的，截短了的;

**P12**

implementation  n.    执行，履行; 工具；仪器；

manifest   v.    表明; 显现; 使人注意到; 

parallel adj.    平行的;  同时发生的;  并行的;

stalled  v.    (使) 熄火，抛锚; 故意拖延;

coarse  adj. 粗糙的; 大颗粒的;

division n. 分开; 分隔; 分配;

Application 应用阶段

Geometry Processing 几何阶段

Rasterization 光栅化阶段

Pixel Processing 像素（片元）阶段

pipelined 流水线化; 流水线; 管线化; 管道化; 管道式;

parallelized 并行; 规模并行; 平行放置;

**P13**

subsequent   adj.    随后的; 后来的; 之后的; 接后的;

specify  v. 具体说明; 明确规定; 详述; 详列;

divides  v.    (使) 分开，分散，分割，分成…;

as the name implies 顾名思义;

**P14**

All this said 所有这些都说明

superscalar 超标量（处理器结构）详见 [https://www.jianshu.com/p/36c80a15a226](https://www.jianshu.com/p/36c80a15a226) 处理器结构 --PipeLine&SuperScalar

implemented  v. 使生效; 贯彻; 执行; 实施;

**P15**

intent n. 意图

replication  n. (绘画等的) 复制; 拷贝; 重复 (实验); (尤指对答辩的) 回答;

vertices  n.(三角形或锥形的) 角顶; 顶点; 至高点;

respective  adj. 分别的; 各自的;

facilitate  v. 促进; 促使; 使便利;

convention n.    习俗; 常规; 惯例; 

semantic  adj.    语义的;

delineated  v.    (详细地) 描述，描画，解释;

matrices matrix 的复数; 矩阵;

**P16**

reorient 重定向

assumed v. 呈现 (外观、样子); 显露 (特征);

be modeled 被模型化 (描述)

elaborate  adj.    复杂的; 详尽的; 精心制作的;

Canonical View Volume 规则观察体

Orthographic Projection 正交投影

Perspective Projection 透视投影

Oblique Projection 斜投影 

Axonometric Projection 轴侧投影

concatenated with 连接到

converge v. 汇集; 聚集; 集中;

perceive v.    注意到; 意识到; 察觉到; 

homogenous adj. 同种类的; 同性质的; 由相同成分 (或部分) 组成的; 同 homogeneous;