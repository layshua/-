# 3.1.1 StencilTest 模板测试
## （1）理解概念
### 1. 引例
![[Pasted image 20221030224512.png]]
-   左图为颜色缓冲区中的一张图，在模板缓冲区中我们会给这张图的每一个片元分配一个0-255的数字（8位，默认为0）
-   中、右图可以看到，我们修改了一些0为1，通过自定义的一些准则，如输出模板缓冲区中1对应的片元的颜色；0的不输出，最后通过模板测试的结果就如右图所示。
### 2.通过模板测试的应用，实现的效果举例

-   ①传送门效果：可以看到左边传送门内的景象正是右侧的场景
![[Pasted image 20221030224810.png]]
-   ②Minions讲解的一些效果，例如3D卡牌效果、侦探镜效果等
- -   大佬链接：[https://www.patreon.com/posts/14832618](https://www.patreon.com/posts/14832618)

![[1.gif|200]]
![[1 1.gif|200]]
![[1 2.gif|200]]
![[1 3.gif|200]]
-   ③每个正方体面显示不同场景（每个面作为蒙版来显示场景）
 《笼中窥梦》游戏场景：
 ![[y7Tcu-l8zuwKKGkVacX8qg.gif]]
 ![[bvS1V1NTiLs9k5UHIqnUUw.gif]]
### 3.理解

-   对于上述的例子总结一下，这些效果基本可以归结为三层组成
-   以②中的图4传送门为例子，三层分别对应：门外场景、门内场景、门
-   也就是说可以理解为：包括两层物体/场景、和一层遮罩
## （2）什么是模板测试

### 1.从渲染管线理解

-   下图为从片元着色器到FrameBuffer的流程（逐片元操作）
![[Pasted image 20221030230400.png]]
-   **逐片元操作流程：**
![[Pasted image 20221030230409.jpg]]

-   可以看到逐片元的流程依次为
-   **像素所有权测试→裁剪测试→透明度测试→模板测试→深度测试→透明度混合**

-   **PixelOwnershipTest（像素所有权测试）：**
-   简单来说就是控制当前屏幕像素的使用权限
-   举例：比如unity引擎中仅渲染scene和game窗口，即只对scene和game窗口部分的像素具有使用权限

-   **ScissorTest（裁剪测试）：**
-   在渲染窗口再定义要渲染哪一部分，默认全部渲染，可以自己控制。
-   和裁剪空间一起理解，也就是只渲染能看到的部分
-   举例：只渲染窗口的左下角部分

-   **AlphaTest（透明度测试）**
-   提前设置一个透明度阈值
-   只能实现不透明效果和全透明效果
-  举例：设置透明度a为0.5，如果片元大于这个值就通过测试，如果小于0.5就剔除掉

-   **StencilTest（模板测试）**

-   **DepthTest（深度测试）**

-   **Blending（透明度混合）**
-   可以实现半透明效果

-   完成接下来的其他一系列操作后，我们会将合格的片元/像素输出到**帧缓冲区（FrameBuffer）**，最后渲染到屏幕上。


-   **逐片元操作是可以配置但不可编程的**（对应图中为黄色背景），也就是说是由管线/硬件自身规定好的，我们只能对里边的内容进行配置。
### 2.从逻辑上理解
![[Pasted image 20221030230942.png]]
-   理解：
-   **referenceValue**：当前模板缓冲片元的参考值（0~255）
-   **&readMask**：与读掩码做一个“与”操作
-   **stencilBufferValue**：模板缓冲区里的值，初始为0
-   中间**comparisonFunction**，就是做一个比较

-   结果：
-   如果通过，这个片元就进入下一个阶段
-   未通过/抛弃，停止并且不会进入下一个阶段，也就是说不会进入颜色缓冲区

-   总结：就是**通过一定条件来判断这个片元/片元属性执行保留还是抛弃**的操作
- 
### 3.从书面概念上理解

**模板缓冲区-FrameBuffer**

-   模板缓冲区与颜色缓冲区和深度缓冲区类似，模板缓冲区可以为屏幕上的每一个像素点保存一个无符号整数值（通常为8位int，0-255）。
-   这个值的意义根据程序的具体应用而定。

**模板测试**

-   渲染过程中，可以用这个值与预先设定好的参考值作（ReferenceValue）比较，根据结果来决定是否更新相应的像素点的颜色值。
-   这个比较的过程就称为**模板测试**。
-   模板测试在**透明度测试之后**，**深度测试之前**。
-   如果模板测试通过，相应的像素点更新，否则不更新。

## （3）基本原理和使用方法
### 1. 语法表示/结构解释
![[Pasted image 20221030231544.png]]
-   **Ref**：当前片元的参考值（0-255）referenceValue
-   **ReadMask**：读掩码
-   **WriteMask**：写掩码
-   **Comp**：比较操作函数
-   **Pass**：测试通过，之后进行操作（StencilOperation，后边有详细讲解）
-   **Fail**：测试未通过，也会进行一个操作
-   **ZFail：** 模板测试通过，深度测试未通过，也可以进行一个操作

### 2. ComparisonFunction

-   我们可以根据需求配置
![[Pasted image 20221030231708.png]]

### 3.StencilOperation 更新值

-   有不同的更新操作，根据自己的需求进行配置
-![[Pasted image 20221030231720.png]]
## （4）案例
### 案例一：卡牌效果

-   **注：Unity中模板缓冲区默认都是0**
ID都为0时，即unity默认的显示效果：
![[Pasted image 20221031161931.png|300]]
Mask 和 Texture的ID都设置为1：
![[Pasted image 20221031155916.png|300]]
![[Pasted image 20221031160105.png|300]]
思路：蒙版Ref[_ID]设置为1，Texture的Ref[_ID]也设置为1，这样可以显示与蒙版重叠的部分，其余部分都剔除。

![[kapai.gif]]
**以下为案例shader，重点在于Stencil部分的设置，其余部分就是按正常shader来写，对于3d模型计算一下光照**
#### ①蒙版Mask的shader
```less
//蒙版，ID设置为1，将外面东西全部剔除
Shader "Unlit/StencilMask"
{
    Properties
    {
        _ID ("Mask ID", Int) = 1
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" "Queue" = "Geometry+1" }
        ColorMask 0 //0：什么都不显示，全透明
        //ColorMask RGBA  //四个通道全部输出，其他可选RGB、R、G、B、0
        Zwrite off
        
        Stencil
        {
            Ref[_ID]
            Comp always //默认always
            Pass replace //replace：通过就把模板缓冲区的值替换成我们的ID值，默认keep
            
            //其他不写的选项默认Keep
            //Fail Keep
            //ZFail keep
        }
        LOD 100

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag

            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
            };

            struct v2f
            {
                float4 pos : SV_POSITION;
            };

            v2f vert (appdata v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                return float4(1,1,1,1); //随便给一个颜色，因为ColorMask为0，不会输出颜色
            }
            ENDCG
        }
    }
}

```
#### ②被遮挡物体的shader
```less
//被遮挡物体 
Shader "Unlit/TextureMasked"  
{  
    Properties  
    {  
        _MainTex("BaseColor",2D) = "white"{}  
        _ID ("Mask ID", Int) = 1  
    }  
    SubShader  
    {  
        //在Mask之后渲染，队列次序比Mask高  
        Tags { "RenderType"="Opaque" "Queue" = "Geometry+2" }  
          
        Stencil  
        {  
            Ref[_ID]  
            Comp equal  //索引值和当前模板缓冲区中的值一致时才会被绘制  
        }  
        LOD 100  
  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
  
            #include "UnityCG.cginc"  
  
            struct appdata  
            {  
                float4 vertex : POSITION;  
                float2 uv : TEXCOORD0;  
            };  
  
            struct v2f  
            {  
                float4 pos : SV_POSITION;  
                float2 uv : TEXCOORD0;  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
  
            v2f vert (appdata v)  
            {  
                v2f o;  
                o.uv = v.uv;  
                o.pos = UnityObjectToClipPos(v.vertex);  
                return o;  
            }  
  
            fixed4 frag (v2f i) : SV_Target  
            {  
                float4 BaseColor = tex2D(_MainTex, i.uv);  
                return BaseColor;   
            }  
            ENDCG  
        }  
    }  
    FallBack "Diffuse"  
}

```
#### ③完善卡牌效果
**分离前后Mask：**
MainTex的A通道是一个Mask，将正反面分离以定制正反面的不同效果，比如单独加Fresnel
![[Pasted image 20221031170431.png|300]]
![[Pasted image 20221031170405.png]]
### 案例二： 盒子不同面显示不同场景
 ![[bvS1V1NTiLs9k5UHIqnUUw.gif]]
 -   和卡牌效果类似，一个用蒙版遮罩的物体，盒子每个面使用一个蒙版遮罩
-   同样利用默认的值为0来做，只是面多了，蒙版和里边显示的物体也多了，ID依次为1、2、3、4
-   总结：一个蒙版对应一个物体，他们使用相同的ID，出来的效果就是：每个面显示的盒子内部物理不同

## （5）总结
-   **最重要(用来比较的）两个值**：
-   **当前模板缓冲区值（StencilBufferValue）**、**模板参考值（ReferenceValue）**

-   模板测试主要就是对这两个值进行特定的比较操作，例如Never、Always、Equal等，具体参考上文的表格

-   模板测试后要对模板缓冲区的值进行更新操作，例如Keep，Replace等，具体参考上文表格

- 模板测试之后可以根据结果对模板缓冲区做不同的更新操作，例如模板测试成功操作Pass、模板测试失败操作Fail、深度测试失败操作ZFail、还有正对正面和背面精确更新操作Passback，Passfront，Failback等...

属性中使用一个内置的枚举，这样就可以在外边自己选择可配置的属性了
 ![[Pasted image 20221031163235.png]]
## （6） 拓展
 ![[Pasted image 20221031163637.png]]
[(3条消息) Unity Shader: 理解Stencil buffer并将它用于一些实战案例（描边，多边形填充，反射区域限定，阴影体shadow volume阴影渲染）_liu_if_else的博客-CSDN博客](https://blog.csdn.net/liu_if_else/article/details/86316361)
### 描边
![[Pasted image 20221031201004.png|300]]
```less
Shader "Unlit/outline"
{
    Properties
    {
        _MainTex ("Texture", 2D) = "white" {}
        [HDR]_EdgeColor("EdgeColor",Color) = (1,1,1,1)
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" }
        LOD 100
        
        Stencil
        {
            Ref 0
            Comp Equal
            Pass IncrSat //通过则stencilBufferValue加1
            Fail Keep    //保留当前缓冲区中的内容，即stencilBUfferValue不变
        }
        
        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 pos : SV_POSITION;
            };

            sampler2D _MainTex;
            float4 _MainTex_ST;
            
            v2f vert (appdata v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);
                UNITY_TRANSFER_FOG(o,o.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                fixed4 col = tex2D(_MainTex, i.uv);
                return col;
            }
            ENDCG
        }
        // 第二个pass 描边
        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            
            #include "UnityCG.cginc"

            struct appdata
            {
                float4 vertex : POSITION;
                float4 normal : NORMAL;
                float2 uv : TEXCOORD0;
            };

            struct v2f
            {
                float2 uv : TEXCOORD0;
                float4 pos : SV_POSITION;
            };

            float4 _EdgeColor;
            
            v2f vert (appdata v)
            {
                v2f o;
                o.pos = UnityObjectToClipPos(v.vertex + normalize(v.normal)*0.01f);
                o.uv = v.uv;
                UNITY_TRANSFER_FOG(o,o.vertex);
                return o;
            }

            fixed4 frag (v2f i) : SV_Target
            {
                return _EdgeColor;
            }
            ENDCG
        }
    }
}


```
buffer的值在当前帧结束前是不清除的，所以它可以跨越不同的shader与pass。Stencil结构写在Subshader中，那么下面的所有pass中的stencil test都按此运行。理想环境下，第一个pass渲染前屏幕上所有像素的stencil值都是0，在该pass的fragment shader结束后，所有进行了渲染的像素都通过了Ref 0和Comp Equal的测试，并执行Pass IncrSat将stencil值加1。
第二个pass中，将顶点进行进行了放大。进行同样的stencil测试，上一个pass渲染过的像素stencil值已经变为1，无法通过Ref 0+Comp Equal测试，那么现在只会在放大后的既是stencil值仍然为0的区域进行渲染。
最后对对第二个pass通过测试的像素给予描边颜色。
## （7）参考资料

-   官方文档：[https://docs.unity3d.com/Manual/SL-Stencil.html](https://docs.unity3d.com/Manual/SL-Stencil.html)
-   [https://blog.csdn.net/u011047171/article/details/46928463](https://blog.csdn.net/u011047171/article/details/46928463)
-   [https://blog.csdn.net/liu_if_else/article/details/86316361](https://blog.csdn.net/liu_if_else/article/details/86316361)
-   [https://gameinstitute.qq.com/community/detail/127404](https://gameinstitute.qq.com/community/detail/127404)
-   [https://learnopengl-cn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/02%20Stencil%20testing/](https://learnopengl-cn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/02%20Stencil%20testing/)
-   [https://www.patreon.com/posts/14832618](https://www.patreon.com/posts/14832618)
-   [https://www.udemy.com/course/unity-shaders/](https://www.udemy.com/course/unity-shaders/)

# 3.1.2 深度测试
![[Pasted image 20221031204347.png]]
## 一、什么是深度测试

-   帮助我们处理物体的遮挡关系
### 1. 从渲染管线理解

-   ![[59e936613d6e957a313031be895df47d_MD5.jpeg]]
-   深度测试同样位于**逐片元操作过程**中，在**模板测试之后**，**透明度混合之前**。
### 2. 从逻辑上理解
深度缓冲：
![[Pasted image 20221031203329.png]]
颜色缓冲：
![[Pasted image 20221031203332.png]]
-   **理解：**

-   和模板测试差不多，都是通过一个比较来判断一系列操作
-   图1：
-   开启深度写入，当前深度值和深度缓冲区的值作比较，如果通过就写入深度，不通过就忽略深度

-   图2：
-   当前深度值和深度缓冲区中的值做比较，如果通过就写入颜色缓冲区，不通过就不写入颜色缓冲区

### 3. 从书面概念上理解

-   **深度测试的概念**

-   就是针对当前屏幕上（更准确的说是**FrameBuffer（帧缓冲区）**）对应的像素点，将对象自身的深度值与当前深度缓冲区的深度值做比较，如果通过了，这个对象在该像素点才会将颜色写入颜色缓冲区。

### 4. 从发展上看
-   ![[58a9ae0fb86496f5c18efc1ebd30bc99_MD5.svg]]
-   我们要渲染一个场景的话，通常会有多个物体。
-   首先要**控制渲染顺序**

-   画家算法：
-   这里是指油画的画法，也就是画一幅油画，是从远处开始画，然后近处的东西一点点叠加在上面（GAMES系列的课提到过多次）
-   存在的问题：例如一列物体，最前面的物体最大，站在正前面看只能看到最前面的物体，这样一来后边的就不用画了，不然就是性能浪费（OverDraw）。

> [!NOTE] 
> OverDraw: 重复渲染同一个像素

-   **Z-Buffer算法：**
-   通过深度缓冲区来控制渲染顺序
-   **控制Z-Buffer对深度的存储**
-   例如：什么时候更新深度缓冲区、什么时候使用深度缓冲区
-   **两个典型的功能：**
-   **Z Test**
-   **Z Write**

-   **控制不同类型物体的渲染顺序**
-   透明物体
-   不透明物体
-   **渲染队列**（很有用的概念，后边会讲）

-   **减少OverDraw
-   Early-Z，一种优化手段，后边会讲
[[第三章 进阶应用#3.5 Early-z和Z-prepass]]
-   Z-cull（优化手段）
-   Z-check（确认正确遮挡关系）

## 二、基本原理和使用方法
### 1.Z-Buffer（深度缓冲区）

-   和颜色缓冲区一样，在每个片段中存储了信息，并且通常和颜色缓冲有着一样的宽度和高度。深度缓冲是由窗口系统自动创建的，它会以16、24、32位float形式存储深度值。**大部分系统中深度值是24位的**，另外8位存模板缓冲。

> [!NOTE] 颜色缓冲区
> 就是最终在显示屏硬件上显示颜色的GPU显存区域了，这个缓冲区储存了每帧更新后的最终颜色值，图形流水线经过一系列测试，包括片段丢弃、颜色混合等，最终生成的像素颜色值就储存在这里，然后提交给显示硬件显示。

-   **Z-Buffer中存储的是当前的深度信息，对于每个像素存储一个深度值。**
-   我们可以通过Z-Write 、Z-Test来调用Z-Buffer，来达到想要的渲染效果。

### 2. Z Writer（深度写入）

-   深度写入包括两种状态

-   ZWrite On 、 ZWrite Off
-   当我们开启深度写入，物体被渲染时针对物体在屏幕（FrameBuffer）上每个像素的深度都写入到深度缓冲区。
-   关闭深度写入状态，物体的深度就不会写入深度缓冲区。

-   除了ZWrite的是否写入深度缓冲区，更重要的是：是否通过深度测试，也就是Z-Test。如果Z-Test都没通过，也就不会写入深度了。

-   也就是说，**只有ZTest和ZWrite都可行的情况下才写入深度缓冲区**

-   综上，ZWrite有On、Off两种情况；ZTest有通过、不通过两种情况，两者结合的四种情况如下：

**深度测试失败，一定不写入**
 ![[Pasted image 20221031204208.png]]
### 3.Z-Test的比较操作
![[Pasted image 20221031204303.png]]
-   **默认情况下**：

-   Z Write：On
-   Z Test：LEqual

-   深度缓冲区一开始为无穷大
### 4. Unity的渲染队列
-   **Unity内置的几种渲染队列**：
![[Pasted image 20221031204519.png]]
-   **按照渲染顺序从先到后排序，队列数越小，越先渲染；反之同理。**

-   **Unity中设置渲染队列**：

-   语法：Tags { “Queue” = “渲染队列名”}
-   默认是Geometry

-   Unity中**不透明物体的渲染顺序**：从前往后
-   **也就是说深度小的先渲染，其次再渲染深度大的**

-   Unity中**透明物体的渲染顺序**：从后往前（类似画家算法，会造成OverDraw）

-   可以在shader的Inspector面板中查看渲染队列相关属性
![[Pasted image 20221031204940.png]]

### 5. 简述Early-Z技术

-   Early-Z是位于三角形遍历之后、逐片元操作之前的。
-   传统的渲染管线中，ZTest是在Blending阶段，这时进行深度测试的话，所以对象的像素着色器都会计算一遍，没有性能提升，只是为了得到正确的效果，造成了大量 的无用计算。（**深度测试失败的片元是已经经过计算的片元，也就是说：到在一步测试不通过而被抛弃，前边的计算就是无用功了**）
-   为了减少这些不必要的计算，**现代GPU运用了Early-Z技术，在顶点和片元阶段之间（光栅化之后，片元着色器之前）进行一次深度剔除Z-Cull（如下左图黑框部分）**。
![[Pasted image 20221031205146.jpg]]
![[Pasted image 20221031205054.png]]
-   如果这次像素被剔除，那就不用在片元着色器中作无关紧要的计算了，这样一来就会带来性能提升。
-   最终的ZTest仍然要进行，以保证正确的遮挡关系。
-   如右图前一次的Z-Cull是为了裁剪达到性能优化的目的，后一次的Z-check是为了保证正确的遮挡关系。

### 6.深度值
#### 正确的理解深度值的概念

-   首先先了解一下模型在渲染管线中的几次空间变换
![[Pasted image 20221031205336.png]]
-   模型一开始所在的模型空间：**无深度。**
-   通过M矩阵变换到世界空间，此时模型坐标已经变换到了齐次坐标（x，y，z，w）：**深度存在z分量**。
-   通过V矩阵变换到观察空间（摄像机空间）：**深度存在z分量（线性）**
-   通过P矩阵变换到裁剪空间：**深度缓冲中此空间的z/w中（已经变成了非线性的深度）**
-   最后通过一些投影映射变换到屏幕空间

#### 为什么深度缓冲区中要存储一个非线性的深度？
1. 正确的投影特性的非线性深度方程是和1/z成正比的。这样一来会有如下效果：<font color="#ff0000">在Z很近的时候有高精度，Z很远的时候低精度</font>。
![[LearnOpenGL#深度值精度]]


-   **平截头体**：又称视景体、视锥，是三维世界中在屏幕上可见的区域，即虚拟摄像机的视野
-   下图中红框的位置是平截头体，就是摄像机拍摄的范围。
![[Pasted image 20221031211925.png]]
#### 另一个原因：Z-Fight-深度冲突
![[LearnOpenGL#深度冲突]]

## 三、渲染顺序解析
![[Pasted image 20221031223142.png]]

-   场景中有三个正方体，并赋予了不同的颜色。正常的情况应该是从前到后依次为蓝、绿、红
- ### 图1详解：正常渲染顺序
- ![[Pasted image 20221031223159.png]]
-   梳理渲染过程：

-   没渲染时，此时Unity的深度缓冲区默认值为无穷大
-   渲染蓝色正方体
![[Pasted image 20221031223209.png]]
-   相对于默认深度缓冲区的无穷大，肯定是小于等于，所以测试通过

-   渲染绿色正方体

-   此时蓝色物体位置的深度缓冲区的值已经不是无穷大了，其它位置还是
-   注：深度缓冲区和颜色缓冲区都是相对于片元来讲的（片元可以理解为未完成的一个像素，还处于渲染管线中的像素）
-   绿色正方体进行深度测试，深度测试同样是LessEqual，并且绿色的深度值比蓝色正方体的大。
-   结果就是：两个正方体重叠部分是大于深度缓冲区的，也就是测试不通过，所以重叠部分没有写入绿色，还是蓝色的
-   没有重叠部分，深度当然比无穷大小，所以写入， 渲染出来了绿色正方体未重叠的部分。

-   红色同理。
### 图2详解：关闭前排正方体的深度写入

![[b86429618c9afad29395410cb346a3f1_MD5.png]]

  
●梳理渲染过程：  
○设置：将蓝色正方体的深度写入ZWrite 关掉了；  
○思路：第一个蓝色正方体的渲染时，测试通过，但是并没有写入深度。  
○也就是说，渲染完蓝色正方体时，深度缓冲区的值还是无穷大。  
○这就是蓝绿重叠部分，显示绿色的原因。
### 图3详解：

-   相较于图2，只是把绿色正方体的ZTest改为了always
-   无论是LessEqual还是always，测试都通过，所以效果和图2一样

### 图4详解：改变ZTest条件

-  ![[Pasted image 20221031223413.png]]

-   将红色正方体的ZTest也改为了always，这样一来红色正方体的深度测试也是一直通过，并且写入。
-   因为是从前往后渲染的，所有依次为蓝、绿、红，深度缓冲区中的值也是后边渲染的
-   可以理解为后边遮住前边的效果。

### 图5详解：改变渲染队列

-   ![[Pasted image 20221031223509.png]]
-   相对于图4，改变了绿色正方体的渲染队列为Geometry+1
-   此时的帧缓冲区面板如下
![[Pasted image 20221031223515.png]]
-   尽管场景中绿色正方体在红色正方体前面，但是因为队列+1，它的渲染顺序变为了红色正方体后

-   也就是说，**渲染队列优先级 > 透明物体的渲染顺序（从前到后）**

### 图6详解：再次理解ZTest条件

![[Pasted image 20221031223523.png]]
-   相对于图1，将绿色正方体的ZTest改为了Greater，
-   也就是说蓝色正方体和绿色正方体重叠部分，大于模板缓冲区的部分通过测试，写入模板缓冲区
-   结果就是重叠部分为绿色，而未重叠部分的深度当然小于无穷大，所以没通过测试，自然也就不渲染。
-   红色部分正常。
#### shader自定义面板
![[Pasted image 20221031223721.png]]
```c
Properties
    {
        _Color ("Color", Color) = (1,1,1,1)
        [Enum(Off, 0, On, 1)]_ZWriteMode("Zwrite Mode",Float) = 1
        [Enum(UnityEngine.Rendering.CompareFunction)] _ZComp("ZTest Comp",Float) = 4 //第四个选项
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" "Queue" = "Geometry"}
        ZWrite [_ZWriteMode]
        ZTest  [_ZComp]
        Cull Off
        
        Pass
        {
	        ......
        }
```

## 四、 X-Ray效果
![[Pasted image 20221031231326.png]]
### 实现思路

-   分为三部分：前边的墙、被墙挡住的X-Ray效果部分、高出墙部分的物体
-   回想一下前边6张图，哪张图是前边渲染完，后边渲染显示在先渲染完前边的？ --->图6
-   也就是说，**X-Ray效果部分我们使用到了ZTest ：Greater，深度写入关闭**
-   **高出墙体部分是默认的渲染：LessEqual、ZWrite On**
- 两个passd对物体绘制两次
### shader
![[Pasted image 20221031231520.png]]

![[Pasted image 20221031231522.png]]

![[Pasted image 20221031231524.png]]

![[Pasted image 20221031231526.png]]

![[Pasted image 20221031231528.png]]

![[Pasted image 20221031231531.png]]
-   **代码理解**

-   写CGINCLUDE的好处：将顶点和片元着色器写在里边，在多passshade的时候，直接调用就可以了。（跟C++头文件类似）

-   X-Ray绘制部分
-   和之前实现思路相同，ZWrite Off，ZTest Greater
-   Cull back 是剔除背面，为了优化
-   Blend     SrcAlpha One ：由于有一个透明的效果，除了上边的，还需要一步Blend，来做透明度混合
-   渲染类型和渲染队列为Transparent

-   正常绘制部分略
## 五、粒子系统中的深度测试

-   创建一个粒子系统ParticleSystem，可以看到默认的是透明的

![[Pasted image 20221031232902.png]]
-   为了加深理解，我们自己来复刻一下这个粒子系统的效果

-   我们自己创建一个材质，给到粒子上

-   此时粒子系统变成了这样

![[Pasted image 20221031232935.png]]
-   创建一个shader（Unlit），把粒子的贴图选上，附到材质上，效果如下（是不透明的），这显然不是我们要的效果

![[Pasted image 20221031232947.png]]

-   打开shader修改代码

-   首先回顾前边说的：<font color="#ff0000">Unity中默认的ZWrite On、ZTest是LessEqual、渲染队列是Geometry</font>
-   我们想要让粒子透明，就需要做如下配置

-   渲染队列改为透明物体的渲染队列：Transparent
-   ZWrite Off，对于透明物体，是有相互叠加关系的，所以关掉写入
-   ZTest 默认（LessEqual），对于透明物体是这样的：如果透明物体前有不透明物体，此时 透明物体看不到；如果透明物体后面有不透明物体，此时透明物体可以看到。
-   要渲染半透明物体，还要进行Blend操作：Blend One One（加法混合，叠加效果的显示）

-   修改完成后效果如下：（正是我们想要的效果）
![[Pasted image 20221031233100.png]]
## 六、总结

-   最重要的两个值：当前深度缓冲区的值（ZBufferValue） 和 深度参考值（ReferenceValue）。通过比较操作还实现理想的渲染效果
-   **Unity中的渲染顺序**：
-   先渲染不透明物体（从前到后），再渲染透明物体（从后往前）

-   **Unity中的默认条件：**
-   ZWrite：On
-   Ztest：LessEqual
-   渲染队列：Geometry（2000）

-   通过对ZWrite和ZTest的相互组合配置来控制**半透明物体的渲染（关闭深度写入，开启深度测试，透明度混合）**

-   引入Early-Z之后深度测试相关的内容（Z-Cull、Z-Check）
-   深度缓冲区中存储的深度值为[0，1]的非线性值
## 七、扩展
![[Pasted image 20221031233631.png]]
**参考资料**
参考一下作者作业部分：[3.1 模板测试和深度测试 (yuque.com)](https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/nqoaio)

其他：
-   [https://blog.csdn.net/puppet_master/article/details/53900568](https://blog.csdn.net/puppet_master/article/details/53900568)
-   [https://learnopengl-cn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/01%20Depth%20testing/](https://learnopengl-cn.readthedocs.io/zh/latest/04%20Advanced%20OpenGL/01%20Depth%20testing/)
-   [https://docs.unity3d.com/cn/2018.4/Manual/SL-CullAndDepth.html](https://docs.unity3d.com/cn/2018.4/Manual/SL-CullAndDepth.html)
-   [https://blog.csdn.net/yangxuan0261/article/details/79725466](https://blog.csdn.net/yangxuan0261/article/details/79725466)
-   [https://roystan.net/articles/toon-water.html](https://roystan.net/articles/toon-water.html)

# 3.2 混合模式及提出
## 定义
_Blend_ 就是把两种颜色混在一起。具体就是把某一像素位置**原来颜色和将要会上去的颜色**，通过某种**方式**或者**算法****混在一起**，从而实现新的效果。
例如：PS内的**正片叠底**，**叠加**都属于混合模式的一种。
![[Pasted image 20221208200713.png]]
## 混合模式的公式

![[Pasted image 20221208200957.png]]

**最终颜色 = Shader计算后的颜色值(当前计算出来的颜色，Output)** * 源因子(_SrcFactor_) + **累积颜色(颜色缓冲区中的颜色)** * 目标因子(_DstFactor_).

**累计颜色**可以理解为渲染当前物体后面的颜色即**GBuffer中的像素**（**颜色缓冲区中的颜色**）。

**混合模式控制的就是源因子和目标因子，**在脚本里会看到的就是 **：Blend SrcFactor DstFactor。**

![[a01f8df47bb0de6e833b1734e0521d9b_MD5.png]]

![[219b9bb96b46c4cac58bf7216a48c97c_MD5.png]]

## Unity ShaderLab支持的混合因子

![[f8b3d6db1d94bc6f62a2090e4380bbaa_MD5.png]]

## 混合模式的操作符
常见：
![[Pasted image 20221208201153.png]]

## 剔除

**法线剔除：** 也被称为背面消隐，根据法线朝向判断哪个面被剔除掉。可以用来控制是否双面渲染。

**语法：**  Cull Off/ Front / Back

**面裁剪：** clip函数会将**参数小于0直接在片元着色器直接丢弃**，常用于**制作溶解，裁剪等效果**。

**语法：** clip()；默认会切掉0的部分。

## 总结

-   混合命令**开启后**，会**禁用GPU上的一些优化**（主要是隐藏表面/**去除Early-Z**），这会使**GPU帧时间增加**。
-   默认操作符是Add。
-   **单独的RGB和Alpha混合与高级OpenGL混合操作不兼容**。

# 3.3 曲面细分与几何着色器
Tessellation Shader (TESS) & Geometry Shader(GS)

在正式开始之前，我觉得应该先回顾下渲染管线，尤其是这两个着色器的位置，因为在面试中也有被问到，如下图；

本篇要说的这两位都是在顶点着色器之后，裁剪之前，其中曲面细分着色器在几何着色器之前，**两个都是可选的着色器，并不是必须要写的**，且曲面细分着色器目前在手机上基本上没应用，而**几何着色器最常用的则是用来渲染草地**；
![[Pasted image 20221208202442.png]]
## 一、应用场景
### 曲面着色器的应用
**①海浪、雪地等**
![[Pasted image 20221208202332.png]]
-   如右图一样，将一条直线进行细分，向一条曲线慢慢逼近

**②和置换贴图（DIsplacement mapping，也叫位移贴图）结合**
 ![[Pasted image 20221208202824.png]]
 -   使用普通法线的模型，在边缘部分的凹凸感会不理想
-   如果使用置换贴图，因为它是真正改变物体的形状，所以边缘部分的凹凸感就会很真实
-   注意：使用置换贴图，对模型的面数有要求。模型低会显得过于锐利

-   正是这个原因，让它和曲面细分着色器有着很好的契合度。
- 
 **③雪地里出现的脚印**

-   可以用曲面细分着色器进行优化
### 几何着色器的应用
**①几何动画**
简单的几何动画、甚至可以做一些破碎的效
![[pVXdtu469WJhFcVlhdyJRg.gif|200]]
![[MYk72g-5Y001bBL-3RJNmw.gif|200]]
**②草地等效果（与曲面细分结合）**
![[Pasted image 20221208203146.png]]
-   自定义草的画法，再和曲面细分着色器结合，就可以得到一个可以**动态调整草密度**的一个草地效果。
##  二、着色器执行顺序
 ![[Pasted image 20221208203243.png]]
 -   整体顺序：顶点 → 曲面细分 → 几何 → 片元

-   曲面细分又分为：Hull shader 、Tessellation Primitive Generator 、 Domain shader

-   **Hull shader**主要作用：定义一些细分的参数（如：每条边上如何细分，内部三角形如何细分）
-   **Tessellation Primitive Generator**，不可编程的
-   **Domain shader**：经过曲面细分着色器细分后的点是位于**重心空间**的，这部分的作用就是**把它转化到我们要用的空间**。

-   在D3D11 和 OpenGL中，名字/叫法有差异，问题不大
## 三、曲面细分着色器
Tessellation shader（TESS）

### 1. TESS的输入和输出

**输入**

-   称为Patch，可以看成是多个顶点的集合，包含每个顶点的属性。**（属性是所有顶点共享的，不是每个顶点有独自的属性）**

**功能**

-   将图元进行细分。

-   图元可以是三角形、矩形等

-   不同的图元，输入参数也不一样。

**输出**

-   细分后的顶点

### 2. TESS的流程

Hull shader → Tessellation Primitive Generator → Domain shader

**Hull shader**

-   定义细分的参数（设定Tessellation factor以及Inside Tessellation factor）

-   （如果需要的话）可以对输入的Patch参数进行改变

**Tessellation Primitive Generator**

-   这部分是不可编程、无法控制的
-   进行细分操作

**Domain shader**

-   对细分后的点进行处理，**从重心空间（Barycentric coordinate system）转换到屏幕空间**

### 3. Hull shader参数详解
#### ①Tessellation Factor
-   定义把一条边分为几个部分
- 
-   **切分的方法有三种**：

-   **equal_Spacing**
-   把一条边等分（二、三分等等..）
- ![[--xJ4PwufQqlzSthwBjlpg.gif]]

-   **fractional_even_spacing**
-   向上取最近的偶数
-   最小值是2
-   会把周长分为n-2的等长部分、以及两端不等长的部分（两端部分和小数有关，具体看gif）
- ![[ZaRGgAhYwKMRrj5IcViwjw.gif]]
- 
  **fractional_odd_spacing**
-   向上取最近的奇数
-   最小值是1
-   会把周长分为n-2的等长部分、以及两端不等长的部分
- ![[pCE4KxkjCNCPtT5Bc8D5wA.gif]]

#### ②Inner Tessellation Factor
定义内部的三角形/矩形是怎么画出来的
**三角形情况**
![[Pasted image 20221208204046.png]]
-   例如上图三等分的情况：
	-   将三条边三等分，然后从一个端点开始，取邻近的两个切分点做垂线，两者的交点就是新三角形的一个端点。以此类推就是左图的效果。

**矩形情况**
![[Pasted image 20221208204410.png]]
![[Pasted image 20221208204412.png]]
-   同样的，做垂线，交点，直到没有交点或者交于重心一个点
### 4. 曲面细分Demo部分
#### **Demo1：曲面细分算法展示**
```c
//曲面细分Demo1
Shader "Unlit/TessShader"
{
    Properties
    {
        _TessellationUniform("TessellationUniform",Range(1,64)) = 1
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" }
        LOD 100
        Pass
        {
            CGPROGRAM
            //定义2个函数 hull domain
            #pragma hull hullProgram
            #pragma domain ds
           
            #pragma vertex tessvert
            #pragma fragment frag

            #include "UnityCG.cginc"
            //引入曲面细分的头文件
            #include "Tessellation.cginc" 

            #pragma target 5.0
            
            struct VertexInput
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
            };

            struct VertexOutput
            {
                float2 uv : TEXCOORD0;
                float4 vertex : SV_POSITION;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
            };

            VertexOutput vert (VertexInput v)
            //这个函数应用在domain函数中，用来空间转换的函数
            {
                VertexOutput o;
                o.vertex = UnityObjectToClipPos(v.vertex);
                o.uv = v.uv;
                o.tangent = v.tangent;
                o.normal = v.normal;
                return o;
            }

            //有些硬件不支持曲面细分着色器，定义了该宏就能够在不支持的硬件上不会变粉，也不会报错
            #ifdef UNITY_CAN_COMPILE_TESSELLATION
                //顶点着色器结构的定义
                struct TessVertex{
                    float4 vertex : INTERNALTESSPOS;
                    float3 normal : NORMAL;
                    float4 tangent : TANGENT;
                    float2 uv : TEXCOORD0;
                };

                struct OutputPatchConstant { 
                    //不同的图元，该结构会有所不同
                    //该部分用于Hull Shader里面
                    //定义了patch的属性
                    //Tessellation Factor和Inner Tessellation Factor
                    float edge[3] : SV_TESSFACTOR;
                    float inside  : SV_INSIDETESSFACTOR;
                };

                TessVertex tessvert (VertexInput v){
                    //顶点着色器函数
                    TessVertex o;
                    o.vertex  = v.vertex;
                    o.normal  = v.normal;
                    o.tangent = v.tangent;
                    o.uv      = v.uv;
                    return o;
                }

                float _TessellationUniform;
                OutputPatchConstant hsconst (InputPatch<TessVertex,3> patch){
                    //定义曲面细分的参数
                    OutputPatchConstant o;
                    o.edge[0] = _TessellationUniform;
                    o.edge[1] = _TessellationUniform;
                    o.edge[2] = _TessellationUniform;
                    o.inside  = _TessellationUniform;
                    return o;
                }

                [UNITY_domain("tri")]//确定图元，quad,triangle等
                [UNITY_partitioning("fractional_odd")]//拆分edge的规则，equal_spacing,fractional_odd,fractional_even
                [UNITY_outputtopology("triangle_cw")]
                [UNITY_patchconstantfunc("hsconst")]//一个patch一共有三个点，但是这三个点都共用这个函数
                [UNITY_outputcontrolpoints(3)]      //不同的图元会对应不同的控制点
              
                TessVertex hullProgram (InputPatch<TessVertex,3> patch,uint id : SV_OutputControlPointID){
                    //定义hullshaderV函数
                    return patch[id];
                }

                [UNITY_domain("tri")]//同样需要定义图元
                VertexOutput ds (OutputPatchConstant tessFactors, const OutputPatch<TessVertex,3>patch,float3 bary :SV_DOMAINLOCATION)
                //bary:重心坐标
                {
                    VertexInput v;
                    v.vertex = patch[0].vertex*bary.x + patch[1].vertex*bary.y + patch[2].vertex*bary.z;
			        v.tangent = patch[0].tangent*bary.x + patch[1].tangent*bary.y + patch[2].tangent*bary.z;
			        v.normal = patch[0].normal*bary.x + patch[1].normal*bary.y + patch[2].normal*bary.z;
			        v.uv = patch[0].uv*bary.x + patch[1].uv*bary.y + patch[2].uv*bary.z;

                    VertexOutput o = vert (v);
                    return o;
                }
            #endif

            float4 frag (VertexOutput i) : SV_Target
            {

                return float4(1.0,1.0,1.0,1.0);
            }
            ENDCG
        }
    }
    Fallback "Diffuse"
}
```

#### Demo2：和和置换贴图结合

-   **基本原理**

-   通过置换贴图的深度，来把顶点沿着它的法线方向进行移动，以此来对mash进行形变。

-   代码部分和上个Demo的区别也就是在顶点shader部分对顶点进行了位移、和一些计算法线的参数。（因为顶点位移后没有对应的法线贴图，所以需要自己计算一下，具体怎么算先不讲，属于置换贴图部分的知识）
```c
//曲面细分Demo2：与置换贴图结合使用
Shader "Unlit/Tess_Diss_Shader"
{
    Properties
    {
        _MainTex("MainTex",2D) = "white"{}
        _DisplacementMap("_DisplacementMap",2D)="gray"{}
        _DisplacementStrength("DisplacementStrength",Range(0,1)) = 0
        _Smoothness("Smoothness",Range(0,5))=0.5
        _TessellationUniform("TessellationUniform",Range(1,64)) = 1
    }
    SubShader
    {
        Tags { "RenderType"="Opaque" 
               "LightMode"="ForwardBase"}
        LOD 100
        Pass
        {
            CGPROGRAM
            //定义2个函数 hull domain
            #pragma hull hullProgram
            #pragma domain ds
           
            #pragma vertex tessvert
            #pragma fragment frag

            #include "UnityCG.cginc"
            #include "Lighting.cginc"
            //引入曲面细分的头文件
            #include "Tessellation.cginc" 

            #pragma target 5.0
            float _TessellationUniform;
            sampler2D _MainTex;
            float4 _MainTex_ST;

            sampler2D _DisplacementMap;
            float4 _DisplacementMap_ST;
            float _DisplacementStrength;
            float _Smoothness;

            struct VertexInput
            {
                float4 vertex : POSITION;
                float2 uv : TEXCOORD0;
                float3 normal : NORMAL;
                float4 tangent : TANGENT;
            };

            struct VertexOutput
            {
                float2 uv : TEXCOORD0;
                float4 pos : SV_POSITION;
                float4 worldPos:TEXCOORD1;
                half3 tspace0 :TEXCOORD2;
                half3 tspace1 :TEXCOORD3;
                half3 tspace2 :TEXCOORD4;
            };

            VertexOutput vert (VertexInput v)
            //这个函数应用在domain函数中，用来空间转换的函数
            {
                VertexOutput o;
                o.uv = TRANSFORM_TEX(v.uv,_MainTex);
                //Displacement
                //由于并不是在Fragnent shader中读取图片，GPU无法获取mipmap信息，因此需要使用tex2Dlod来读取图片，使用第四坐标作为mipmap的level，这里取了0
                float Displacement = tex2Dlod(_DisplacementMap,float4(o.uv.xy,0.0,0.0)).g;
                Displacement = (Displacement-0.5)*_DisplacementStrength;
                v.normal = normalize(v.normal);
                v.vertex.xyz += v.normal * Displacement;

                o.pos = UnityObjectToClipPos(v.vertex);
                o.worldPos = mul(unity_ObjectToWorld, v.vertex);

                //计算切线空间转换矩阵
                half3 vNormal = UnityObjectToWorldNormal(v.normal);
                half3 vTangent = UnityObjectToWorldDir(v.tangent.xyz);
                //compute bitangent from cross product of normal and tangent
                half tangentSign = v.tangent.w * unity_WorldTransformParams.w;
                half3 vBitangent = cross(vNormal,vTangent)*tangentSign;
                //output the tangent space matrix
                o.tspace0 = half3(vTangent.x,vBitangent.x,vNormal.x);
                o.tspace1 = half3(vTangent.y,vBitangent.y,vNormal.y);
                o.tspace2 = half3(vTangent.z,vBitangent.z,vNormal.z);
                return o;
            }

            //有些硬件不支持曲面细分着色器，定义了该宏就能够在不支持的硬件上不会变粉，也不会报错
            #ifdef UNITY_CAN_COMPILE_TESSELLATION
                //顶点着色器结构的定义
                struct TessVertex{
                    float4 vertex : INTERNALTESSPOS;
                    float3 normal : NORMAL;
                    float4 tangent : TANGENT;
                    float2 uv : TEXCOORD0;
                };

                struct OutputPatchConstant { 
                    //不同的图元，该结构会有所不同
                    //该部分用于Hull Shader里面
                    //定义了patch的属性
                    //Tessellation Factor和Inner Tessellation Factor
                    float edge[3] : SV_TESSFACTOR;
                    float inside  : SV_INSIDETESSFACTOR;
                };

                TessVertex tessvert (VertexInput v){
                    //顶点着色器函数
                    TessVertex o;
                    o.vertex  = v.vertex;
                    o.normal  = v.normal;
                    o.tangent = v.tangent;
                    o.uv      = v.uv;
                    return o;
                }

                //float _TessellationUniform;
                OutputPatchConstant hsconst (InputPatch<TessVertex,3> patch){
                    //定义曲面细分的参数
                    OutputPatchConstant o;
                    o.edge[0] = _TessellationUniform;
                    o.edge[1] = _TessellationUniform;
                    o.edge[2] = _TessellationUniform;
                    o.inside  = _TessellationUniform;
                    return o;
                }

                [UNITY_domain("tri")]//确定图元，quad,triangle等
                [UNITY_partitioning("fractional_odd")]//拆分edge的规则，equal_spacing,fractional_odd,fractional_even
                [UNITY_outputtopology("triangle_cw")]
                [UNITY_patchconstantfunc("hsconst")]//一个patch一共有三个点，但是这三个点都共用这个函数
                [UNITY_outputcontrolpoints(3)]      //不同的图元会对应不同的控制点
              
                TessVertex hullProgram (InputPatch<TessVertex,3> patch,uint id : SV_OutputControlPointID){
                    //定义hullshaderV函数
                    return patch[id];
                }

                [UNITY_domain("tri")]//同样需要定义图元
                VertexOutput ds (OutputPatchConstant tessFactors, const OutputPatch<TessVertex,3>patch,float3 bary :SV_DOMAINLOCATION)
                //bary:重心坐标
                {
                    VertexInput v;
                    v.vertex = patch[0].vertex*bary.x + patch[1].vertex*bary.y + patch[2].vertex*bary.z;
			        v.tangent = patch[0].tangent*bary.x + patch[1].tangent*bary.y + patch[2].tangent*bary.z;
			        v.normal = patch[0].normal*bary.x + patch[1].normal*bary.y + patch[2].normal*bary.z;
			        v.uv = patch[0].uv*bary.x + patch[1].uv*bary.y + patch[2].uv*bary.z;

                    VertexOutput o = vert (v);
                    return o;
                }
            #endif

            float4 frag (VertexOutput i) : SV_Target
            {
                float3 lightDir =_WorldSpaceLightPos0.xyz;
                float3 tnormal = UnpackNormal (tex2D (_DisplacementMap, i.uv));
                half3 worldNormal;
                worldNormal.x=dot(i.tspace0,tnormal);
                worldNormal.y= dot (i.tspace1, tnormal);
                worldNormal.z=dot (i.tspace2, tnormal);
                float3 albedo=tex2D (_MainTex, i.uv). rgb;
                float3 lightColor = _LightColor0.rgb;
                float3 diffuse = albedo * lightColor * DotClamped(lightDir,worldNormal);
                float3 viewDir = normalize (_WorldSpaceCameraPos. xyz-i. worldPos. xyz);
                float3 halfVector = normalize(lightDir + viewDir);
                float3 specular = albedo * pow (DotClamped (halfVector, worldNormal), _Smoothness * 100);
                float3 result = specular + diffuse;
                return float4(result, 1.0);

                return float4(result,1.0);
            }
            ENDCG
        }
    }
    Fallback "Diffuse"
}
```

## 四、几何着色器-Geometry shader （GS）


### 1.GS的输入和输出

**输入**

-   输入为单个图元（三角形、矩形、线等等）
-   根据不同的图元，shader中会出现不同的顶点数量

**输出**

-   输出也为图元（一个或者多个）
-   同时还要定义输出的最大顶点数
-   输出的图元需要自己一个点一个点的自己去构建，顺序很重要（这个着色器最主要的功能：自己构建图元）

### 2.流程

-   输入输出结构
-   定义最大输出定点数
-   几何着色器

### 3. 草地绘制
[菜鸡都能学会的Unity草地shader - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/433385999)

# 3.4 前向/延迟渲染路径

## 一、渲染路径

什么是渲染路径（Rendering Path）

-   **决定光照的实现方式**。（也就是当前渲染目标使用**光照的流程**）

## 二、渲染方式

首先看一下两者的直观的不同
![[Pasted image 20221208214124.png]]

### 前向/正向渲染 Forward Rendering

一句话概括：每个光照都计算

#### 1 流程
![[Pasted image 20221208214244.png]]
-   如图所示，**流程**为：

-   待渲染几何体 → 顶点着色器 → 片元着色器 → 渲染目标
-   在渲染每一帧的时，每一个顶点/片元都要执行一次片元着色器代码，这时需要将所有的光照信息传到片元着色器中。

-   虽然大部分情况下的光照都趋向于小型化，而且照亮区域也不大，但即便是离这个像素所对应的世界空间的位置很远的光源，光照计算还是会把所有的光源考虑进去的。
-   **简单来说就是不管光源的影响大不大，计算的时候都会把所有光源计算进去**，这样就会造成一个很大的浪费

#### 2 规则（如何渲染每一帧的）和注意事项

-   **发生在顶点处理阶段，会计算所有顶点的光照**。全平台支持

-   规则1：最亮的几个光源会被实现为逐像素光照
-   规则2：然后就是，最多四个光源会被实现逐顶点光照
-   规则3：剩下的光源会实现为效率较高的**球谐光照（Spherical Hamanic）**，这是一种模拟光照。SH 光照可以被非常快速地渲染，它只消耗很少的 CPU 性能，几乎不消耗 GPU 性能。并且增加 SH 灯光的数量不会影响性能的消耗。

一个灯光是逐像素光照还是其他方式渲染取决于以下几点：
（1）渲染模式（Render Mode）设置为 Not Important 的灯光总是以逐顶点或者 SH 的方式渲染。
（2）渲染模式（Render Mode）设置为 Important 的灯光总是逐像素渲染。
（3）最亮的平行光总是逐像素渲染。
（4）如果逐像素光照的灯光数量少于项目质量设置中 Pixel Light Count（最大像素光照数量），那么其余比较亮的灯光将会被逐像素渲染。
（5）最后剩下的光源，按照规则2或3。

**Render Mode 设置：** 默认为 Auto，Unity 会根据灯光的亮度以及与物体的距离自动判断该灯光是否重要。
![[Pasted image 20230615135723.png|350]]

**Pixel Light Count 设置：**
![[Pasted image 20221208214300.png|450]]

-   所以，如果一个物体受到n个光源影响，那么每个片元着色器执行代码时，都必须把n个光源传递给着色器中进行计算。
![[Pasted image 20221208214311.png]]
#### 3 两种 Pass 

![[Pasted image 20230615140142.png|350]]
一个物体受到 A-H 共8个灯光照射，假设所有灯光有相同颜色和强度，并且它们的渲染模式为自动。

最终这8个灯光的渲染模式如图所示，由于 A-D 这4个灯光距离物体更近，因此亮度更亮，会逐像素渲染，然后最多4个灯光（D-G）逐顶点渲染，最后剩余的灯光（G-H）以 SH 渲染。
![[Pasted image 20230615140211.png|400]]

灯光 D 既是逐像素照明又是逐顶点照明，灯光 G 既是逐顶点照明又是 SH 照明，这是因为当物体或者灯光移动的时候，不同渲染模式的灯光交界处会出现明显的缺陷，为了避免这个问题，**Unity 将不同的灯光组之间进行了重叠**。

**前向渲染有两种 Pass：Base Pass 和 Additional Pass**

![image-20220707190035317](image-20220707190035317.png)

1. Base Pass 中的渲染计算包含一个逐像素的平行光和所有逐顶点或 SH 的灯光，并且也会包含所有来自于 Shader 的光照贴图、环境光和自发光。BasePass 中的平行光默认支持投射阴影，
2. 其他逐像素的灯光会在额外的 Additional Pass 中渲染，每一个灯光会产生一个额外的 Pass。在 Additional Pass 中的光源默认没有阴影效果，可以使用 `multi_compile_fwdadd_fullshadows` 编译指令代替 `multi_compile_fwdadd` 编译指令，为点光源和聚光灯开启阴影效果。
3. Additional Pass 中还要开启混合模式，因为我们希望每个 Additoinal Pass 可以和上次一的光照结果在帧缓存冲进行叠加，从而得到最终的有多个光照的渲染结果。如果没有开启和设置混合模式 Blend One One，那么 Additional Pass 的渲染结果会覆盖掉之前的渲染结果，看起来好像该物体之受该光源的影响。
4. 对于前向渲染来说，一个 Unity Shader 通常会定义一个 Base Pass (Base Pass 也可以定义多次，例如需要双面渲染等情况）以及一个 Additional Pass。**一个 Base Pass 仅会执行一次** (定义了多个 Base Pass 的情况除外)，**而一个 Additional Pass 会根据影响该物体的其他逐像素光源的数目被多次调用，即每个逐像素光源会执行一次 Additional Pass。**

### 延迟渲染 Deferred Rendering

一句话概括：先不计算光照，延迟到最后再一起计算

#### 1、什么是延迟渲染

-   主要用来解决大量光照渲染的方案
-   延迟渲染的实质是：
-   先不要做迭代三角形做光照计算，而是先找出来你能看到的所有像素，再去迭代光照。
-   直接迭代三角形的话，由于大量三角形是看不到的，会造成极大的浪费。

#### 2、流程

![[Pasted image 20221208215309.png]] -   流程为：待渲染几何体 → 顶点着色器 → 片元着色器（**写入颜色，但不进行光照计算**）→  MRT 多重渲染目标 → 光照计算（全部执行逐像素渲染） → 渲染目标

过程可以拆分为**两个 pass：**
-   第一个pass：**几何处理通路**。
    -   首先将场景渲染一次，获取到的待渲染对象的各种几何信息存储到名为G-buffer的缓冲区中，这些缓冲区用来之后进行更复杂的光照计算。
    -   由于有深度测试，所以最终写入G-buffer中的，都是离摄像机最近的片元的集合属性，这就意味着，在G-buffer中的片元必定要进行光照计算。
-   第二个pass：**光照处理通路**。
    -   这个pass会遍历所有G-buffer中的位置、颜色、法线等参数，执行一次光照计算。

#### 3、一些注意事项

-   **G-buffer的概念**

-   G-Buffer，全称Geometric Buffer ，译作**几何缓冲区**，它主要用于**存储每个像素对应的位置（Position），法线（Normal），漫反射颜色（Diffuse Color）以及其他有用材质参数。**

-   根据这些信息，就可以在像空间（二维空间）中对每个像素进行光照处理。

-   如图为一个典型的G-buffer
![[Pasted image 20221208215538.jpg]]

-   UE4默认使用的是延迟管线

-   我们在视图模式---缓冲显示---总览，就可以看到所有G-buffer的预览
![[Pasted image 20221208215548.png]]

-   **延迟渲染**<font color="#ff0000">不支持透明物体的渲染</font>，因为没有深度信息，所以渲染透明物体时引擎会自动使用前向渲染处理
- 延迟着色不支持正交投影，当摄像机使用正交投影模式的时候，摄像机会自动使用前向渲染。
> [!NOTE] MRT现在已经支持 MSAA 抗锯齿！
> DX10.1支持了带 MSAA 的 MRT，很多老文章说延迟渲染不支持抗锯齿是因为十几年前 DX9 时代的 MRT 不支持MSAA

-   伪代码
- ![[Pasted image 20221208215555.png]]
-   RT（G-buffer）相当于把整个屏幕的信息绘制到一个图中，每个RT都可以写到一个G-buffer中
-   G-buffer中的数据都是2D的，所以我们的光照计算就相当于一个**2D的光照后处理**
### 三、不同渲染路径的特性

#### 1、后处理方式不同

-   如何需要深度信息进行后处理的话

-   前向渲染需要单独渲染出一张深度图
-   延迟渲染直接用G-buffer中的深度图计算

#### 2、着色计算不同（shader）

延迟渲染因为是最后统一计算光照的，所以只能算一个光照模型（如果需要其他光照模型，只能切换pass）

## 四、不同渲染路径的优劣

### 1、前向渲染的优点、缺点

**优点**

-   1.支持半透明渲染
-   2.支持使用多个光照pass
-   3.支持自定义光照计算方式

-   （延迟渲染是渲染到Gbuffer，再一起计算光照，所以不支持每一个物体用单独的光照方式计算）

**缺点**

-   1.光源数量对计算复杂度影响巨大
-   2.访问深度等数据需要额外计算（需要再渲染一张深度图）

### 2、延迟渲染的优点、缺点

**优点**

-   1.大量光照场景的情况下，优势明显
-   2.只渲染可见像素，节省计算量
-   3.对后处理支持良好（例如深度信息：直接拿G-buffer中的就行）
-   4.用更少的shader（所有的物体光照模型都一样，很多东西不用再定义了）

缺点
-   1.对MSAA支持不友好
-   2.透明物体渲染存在问题（深度问题，只渲染力物体最近的物体，渲染透明度时会出现问题）
-   3.占用大量的显存带宽，所以移动端用得较少（原神是延迟渲染）

-   涉及一个clear的操作，如果不清理的话，后边可以继续获取到
-   每一帧都需要几张rt在显存中传输、清理等，会更耗带宽
-   4.只能使用同一个光照pass

## 五、其他部分

### 1、渲染路径的设置

-   Project Setting中进行设置
![[Pasted image 20221208221443.png]]
![[Pasted image 20221208221457.png]]
### 2、TBDR（分块延迟渲染）
针对移动端的优化

-   有两个TBDR，名字一样，内容不同

-   第一个：
- 是SIGGRAPH2010提出的，作为传统Defferred Rendering的另一种主要改进，**分块延迟渲染（Tile-Based Deferred Rendering，TBDR）旨在合理分摊开销（amortize overhead）**，自SIGGRAPH 2010上提出以来逐渐为业界所了解。基于延迟渲染的优化方式，通过分块来降低带宽内存用量（解决带宽和内存问题）
![[Pasted image 20221208221615.png]]
延迟渲染的分块，把整个图像分为很多块，再一块一块的渲染

-   第二个：
-   PowerVR基于手机GPU的TBR框架提出的改进，通过HSR减少Overdraw
-   TBDR这个架构是PowerVR提出来的对TBR的一次改进，在TBR的基础上再加了一个Deferred。
-   通过做一些可见性测试来减少Overdraw
-   **涉及手机GPU架构，和延迟渲染没什么关系**
[[第三章 进阶应用#3.7 现代移动端的TBR和TBDR渲染管线]]
### 3、其他渲染路径

**延迟光照（Light Pre-Pass / Deferred Lighting）**

-   减少G-buffer占用的过多开销，支持多种光照模型

-   和延迟渲染的区别：
-   用更少的 buffer 信息，着色计算的时候用的是 forward，所以第三步开始都是前向渲染（可以对不同的物体进行不同的光照模型）

**Forward+（即Tiled Forward Rendering，分块正向渲染）**

-   减少带宽，支持多光源，强制需要一个preZ
-   通过分块索引的方式，以及深度和法线信息来到需要进行光照计算的片元进行光照计算。
-   需要法线和深度的后处理需要单独渲染一个rt出来
-   强制使用了一个preZ（如果没涉及过这个概念的话，可以理解为进行了一个深度预计算Pass）

**群组渲染（Clustered Rendering）**

-   带宽相对减少，多光源下效率提升
-   分为forward和deferred两种
-   详细补充拓展：[https://zhuanlan.zhihu.com/p/54694743](https://zhuanlan.zhihu.com/p/54694743)

### 5、PreZ(Zprepass)

-   实际上就是一个深度计算

**和深度图的区别：**

-   都是深度信息
-   PreZ是用一个pass，只算深度
-   深度图是算成了一张RT（RenderTexture），把**深度信息绘制到了一张RT上**。

-   具体用途：
-   大规模草、透明排序会用到PreZ

-   early-z 和 PreZ的区别
-   early-z，自动的，对面数有要求（硬件自动）
-   PreZ，当early-z失效的时候，或者需要深度图的时候，一种手动代替的方案
[[第三章 进阶应用#3.5 Early-z和Z-prepass]]

### 6、一些补充

-   Unity的urp是不支持延迟渲染的，老管线支持。
-   UE默认管线就是延迟渲染管线
-   一般延迟渲染用于主机/大项目

# 3.5 Early-z和Z-prepass

## 一、深度测试：Depth Test

### 1.回顾深度测试的内容
-   深度测试位于逐片元操作中、模板测试后、透明度混合前
-  ![[8369c261f03a16b5b6e9645d9e6b6786_MD5.png]]

-   深度测试可以解决：物体的可见遮挡性问题

-   我们可以用一个例子说明
![[Pasted image 20221208224546.png]]
![[Pasted image 20221208224556.png]]
-   上图的解释：

-   首先先渲染紫色三角形，紫色三角形的深度值为5，当渲染它的时候，它与深度缓冲区中的∞做比较，因为默认的test比较条件为LEqual，所以5小于∞，并且写入了深度缓冲器
-   之后进行黄色三角形的渲染，和上一步同理，会进行深度对比并进行相关操作，渲染完成后的结果如右图下边所示

**深度测试流程图**

-   具体每一步都可以对应之前讲的笔记理解
![[Pasted image 20221208224640.png]]

## 2.深度测试带来的问题

-   前边已经说过很多次了，就是性能浪费、OverDraw
![[Pasted image 20221208224714.png]]
-   简单地概括就是
-   在**深度测试前**计算过的片元，有一些通过不了深度测试将会被直接抛弃（图中的红色片元），那么之前做得计算就都是无效计算了。
-   这个问题的解决方法就是：**early-z**

## 二、提前深度测试：early-z

### 1.Early-Z的内容
-   是在传统管线中的光栅化阶段之后、片元着色器之前加的一步操作。
![[Pasted image 20221208224906.png]]
![[Pasted image 20221208224921.png]]
-   图中的例子：

-   片元1写入深度后，在渲染片元2、3的时候，会进行**提前深度测试（z-cull）**，因为没有通过，所以这两个片元不会被计算

-   **区分两次深度测试**
-   提前的深度测试叫作**Z-Cull**
-   后续的深度测试为了确定正确的遮挡关系，叫作**Z-Check**

-   也就是在计算之前就做一次深度测试，如果不通过就直接不计算了，这样就避免了无效的计算

-   **补充**：
-   Early-Z同样可以搭配使用模板测试

### 2.Early-Z失效的情况

-   ①开启Alpha Test 或 clip/discard等手动丢弃片元操作
-   通常Early-Z不仅会进行深度测试，还要进行深度写入
-   例如以下情况：
-   如果经过AlphaTest，前面渲染的片元被丢弃了（但写入了深度），那么后续的像素都将无法正常渲染。

-   ②手动修改GPU插值得到的深度
-   类似上述情况

-   ③开启Alpha Blend
-   开启了透明度混合不会开启深度写入，也就不符合Early-Z了

-   ④关闭深度测试
-   都关了还测试啥
### 3.高效利用Early-Z
- **不透明物体由远往近渲染，early-z将没有任何优化效果**

-   在渲染前，将不透明物体**从近往远渲染**的话，Early-Z能发挥最大的性能优化
-   具体怎么排序？
-   ->可以让cpu将物体按照由近到远的顺序排好，再交付给gpu进行渲染

-   问题：
-   复杂的场景，cpu性能消耗很大
-   严格按照由近到远的顺序渲染，将不能同时搭配批处理优化手段。
-   **有没有其他方法？ ->pre-z**
## 三、Z-Prepass（Pre-Z）
### 1.方式1：双pass

- **内容**
-   使用两个pass
-   pass1：Z-prepass中**仅仅写入深度**，不计算输出任何颜色。目的只是为了深度值写入缓冲区
-   pass2：关闭深度写入，将深度比较函数改为相等，进行正常的透明度混合（AlphaBlend）

-   **效果：**
-   每个物体都会渲染两个pass，且所有物体的z-prepass的结果就自动形成了一个最小深度值的缓冲区Z-buffer，无需cpu进行排序

-   **代码：**
- ![[Pasted image 20221208225600.png]]
- **问题1：动态批处理**

-   多pass shader无法进行动态批处理 ---> Draw Call问题

- **问题2：Draw Call**

-   使用z-prepass shader 的物体，draw call会多一倍
- ![[Pasted image 20221208225622.png]]
**《入门精要》中写过的Pre-Z**
![[冯乐乐入门精要#2. 开启深度写入的半透明效果]]
### 2.方式2：提前分离的Prepass

用于解决DrawCall问题

- **内容**

-   仍然使用两个pass

-   将pass1的z-prepass单独分离出一个shader，并用这个shader将场景的不透明物体先渲染一遍
-   原来shader中的pass，仍然关闭深度写入，深度比较函数仍然为相等，进行正常的透明度混合

**补充**
-   URP的SRP batch做的合批是不会减少Draw Call的
-   他的最大的优化在于合并set pass call，减少set pass call的开销
-   因为CPU上的最大开销来自于准备工作（设置工作）
-   而非DrawCall本身（这只是要放置GPU命令缓冲区的一些字节而已），draw call是不会减少的

-   [https://www.xuanyusong.com/archives/4759](https://www.xuanyusong.com/archives/4759)
-   [https://blog.csdn.net/lsjsoft/article/details/90734932](https://blog.csdn.net/lsjsoft/article/details/90734932)

## 3.Pre-Z也是透明渲染的一种解决方案
![[Pasted image 20221208225657.png]]
-   这样会存在一个问题：无法看到透明物体的背面
-   解决方法：透明物体的双面渲染

-   核心思路：将渲染分为正面背面两部分
-   pass1：
-   只渲染背面（cull front）

-   pass2
-   只渲染正面（cull back）

-   由于Unity会顺序执行Subshader中的各个Pass，所以我们可以保证背面总是在正面被渲染之前渲染，来得到正确的深度渲染关系
## 四、Z-prepass的其他问题

### 1.Z-prepass的性能消耗是否能被忽视

-   国外论坛一位名为lipsryme的老哥做了一项实验：
![[Pasted image 20221208225723.png]]
-   可以看到，Z-prepass的消耗为2.0ms，而带来的优化只减少了0.3ms（2.7-2.4）
-   后续讨论中，发现Z-prepass是需要根据项目的实际情况来决定是否采用的。

-   **总结有以下建议**

-   当一个有非常多OverDraw的场景，且不能很好的将不透明物体从前往后进行排序时，可以考虑使用PreZ进行优化
-   注意，PreZ会增加DrawCall，如果用错了可能是负优化
- 
## 五、Early-Z 和 Z-prepass的实例应用

### 1.面片叠加的头发渲染

-   对于半透明的面片来说，需要**从后往前进行排序渲染**才能得到正确的透明度混合结果
- ![[Pasted image 20221208230553.png]]
![[Pasted image 20221208230548.png]]
### 2.排序后的头发渲染
![[Pasted image 20221208230615.png]]
-   分为3个pass

-   pass1

-   处理不透明部分，开启Alpha test透明度测试，仅通过不透明的像素，
-   关闭背面剔除
-   开启深度写入

-   pass2

-   剔除正面，渲染背面

-   pass3

-   剔除背面，渲染正面

-   问题：会带来非常多OverDraw的问题
### 3.性能改善
![[Pasted image 20221208230629.png]]
-   使用Early-Z剔除
-   透明度测试开启时Early-Z无法使用的解决方案：    

-   使用一个简单的shader进行透明度测试形成 Z-Buffer，（就是我们上边说的提前分离的z-prepass）
### 4.改善的渲染方案
![[Pasted image 20221208230643.png]]
-   pass1：准备Z-Buffer

-   开启透明度测试
-   关闭背面剔除
-   开启深度写入，深度测试设置为less
-   关闭颜色缓冲区写入
-   用于一个简单的片元着色器来返回透明度值

-   pass2、pass3、pass4参考之前排序后的头发渲染部分，同理
## 六、其他参考资料

-   [https://www.cnblogs.com/ghl_carmack/p/10166291.html](https://www.cnblogs.com/ghl_carmack/p/10166291.html) ---深入剖析GPU Early Z优化
# 3.6 纹理压缩
## 一、什么是纹理压缩

-   **纹理压缩是**：
-   为了解决内存、带宽问题，专为在计算机图形渲染系统中**存储纹理**而使用的**图像压缩技术**。

-   **区分图片格式和纹理压缩格式**

-   **概念上讲**

-   图片格式：
-   是图片文件的存储格式，通常在硬盘、内存中存储，传输文件时使用
-   例如：jpg、png、gif、bmp

-   纹理压缩格式：
-   是**显卡能直接进行采样**的**纹理数据格式**，通常在向显卡中加载纹理时才使用

-   **原理上讲**

-   图片格式：
-   图片压缩格式是**基于整张图片进行压缩**，像素之间解码过程中**存在依赖关系**
-   无法实现单个像素级的解析，发挥不了显卡的并行能力
-   并且，无论什么格式在显卡解码后都是RGBA的纹理格式
-   总结：无法减少显存的占用率，且需要CPU解压后才能被GPU读取，结果就是：增加了CPU的时间和带宽

-   纹理压缩格式：
-   基于块压缩，能够更快的读取像素所属字节块进行解压缩，以支持快速访问
-   “随机访问”：如果渲染一个物体时，需要在某个坐标上采样纹理，那么GPU只需要读取该像素所属固定大小字节块，对其进行解压即可。

-   举例理解：
-   如果拿到一张贴图，设置纹理压缩格式：
-   CPU会按照我们设定的格式进行压缩，然后传递给GPU读取

-   如果不设置纹理压缩格式，以图片格式进行：
-   CPU也会进行压缩，但是会压缩为RGBA32格式，但其实这个格式是非常大的，并没有起到压缩的作用
## 二、为什么要使用纹理压缩
![[Pasted image 20221208232051.png]]
-   实际上，使用纹理压缩的原因在上部分**图片格式和纹理压缩格式区别**的部分里已经讲了

-   **图片压缩格式下**

-   无法实现像素级解析，**无法发挥GPU并行能力**，无法减少显存的占用率
-   需要在到GPU之间使用CPU解压缩，增加了CPU的时间和带宽

-   **纹理压缩格式下**

-   GPU可以直接读取贴图，不需要经过中间CPU解码/解压缩的步骤
-   还支持“随机访问”

-   总结一下就是：

-   我们需要一种**内存占用既小又能被GPU直接读取的格式**（这种格式就是纹理压缩）

- **总结**
-   纹理压缩相对正常图片格式，能够直接被GPU采样，发挥GPU强大的并行能力，且优化了带宽问题
## 三、常见的纹理压缩格式
![[Pasted image 20221208232125.png]]
>黄字是我们常用的压缩格式 
### 非纹理压缩格式

-   RGBA8888（RGBA32）
-   R、G、B、A四个通道各占8位
-   所以一个像素消耗：4 * 8 = 32位（bit）= 4字节（byte）

-   RGBA4444（RGBA16）
-   四个通道各占4位内存
-   一个像素消耗：4 * 4 = 16位 = 2字节

-   RGB888（RBG24）
-   同理，一个像素消耗**:** 3字节

-   RGB565(RGB16)
-   一个像素消耗**：**2字节

-   **总结**
-   带透明通道的，单通道可以是4位、8位
-   不带透明通道的，单通道可以是8位，或者在RGB分16位（565、绿通道多给1位）
### 1、DXTC系列

DXTC系列的纹理压缩格式来源于S3公司提出的S3TC算法

-   **基本思想**：
-   把4×4的像素块压缩成一个64或128位的数据块

-   **优点**：
-   创建了一个固定大小且独立的编码片段，没有共享查找表或其他依赖关系，简化了解码过程

#### DXT1（BC1）

-   也叫作BC1
-   **内容**：
-   将4×4的像素块压缩成了一个64位的数据块，这个64位的数据块中包含：

-   其中32位是：
-   两个16位RGB（RGB565）颜色。
-   （这两个RGB颜色是4×4像素块中的两个极端颜色值，然后通过线性插值计算出剩余的两个中间颜色）

-   剩余的32位
-   平均分配给了16个像素作为颜色值的索引值，每个像素占2位

-   **理解**：
![[Pasted image 20221208232506.png]]
![[Pasted image 20221208232510.png]]
-   64位分别为：
-   其中32位是：蓝色的A、B两个16位RGB颜色，它们是极端颜色（格式为RGB565）

-   极端颜色通过线性插值得到的中间颜色：红色的C、D

-   另外32位是：16个像素的颜色索引值，每个像素占2位（可能是 00 01 10 11，可以分别表示上边的A、B、C、D四种颜色）

-   **注意**：

-   **①**存储极端颜色的格式是RGB565，也就是说绿（G）通道的精度比其他两个通道精度高一些

-   这就是有些人说把信息放绿通道精度更高的原因
-   //补充：多出来的精度给绿通道是因为：人眼对绿色更敏感

-   **②**DXT1格式适用于不具有透明度信息或者具有一位透明度信息（表示完全透明or完全不透明）的贴图

-   对于没有Alpha信息的贴图，压缩遵循上文
-   对于有Alpha信息的贴图
-   极端颜色插值时，中间颜色只有一个，另一个表示完全透明or完全不透明（例如上述例子中，C为中间颜色，D表示透明信息）
-   每个像素索引时，极端颜色+中间颜色表示完全不透明，另外一个表示完全透明

-   **DXT1的压缩率**

-   参照对象：RGB24（DXT1主要用于没有Alpha信息的贴图）
-   DXT1:

-   总数据块为64位，16个像素共用 =>一个像素4位

-   所以压缩率为：24 / 4 = 6:1

#### DXT2/3（BC2）

-   也叫作BC2
-   128位
-   颜色信息和DXT1是一样占用64位，多出64位用来增加Alpha信息

-   Alpha信息并没有插值，只是单纯的为每一个像素多给4位信息，用来记录Alpha信息
-   这样一来，每个像素就占4+4=8位，（0~3表示透明信息，4-7表示颜色信息）

-   **简单来说就是：**
-   相比DXT1，多了64位用来存Alpha信息， 16个像素，每个4位

-   **DXT2和DXT3的区别**：
-   DXT2是已经完成了颜色与Alpha的混合，当透明度发生改变时，直接改变整体颜色值，不再单独进行复合
-   DXT3的Alpha信息相对独立（分开压缩）

-   **DXT2、3的压缩率**
-   参照对象：RGBA（32位）
-   总数据块为128位，16个像素共用 =>一个像素8位
-   压缩率为：32 / 8 = 4:1

#### DXT4/5（BC3）

-   也被称为BC3

-   128位
-   **和DXT2/3的区别：**
-   Alpha信息是通过线性插值得来的：
-   表示颜色信息的64位同上
-   多出的64位：
-   2个8位的极端值
-   每个像素3位的索引值（16*3）

-   **DXT4和DXT5的区别**：

-   同2和3

-   **DXT4、5的压缩率**

-   同为4:1

#### 扩展知识

-   Unity将贴图类型选为法线时，会采用DXTnm格式

-   它基于DXT5，会把法线贴图的R通道存入A通道，然后将RB通道清除为1
-   这样就可以把法线xy信息分别存入到RGB和A中进行压缩，**来获得更高的精度**
-   最后再根据xy构建出z的信息
### 2、ATI系列
#### ATI1/2（BC4、BC5）

-   ATI1，也被称为BC4

-   64位
-   每一个数据块中存储的是单个颜色通道的数据
-   **主要用于存储：高度图、光滑度贴图等单通道信息**
-   ATI1的压缩方式：

-   和DXT5中，对于Alpha数据处理一样

-   ATI2,也被称为BC5

-   128位
-   和ATI1的区别在于，它存储了两个颜色通道的数据
-   ATI2的压缩方式：

-   处理方式也是相同的，相当于存储了两个ATI1的数据块

-   如果想要节省通道只存储法线xy通道时，就可以采用BC5（ATI2）压缩格式

-   **优点：**
-   因为每个通道都会有自己的索引，会单独压缩，所以**法线贴图的xy信息可以比DXT1中有更多保真度**

-   **缺点：**
-   需要使用两倍内存，需要更多的带宽才能将纹理传递到着色器中

-   **压缩比：**
-   ATI1：
-   参照对象：单通道 8位
-   总数据块为 64位，16个像素，所以每个像素4位
-   压缩比为：8 / 4 =2:1

-   ATI2：
-   参照对象：两个通道 16位
-   总数据块为 128位，16个像素，所以每个像素4位
-   压缩比为：16 / 8 = 2:1

-   //注：一些资料上显示BC4和5的压缩比为4/1，查了很多还是没找到详细资料。这一块待定，日后搞清楚了回来修改

-   弹幕有同学提出：维基百科中说，4:1的压缩比，是因为单个像素当作32位的大小来计算了

#### BC6/7

-   BC6和BC仅在D3D11及以上图形硬件中受到支持
-   他们每个块占用16字节

-   BC6
-   针对RGB半精度浮点数数据进行压缩
-   **是专门针对HDR（高动态范围）图像设计的压缩算法**
-   压缩比为6:1

-   BC7
-   针对8位RGB或RGBA的图像进行压缩
-   **是专门针对LDR（低动态范围）图像设计的压缩算法**，该格式用于高质量的RGBA压缩，可以显著减少由于压缩法线带来的错误效果
-   压缩比为3:1

-   **一般我们使用BC7给端游高质量图像进行压缩**
-   Reference：
-   BC6和BC7的官方原理说明
-   [https://docs.microsoft.com/zh-cn/windows/uwp/graphics-concepts/bc6h-format](https://docs.microsoft.com/zh-cn/windows/uwp/graphics-concepts/bc6h-format) [https://docs.microsoft.com/zh-cn/windows/uwp/graphics-concepts/bc7-format](https://docs.microsoft.com/zh-cn/windows/uwp/graphics-concepts/bc7-format)

### 3、ETC系列

-   DirectX选择DXTC作为标准压缩格式，而OpenGL选择了爱立信研发的ETC格式
-   **几乎所有安卓设备都支持ETC格式，所以它在移动端应用广泛**

-   基本思想：
-   ETC的方案同样将4×4的像素单元压缩成64位数据块，同时，将像素单元水平或竖直朝向分为两个区块，每个像素颜色等于基础颜色加上索引指向的亮度范围
![[Pasted image 20221208234341.png]]
-   总结：每个区块中有12位用来存储颜色信息（12*2），16位存储其8个像素的索引（每个像素2位，16*2），4位存储亮度索引（4*2）
#### ETC1
![[Pasted image 20221208234503.png]]
-   **亮度索引值**：（上表，水平方向）
-   每个区块的亮度索引值（3位，0-7）会 从8个亮度索引值中获取当前像素单元的亮度表
-   //注：课程里讲的是4位，0-15个亮度索引值，但资料中显示的是3位索引值，表中也是，正确性存疑

-   **像素索引值**（上表，竖直方向）：
-   每个像素的像素索引值（2位，0-3）可以从亮度表的四个值中选取对应的亮度补充值

-   **最终的颜色 = 12位基础颜色信息 + 亮度补偿值**
-   补充：

-   **原理：**

-   将4×4的像素块编码为2×4或者4×2像素的两个块
-   每个块指定一个基色，每个像素的颜色铜鼓偶一个编码为相对于这个基色偏移的灰度值确定（上面提到的亮度）

-   **位数占比**：

-   亮度索引3位*2
-   像素索引2位*16
-   基础颜色12位（444*2，或者555+333）*2
-   flip1位（控制水平或者竖直划分）*2
-   总位数 = 3*2 + 2*16 + 12*2 + 1*2 = 64位
-   //注：*2是因为有两个块，*16是因为有16个像素

-   **压缩率**：

-   参照标准：RBG24
-   总共有64个数据块，针对16个像素，也就是每个像素4位
-   压缩比 = 24 / 4 = 6:1

-   **对于ETC1不支持Alpha通道的解决方案**
-   采用两张纹理混合的方式

-   **ETC1的适用情况**

-   长宽为2的幂次的贴图
-   不适用于带透明通道的贴图
-   适用于基本所有安卓设备

#### ETC2

-   TEC2是ETC1的扩展，支持了Alpha通道（内存占用大于ETC1）
-   硬件要求OpenGL ES3.0和OpenGL4.3以上

### 4、ASTC

-   ASTC是由ARM和AMD联合开发的纹理压缩格式
-   **优点：**
-   可以根据不同图片选择不同压缩率的算法
-   图片长宽不需要是2的次幂
-   同时支持HDR和LDR

-   **缺点：**
-   兼容性不够完善
-   解码时间较长
-   无法在iphone6以下的设备运行

-   **基本思想：**
-   同样是基于块的压缩算法，与BC7类似
-   数据块大小固定为128位
-   块中的像素数量可变，从4×4到12×12像素都有

-   **每个数据块中存储了两个插值端点**
-   存储的不一定是颜色信息，也可能是Layer信息，这样可以用来对Normal或Alpha进行更好的压缩（根据贴图类型进行针对性压缩）

-   **块中的每个纹素，存储其对应插值点的权重值**
-   权重值数量可以 少于纹素数量，可以通过插值得到每个纹素的权重值，再进行颜色计算

-   **128位数据块中存储的信息：**
-   11位，权重、高度信息、特殊块标识
-   2位，Part数量
-   4位，16中插值端点模式（LDR/HDR、RGB/RGBA）
-   111位，插值端点信息、纹素权重值、配置信息

### 5、PVRTC

-   PVRTC是由Imagination公司专为PowerVR显卡设计的压缩格式（iphone、ipad，部分安卓机）
-   不是基于块的算法，而是将图像分为了低频和高频信号

-   低频信号由两张低分辨率图像AB组成
-   高频信号则是一张记录了每个像素混合的权重值的全分辨率低精度的调制图像
-   解码时，AB图像经过双线性插值放大，然后根据调制图像权重进行混合

-   **压缩原理**

-   分为4-bpp 和 2-bpp（bpp = Bit Per Pixel，即每个像素占的位数）
-   **4-bpp为例：**

-   把4×4的像素单元压成一个64位数据块

-   64位数据块中包含了A、B两张图（在原图基础上压缩到1/4的低分辨率图像）
-   不同模式下每个像素调制数据可以得到不同的混合值，根据这个混合值用A和B混合得出最终颜色值

-   位数占比：

-   32位的调制数据（2*16）
-   1位的调制标志（也称为模式）
-   15位的颜色A（554或4433），1位颜色A的不透明标志
-   14位颜色B（555或4443），1位颜色B的不透明标志
-   共计：32 +1 + 16 + 15 = 64位

-   **压缩率**
-   以RGB为参照标准
-   压缩率 = 24 / (64/16) = 6:1
-   以RGBA为参照标准
-   压缩率 = 32 / (64/16) = 8:1

-   **2-bpp**
-   把一个8×4的像素单元压成了64位数据块

## 四、总结

### 1、画质比较

-   RGBA > ASTC 4×4> ASTC6×6 > TEC2 ≈ ETC1
-   //注：画质较为主观，且不同的贴图针对不同压缩格式也不同，仅供参考

### 2、压缩比

-   DXT1 6:1
-   DXT2/3 4:1
-   DXT4/5 4:1
-   ATI1 4:1
-   ATI2 4:1
-   BC6 6:1
-   BC7 3:1
-   ETC1 6:1
-   PVRTC 6:1
-   ASTC 4:1~35.95:1

### 3、实际应用中的选择

**PC**
-   ① 低质量使用DXT1格式不支持A通道，使用DXT5格式支持A通道；
-   ② 高质量使用BC7格式，支持A通道；

**安卓**
-   ① 低质量使用ETC1格式，但不支持A通道；
-   ② 低质量使用ETC2格式，支持A通道，需要在OpenGL ES 3.0/OpenGL 4.3以上版本；
-   ③ 高质量使用ASTC格式，需要在Android 5.0/OpenGL ES 3.1以上版本；

**IOS**
-   ① 高质量使用ASTC格式，需要Iphone6以上版本；
-   ② 低质量使用PVRTC2格式，支持Iphone6以下版本；

**补充**
-   实际手机端项目中，我们比较常用ASTC（安卓和IOS通用）
-   英伟达和Unity官方对于不同类型贴图给出了不同的压缩方案建议，感兴趣的同学可以看下：

-   Using ASTC Texture Compression for Game Assets | NVIDIA Developer
-   Unity - Manual: Recommended, default, and supported texture compression formats, by platform (unity3d.com)

五、其他补充

## ①常见分辨率及纹理压缩格式下的内存占比分析

-   在Ben Cloward大佬的视频里也有提过几嘴纹理压缩的问题，有个表还挺直观，在这里也摘过来：

-   具体可以看看我这篇笔记：[https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/wypves](https://www.yuque.com/sugelameiyoudi-jadcc/okgm7e/wypves)
# 3.7 现代移动端的TBR和TBDR渲染管线
先学习PC端的再来看。。。
[IMR, TBR, TBDR 还有GPU架构方面的一些理解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/259760974)

# 3.8 Commandbuffer及URP基础
[Command Buffers In Unity - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/news/102132)
unity方向，后续再看