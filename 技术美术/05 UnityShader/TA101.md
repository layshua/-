# 案例
## 溶解
### 透明效果
[[冯乐乐入门精要#透明效果]]
Unity 中，我们通常使用两种方法来实现透明效果：第一种是使用透明度测试(Alpha Test),这种方法其实无法得到真正的半透明效果；另一种是透明度混合 (Alpha Blending)。

**透明度测试和透明度混合的基本原理如下**：

• 透明度测试：它采用一种“霸道极端”的机制，只要一个片元的透明度不满足条件（通常是小千某个阙值），那么它对应的片元就会被舍弃。被舍弃的片元将不会再进行任何处理，也不会对颜色缓冲产生任何影响；否则，就会按照普通的不透明物体的处理方式来处理它，即进行深度测试、深度写入等。也就是说，**透明度测试是不需要关闭深度写入的**，它和其他不透明物体最大的不同就是它会根据透明度来舍弃 些片元。虽然简单，但是它产生的效果也很极端，要么完全透明，即看不到，要么完全不透明，就像不透明物体那样。

• 透明度混合： 这种方法可以得到真正的半透明效果。它会使用当前片元的透明度作为混合因子，与已经存储在颜色缓冲中的颜色值进行混合，得到新的颜色。但是，**透明度混合需要关闭深度写入**，这使得我们要非常小心物体的渲染顺序。需要注意的是，透明度混合只关闭了深度写入，但没有关闭深度测试。

**渲染引擎采用的方案**：
(1) 先渲染所有不透明物体，并开启它们的深度测试和深度写入。
(2) 把半透明物体按它们距离摄像机的远近进行排序，然后按照从后往前的顺序渲染这些半透明物体，并开启它们的深度测试，但关闭深度写入。

Unity 为了解决渲染顺序的问题提供了 **渲染队列 (render queue)** 这一解决方案。我们可以使用 **`SubShader Queue`** 标签来决定我们的模型将归于哪个渲染队列。 **Unity 在内部使用一系列整数索引来表示每个渲染队列，且索引号越小表示越早被渲染**。![[Pasted image 20221003232825.png]]
![[冯乐乐入门精要#透明度测试]]

### 使用噪声
![[冯乐乐入门精要#消融效果]]

### ASE实现
![[Pasted image 20221004114121.png]]

### Shader实现
实现裁剪效果时采用局部坐标，不采用世界坐标。原因在于当物体移动时，世界坐标发生改变无法控制裁剪效果，控制局部坐标就容易一些。
```c
Shader "Unlit/myshader"  {  
    Properties  
    {  
        _MainTex("Main Texture", 2D) = "white"{}     //贴图参数  
        _NoiseTex("Noise Texure", 2D) = "white"{}    //噪声贴图  
        _BurningValue("_BurningValue", Float) = 1  //控制噪声大小  
        _BurningWidth("_BurningWidth", Float) = 0.01  //控制溶解效果边缘宽度  
        _BurningOffset("_BurningOffset", Float) = 0.55 //   
[HDR]_Color("_Color", Color) =  (1,1,1,0)    //颜色参数,注意标注[HDR]，才能开启bloom效果  
    }  
    SubShader{  
        Tags {"RenderType" = "Opaque"}  
          
        Pass  
        {  
            CGPROGRAM  
  
            #pragma vertex vert;  
            #pragma fragment frag;  
  
            #include "UnityCG.cginc"    //头文件  
  
            //数据变量  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _NoiseTex;  
            float _BurningValue;  
            float _BurningWidth;  
            float _BurningOffset;  
            float4 _Color;  
              
            struct a2v  
            {  
                float4 vertex : POSITION;   //顶点局部坐标  
                float2 uv     : TEXCOORD0;          //顶点的uv1  
                float4 normal : NORMAL;             //顶点的法线  
                float4 color  : COLOR;              //顶点的颜色  
            };  
  
            struct v2f  
            {  
                float4 vertex       : SV_POSITION;  //顶点的裁剪坐标系下的坐标  
                float2 uv           : TEXCOORD0;    //顶点的uv  
                float4 worldNormal  : TEXCOORD1;    //顶点世界法线  
                float3 worldPosition  : TEXCOORD2;  //顶点世界坐标  
                float3 localPosition  : TEXCOORD3;  //奠定局部坐标  
            };  
  
            v2f vert(a2v v)  
            {  
                v2f o;  
                o.vertex = UnityObjectToClipPos(v.vertex);  
                o.worldNormal = mul(v.normal, unity_WorldToObject);  
                o.uv = v.uv;  
  
                o.localPosition = v.vertex.xyz; //局部坐标  
                o.worldPosition = mul(unity_ObjectToWorld, v.vertex);  
                  
                return o;  
            }  
  
            float4 frag(v2f i) : SV_Target  
            {  
                float height = i.localPosition.y + _BurningOffset; //若不加0.55，当_BurningValue为0时，会出现水平的分界线在模型原点(这个值可以随便调)  
                //采样贴图  
                float4 final = tex2D(_MainTex, i.uv);  
                float noise = tex2D(_NoiseTex, i.uv).r;    
                //noise +=0.1; //控制noise最小值为0.1,避免噪声的接近0的部分需要乘以很大的_BurningValue（用于黑色部分很多的噪声贴图）  
                float burn = noise * _BurningValue; //控制噪声大小  
                float s1 = step(height, burn);  
                float s2 = step(height, burn + _BurningWidth);  
                float colorRange = s2 - s1;     //得出溶解边缘  
                clip(height - burn);  
                return lerp(final,  _Color, colorRange);  
            }  
            ENDCG  
        }  
          
    }  
}
```






菲尼尔边缘光效果
```c
Shader "Unlit/robotshader"  {  
    Properties  
    {  
        _MainTex("Main Texture", 2D) = "white"{}     //贴图参数  
        _NoiseTex("Noise Texure", 2D) = "white"{}    //噪声贴图  
        _BurningValue("_BurningValue", Float) = -6  //控制噪声大小  
        _BurningWidth("_BurningWidth", Float) = 0.1  //控制溶解效果边缘宽度  
        _BurningOffset("_BurningOffset", Float) = 0.55   
[HDR]_Color("_Color", Color) =  (1,1,1,0)    //颜色参数,注意标注[HDR]，才能开启bloom效果  
        //菲涅尔  
        _FresnelScale("FresnelScale", Range(0,0.05)) = 0  
        [HDR]EdgeColor("FresnelColor", COLOR) = (1,1,1,1)  
          
          
    }  
    SubShader{  
        Tags {"RenderType" = "Opaque"}  
          
        Pass  
        {  
            CGPROGRAM  
  
            #pragma vertex vert;  
            #pragma fragment frag;  
  
            #include "UnityCG.cginc"    //头文件  
  
            //数据变量  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _NoiseTex;  
            float _BurningValue;  
            float _BurningWidth;  
            float _BurningOffset;  
            float4 _Color;  
            float _FresnelScale;  
            fixed4 EdgeColor;  
              
            struct a2v  
            {  
                float4 vertex : POSITION;   //顶点局部坐标  
                float2 uv     : TEXCOORD0;          //顶点的uv1  
                float4 normal : NORMAL;             //顶点的法线  
                float4 color  : COLOR;              //顶点的颜色  
            };  
  
            struct v2f  
            {  
                float4 vertex       : SV_POSITION;  //顶点的裁剪坐标系下的坐标  
                float2 uv           : TEXCOORD0;    //顶点的uv  
                float4 worldNormal  : TEXCOORD1;    //顶点世界法线  
                float3 worldPosition  : TEXCOORD2;  //顶点世界坐标  
                float3 localPosition  : TEXCOORD3;  //奠定局部坐标  
            };  
  
            v2f vert(a2v v)  
            {  
                v2f o;  
                o.vertex = UnityObjectToClipPos(v.vertex);  
                o.worldNormal = mul(v.normal, unity_WorldToObject);  
                o.uv = v.uv;  
  
                o.localPosition = v.vertex.xyz;   
                o.worldPosition = mul(unity_ObjectToWorld, v.vertex);  
                  
                return o;  
            }  
  
            float4 frag(v2f i) : SV_Target  
            {  
                float3 viewDir = UnityWorldSpaceViewDir(i.worldPosition);  
                float3 worldNormal = normalize(i.worldNormal);  
  
                //Schlick菲涅尔近似式  
                float Fresnel =  _FresnelScale+ (1 -_FresnelScale) * pow(1 - saturate(dot(worldNormal,viewDir)), 5);  
                  
                float4 FresnelColor = EdgeColor * Fresnel;  
                  
                float height = i.localPosition.y + _BurningOffset;   
                float4 final = tex2D(_MainTex, i.uv) + FresnelColor;  
                float noise = tex2D(_NoiseTex, i.uv).r;    
                  
                      
                float burn = noise * _BurningValue * _CosTime.z * 5;; //控制噪声大小  
                float s1 = step(height, burn);  
                float s2 = step(height, burn + _BurningWidth);  
                float colorRange = s2 - s1;     //得出溶解边缘  
                clip(height - burn);  
                  
                return lerp(final, _Color, colorRange);  
            }  
            ENDCG  
        }  
    }  
}
```
## ASE全息投影
投光：锥形模型+同形状贴图（PS画一个）+噪音
山：
1. 边缘光 
2. 线条（纹理采样或者用世界坐标） 
3. 扩散圈，从中间到边缘越来越暗。世界坐标求圈的范围
4. 从边缘到中心的高光
5. 线 ：mesh uv滚动  unity自带：Line Renderer
7. 球：边缘光
8. 红色区域：直接贴图或者使用一个建模

### 透明效果设置
![[Pasted image 20221006144843.png|300]]
### 锥体投影光
#### 透明度衰减
使用uv可以对水平和竖直方向进行透明度衰减![[Pasted image 20221007163814.png]]
#### 表面波动
这里使用的**Vronoi节点**可以进行多种效果变换。
[Voronoi](http://wiki.amplify.pt/index.php?title=Unity_Products:Amplify_Shader_Editor/Voronoi)![[Pasted image 20221007164401.png]]
#### 噪音跳动
Random Range节点：根据输入Seed返回一个伪随机数值，该值位于输入Min和Max分别定义的最小值和最大值之间![[Pasted image 20221007164610.png]]
不使用噪声纹理，直接使用uv坐标也可以实现![[Pasted image 20221007164814.png]]
### 山地
#### 菲涅尔边缘光
![[Pasted image 20221009230406.png]]
#### 方格线
基于顶点坐标的方格线![[Pasted image 20221007165548.png]]
#### 扫描
基于顶点与原点的距离：从中间到两边扫描![[Pasted image 20221007170254.png]]
基于世界坐标高度：从下到上![[Pasted image 20221007170619.png]]
### 发光组件
#### 闪烁
![[Pasted image 20221007170749.png]]
#### 线条移动
横向：使用unity内置object3d，Line![[Pasted image 20221007171035.png]]
旋转时钟：基于极坐标, 所用模型uv也是一圈![[Pasted image 20221007171829.png|200]]![[Pasted image 20221007171134.png]]
## 琥珀
### 制作流程
1.表现需求    如：琥珀材质（纯表现）
->合理？
2.渲染特性   如：漫反射、高光、反射、透射（与原画确认）
->可行性？
3.特性实现
如： （1）现有Shader能否满足？（PBR，UberEffect等）
	    （2）与环境的关系（天气变换，阴影，氛围，融合等）
	    （3）具体实现
->尽早反馈
4.迭代反馈
如：（1）反馈迭代
	（2）优化（性能要求，代码优化，贴图合并复用等）
### 渲染特性
![[Pasted image 20221009224517.png]]
                                     不均匀内部介质：视差贴图

ASE中CubeMap使用前的设置
![[Pasted image 20221010093658.png|300]]
![[Pasted image 20221010093722.png|300]]
蚊子先渲染，琥珀后渲染：将蚊子的渲染队列改小点1800
抓起已经渲染过的蚊子，再以屏幕空间采样的方式显示出来，还加上了折射
### 流程
#### 1.高亮折痕
![[Pasted image 20221015154226.png]]![[Pasted image 20221015154255.png]]
#### 2.CheapSSS透射
![[Pasted image 20221015154315.png]]
#### 3.Bubble 气泡
![[Pasted image 20221015154356.png]]![[Pasted image 20221015154406.png]]
#### 4. 湖泊底色
![[Pasted image 20221015154423.png]]
#### 5.  光照
![[Pasted image 20221015154444.png]]![[Pasted image 20221015154458.png]]
#### 6. MatCap
![[Pasted image 20221015154513.png]]
#### 7.CubeMap
![[Pasted image 20221015154529.png]]
#### 8.SceneTexColor
![[Pasted image 20221015154552.png]]
#### 9.SceneColor
![[Pasted image 20221015154618.png]]
#### 10.result
![[Pasted image 20221015154933.png]]
#### 代码
```c#
Shader "Unlit/code_amber"  
{  
    Properties  
    {  
        [Header(Texture)]  
        [Space(5)]  
        _MainTex ("MainTex", 2D) = "white" {}  
        _amber_n1 ("amber_n1", 2D) = "white" {}  //NormalMap  
        _amber_n2 ("amber_n2", 2D) = "white" {}  //NormalMap  
        _amber_bubble("amber_bubble", 2D) = "white" {}    
        _ambermix("amber_bubble", 2D) = "white" {}    
        _MatCap("MatCap",2D) = "white" {}  
        _CubeMap("CubeMap",Cube) = "white" {}  
        _normals_exporthr("normals_exporthr", 2D) = "white" {}  
          
        [Header(ParallaxMap)]  
        [Space(5)]  
        _ParallaxHeight("CreaseParallaxHeight",float) = 1.2  
        _ParallaxScale("CreaseParallaxScale",float) = 1  
        [Header(Crease)]  
        [Space(5)]  
        _CreaseFresnelScale("CreaseFresnelScale", Range(0,1)) = 0.1  
        _CreaseFresnelColor("CreaseFresnelColor", Color) = (1,1,1,1)  
          
        [Header(CheapSSS)]  
        [Space(5)]  
        _CheapSSSAngle ("CheapSSSAngle", Range(0,1)) = 0.3  
        _CheapSSSExp("CheapSSSExp",float) = 1  
        _CheapSSSScale("CheapSSSExp",float) = 1  
        _CheapSSSColor("CheapColor",Color) = (1,1,1,1)  
          
        [Header(BubbleParallaxUV)]  
        [Space(5)]  
        _BubbleParallaxUVHeight("BubbleParallaxUVHeight",float) = 1.2  
        _BubbleParallaxUVScale("BubbleParallaxUVScale",float) = 1.9  
        _BubbleParallaxUVOffset("BubbleParallaxUVOffset",float) = 4.43  
        _BubbleColor("BubbleColor",Color) = (1,1,1,1)  
          
        [Header(FlowNoise)]  
        [Space(5)]  
        _AmberColor("AmberColor",Color) = (1,1,1,1)  
        _lerpColor1("lerpColor1",Color) = (0.4,0.4,0.4,0)  
        _lerpColor2("lerpColor1",Color) = (1,1,1,0)  
          
        [Header(CubeMap)]  
        [Space(5)]  
        _CubeMapFresnelScale("CubeMapFresnelScale", Range(0,1)) = 0.1  
        _CubeMapFresnelIntensity("_CubeMapFresnelIntensity",float) =1  
        [Header(Specular)]  
        [Space(5)]  
        _SpecularExp("_SpecularExp",float) = 1  
        _SpecularScale("_SpecularScale",float) = 1  
        [Header(SceenTexColor)]  
        [Space(5)]  
        _SceenUVlerp("SceenUVlerp",Range(0,1)) = 0.8  
        _SceenUVScale("SceenUVScale",float) =1  
        _SceenTexColor("SceenUVColor",Color) = (1,1,1,1)  
          
        [Header(SceenColor)]  
        [Space(5)]  
        _RefractRatio("RefractRatio",Range(0,1)) = 0.6  
        _SceneDistortionIntensity("_SceneDistortionIntensity",Range(0,1)) = 0.05  
        _FinalColorAlpha("FinalColor_Alpha",Range(0,1)) = 0.5  
        }  
    SubShader  
    {  
        GrabPass{"_ScreenTex"}  
        Tags { "RenderType"="Opaque" }  
        LOD 100  
  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
  
            #include "UnityCG.cginc"  
            #include "AutoLight.cginc"  
  
            struct appdata  
            {  
                float4 vertex : POSITION;  
                float3 normal : NORMAL;  
                float4 tangent : TANGENT;  
                float2 uv : TEXCOORD0;  
            };  
  
            struct v2f  
            {  
                float4 vertex : SV_POSITION;  
                float2 uv : TEXCOORD0;  
                float3 normal : TEXCOORD1;  
                float3 tangent : TEXCOORD2;  
                float3 bitanget : TEXCOORD3;  
                float3 worldPosition : TEXCOORD4;  
                float3 localPosition : TEXCOORD5;  
                float3 localNormal : TEXCOORD6;  
                float4 ScreenPos : TEXCOORD7;  
                  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _amber_n1;  
            sampler2D _amber_n2;  
            sampler2D _amber_bubble;  
            sampler2D _ambermix;  
            sampler2D  _MatCap;  
            samplerCUBE _CubeMap;  
            sampler2D _normals_exporthr;  
            sampler2D _ScreenTex;  
              
            //ParallaxMap  
            float _ParallaxHeight, _ParallaxScale;  
              
            //Crease  
            float _CreaseFresnelScale;  
            float4 _CreaseFresnelColor;  
  
            //CheapSSS  
            float _CheapSSSAngle;  
            float _CheapSSSExp;  
            float _CheapSSSScale;  
            float4 _CheapSSSColor;  
  
            //Bubble  
            float _BubbleParallaxUVHeight,_BubbleParallaxUVScale,_BubbleParallaxUVOffset;  
            float4  _BubbleColor;  
                  
            //FlowNoise  
            float4 _AmberColor,_lerpColor1,_lerpColor2;  
  
            //MatCap  
            float4 _MatCap_ST;  
              
            //CubeMap  
            float _CubeMapFresnelScale;  
            float _CubeMapFresnelIntensity;  
            //Specular  
            float _SpecularExp, _SpecularScale;  
  
            //SceneTexColor  
            float _SceenUVlerp;  
            float _SceenUVScale;  
            float4 _SceenTexColor;  
  
            //ScreenColor  
            float _RefractRatio;  
            float _SceneDistortionIntensity;  
  
            float  _FinalColorAlpha;  
            v2f vert (appdata v)  
            {  
                v2f o;  
                o.vertex = UnityObjectToClipPos(v.vertex);  
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);  
                o.normal = UnityObjectToWorldNormal(v.normal);  
                o.tangent = UnityObjectToWorldDir(v.tangent);  
                o.bitanget = cross(o.normal, o.tangent) * v.tangent.w;  
                o.worldPosition = mul(unity_ObjectToWorld, v.vertex);  
                o.localPosition = v.vertex.xyz;  
                o.localNormal = v.normal;  
                o.ScreenPos = ComputeScreenPos(o.vertex);  
                return o;  
            }  
  
            fixed4 frag (v2f i) : SV_Target  
            {  
                float3x3 TBN = float3x3(normalize(i.tangent),normalize(i.bitanget),normalize(i.normal));  
                float3 world_Normal = normalize(i.normal);  
                float3 world_LightDir = normalize(UnityWorldSpaceLightDir(i.worldPosition));  
                float3 world_ViewPos = normalize(UnityWorldSpaceViewDir(i.worldPosition));  
                //左乘TBN 从世界空间转换到切线空间  
                float3 tangent_ViewPos = normalize(mul(TBN, world_ViewPos));  
  
                //ParallaxMap  
                float2 ParrallaxMap = ((_ParallaxHeight - 1) * tangent_ViewPos.xy * _ParallaxScale) + i.uv;  
                  
                //高亮折痕 Crease  NormalMap + Fresnel                float3 CreaseNormalMap = normalize(mul(UnpackNormal(tex2D(_amber_n2,ParrallaxMap)), TBN));  
                float CreaseFresnel = _CreaseFresnelScale+ (1 -_CreaseFresnelScale) * pow(1 - saturate(dot(CreaseNormalMap, world_ViewPos)), 5);  
                float4 Crease = mul(CreaseFresnel, _CreaseFresnelColor);  
  
                //CheapSSS 透射  
                float3 CheapSSSNormalMap = normalize(mul(UnpackNormal(tex2D(_amber_n1,i.uv)), TBN));  
                float4 CheapSSSEdge = pow(dot(normalize(-lerp(CheapSSSNormalMap, world_LightDir, _CheapSSSAngle)),world_ViewPos),_CheapSSSExp) * _CheapSSSScale;  
                float4 CheapSSS = CheapSSSEdge * _CheapSSSColor;  
  
                //Bubble  
                //BubbleParallaxMap                float2 BubbleParrallaxMap = ((_BubbleParallaxUVHeight-1) * tangent_ViewPos.xy * _BubbleParallaxUVScale) + (i.uv * _BubbleParallaxUVOffset);  
  
                float3 BubbleTex = tex2D(_amber_bubble, BubbleParrallaxMap);  
                float4 Bubble = BubbleTex.g * _BubbleColor;  
  
                //FlowNoise 琥珀底色  
                float3 FlowNoiseMap = tex2D(_ambermix, ParrallaxMap);  
                float4 FlowNoise = lerp(_lerpColor1, _lerpColor2,FlowNoiseMap.g) * _AmberColor;  
                  
                //MatCap  
                float3 view_Normal = mul(unity_MatrixV, world_Normal);  
                float3 view_Normal01 = view_Normal * 0.5 + 0.5;  
                float3 MatCaptexture = tex2D(_MatCap, view_Normal01.xy);  
                float4 MatCap = float4(MatCaptexture,1);  
  
                //CubeMap  
                float3 Reflect = reflect(-world_ViewPos,world_Normal);  
                float3 CubeMaptexture = texCUBE(_CubeMap, Reflect);   
                float CubeMapFresnel = _CubeMapFresnelScale+ (1 -_CubeMapFresnelScale) * pow(1 - saturate(dot(CreaseNormalMap, world_ViewPos)), 5);  
                float4 CubeMap = float4(CubeMaptexture * CubeMapFresnel *_CubeMapFresnelIntensity,1);  
                  
                  
                //Diffuse  
                float4 Diffuse = dot(world_Normal,world_LightDir) * 0.5 + 0.5;  
                  
                //Specular  
                float3 SpecularNormalMap = normalize(mul(UnpackNormal(tex2D(_amber_n2, i.uv)), TBN));  
                float3 Half_Vector = normalize(world_ViewPos + world_LightDir);  
                float4 Specular = pow(max(0, dot(SpecularNormalMap,Half_Vector)),_SpecularExp) * _SpecularScale;  
  
                //SceneTexColor  
                float2 ScreenTexUV = lerp(i.uv,normalize(i.ScreenPos),_SceenUVlerp)* _SceenUVScale;  
                float4 SceneTexColor = tex2D(_amber_bubble, ScreenTexUV).r * _SceenTexColor;  
  
                //SceneColor 折射  
                float3 SceneColorNormalMap = normalize(mul(UnpackNormal(tex2D(_normals_exporthr,i.uv)), TBN));  
                float3 Refract = refract(-world_ViewPos,SceneColorNormalMap,_RefractRatio);   
                float3 tangent_Refract = normalize(mul(TBN, Refract));  
                float4 SceneColor = tex2D(_ScreenTex, (normalize(i.ScreenPos) + tangent_Refract * _SceneDistortionIntensity));  
                  
                float4 finalColor = lerp(SceneColor,Crease+Bubble+FlowNoise+MatCap+CubeMap+Specular + SceneTexColor, _FinalColorAlpha);  
                  
                return finalColor;  
            }  
            ENDCG  
        }  
    }  
}
```
## 温斯特的能量盾（需要重看）
![[TA101_作业_温斯顿的能量盾_3.jpg]]
### 接触描边效果
![[TA101_作业_温斯顿的能量盾_4.jpg]]
![[TA101_作业_温斯顿的能量盾_5.jpg]]
**深度图和屏幕uv坐标可以反推出世界坐标？**
![[TA101_作业_温斯顿的能量盾_6.jpg]]
#### 深度交接出白边
![[Pasted image 20221101170800.png]]
#### 深度过渡颜色
![[Pasted image 20221101170818.png]]
lerp之后的最终效果
![[Pasted image 20221101170834.png]]
其中Step颜色为：lerp后白色部分为交界处白边，上面部分为过渡颜色
![[Pasted image 20221101170939.png]]

![[Pasted image 20221101170859.png]]
### Fresnel外表面
![[Pasted image 20221101173938.png]]
![[Pasted image 20221101174026.png]]


### 交互：碰撞冲击波(待学习)

![[TA101_作业_温斯顿的能量盾_7.jpg]]

```c#
Vector4[] _HitPoints;  //x,y,z代表位置，w代表范围
//w值为[0~1】 碰撞点有效 如果为负数无效（在shader中计算）

Shader.SetGlobalVectorArray("_HitPoints", _HitPoints);
//该方法影响全局
//也可以采用只影响一个材质的方法：
Material.SetXXXX()


```




# 【第一章】Shader基础
## 颜色
**RGB**比较常用（负数都显示成黑色）
**HSV** (Hue, Saturation, Value)
色调（H）、饱和度（S）和明度（V）
Hexadecimal：十六进制
![[Pasted image 20221003152912.png|200]]
## uv
uv坐标从左至右，从下至上，范围0~1

## ASE
[Amplify Shader Editor 1.8.9.012.unitypackage_免费高速下载|百度网盘-分享无限制 (baidu.com)](https://pan.baidu.com/s/1xEPdaZxlO5tgyJV6iJm1qA?pwd=ea6y)
[Amplify Shader Editor手册(中文版)](https://blog.csdn.net/DebuggerPrisonBreak/article/details/85863719?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%2285863719%22%2C%22source%22%3A%22weixin_45532761%22%7D)
#### 导入ASE包

![[f3f9315d439f2cf23ca4c577bde76cea_MD5.webp]]

或者直接拖拽到Projects窗口下的的Assets文件中，全部一键导入

![[6e80998d06f18d327b6058d5bb649911_MD5.webp]]

#### 基础界面了解

![[1f32446287aa8542cd389ed022b92b67_MD5.webp]]

打开canvas即可进入基础界面

![[891be26a168e528012352418f20ce08f_MD5.webp]]

都是熟悉的单词，看看就好，后面用多就记住了

![[55966892d8a91fe06a2e8529f5a31080_MD5.webp]]

看到中间的窗口，最上方

![[d7ac2ee3ae813367ab1517caab28bcfc_MD5.webp]]

从左到右依次是

1.创建并应用shader至材质

2.自动保存

3.在默认的shader编辑器打开shader文件

4.5.分享节点，屏幕拍照

6.节点屏幕居中

7.关注主节点

8.删除未被连接的多余节点

自己想跟着学的话可以直接进大佬的群，里面有资料。
下面是一些常用节点

![[e87c2810ab7515b4f0a558b8267bd081_MD5.webp]]
#### 操作
xyz面分别显示对应图片，此时-x-y-z面颜色值为-1黑色
![[Pasted image 20221003172541.png|300]]![[Pasted image 20221003172610.png]]
六面显示![[Pasted image 20221003174221.png]]

## 时间控制
_Time 用来驱动shader内部的动画。我们可以用它来计算时间的变换。基于此可以在shader中实现各种动画效果。  
官方提供了下面几个变量供我们使用
```csharp
//t是自该场景加载开始所经过的时间，4个分量分别是 (t/20, t, t*2, t*3)
_Time   float4  time (t/20, t, t*2, t*3),   
//t 是时间的正弦值，4个分量分别是 (t/8, t/4, t/2, t)
_SinTime    float4  Sine of time: (t/8, t/4, t/2, t).
//t 是时间的余弦值，4个分量分别是 (t/8, t/4, t/2, t)
_CosTime    float4  Cosine of time: (t/8, t/4, t/2, t).
//dt 是时间增量，4个分量的值分别是(dt, 1/dt, smoothDt, 1/smoothDt)
nity_DeltaTime  float4  Delta time: (dt, 1/dt, smoothDt, 1/smoothDt).
```
如果使用 fixed x= Speed * _Time; 等价于 fixed x= Speed * _Time.x;

_Time各个分量的值如下：

_Time.x = time / 20  
_Time.y = time  
_Time.z = time * 2  
_Time.w = time * 3

那么_SinTime.w 等价于 sin(_Time.y)

## 绕轴旋转
两种方法，C#脚本拖到模型上。
```C#
public class RobotRotate : MonoBehaviour  
{  
    public float speed=90f;  
    void Start()  
    {   
            
    }  
    void Update()  
    {  
        transform.Rotate(Vector3.right*Time.deltaTime*speed);  
    }  
  
//right（右）：代表坐标轴（1,0,0）
//left （左）：代表坐标轴（-1,0,0）
//up（上） :代表坐标轴（0,1,0）
//down （下）： 代表坐标轴（0,-1,0）
//forward （前）：代表坐标轴（0,0,1）
//back（后）：代表坐标轴（0,0,-1）
//zero（零）：代表坐标轴（0,0,0）
//one（一）：代表坐标轴（1,1,1）
}
```

```c#
void Update()
	{
		//当按着键盘的空格键时，物体就开始围绕自身的x轴进行旋转
		if (Input.GetKey(KeyCode.Space))
		{
			//如果是围绕自身的x轴进行旋转，就是transform.Rotate(new Vector3(1, 0, 0));
			//如果是围绕自身的y轴进行旋转，就是transform.Rotate(new Vector3(0, 1, 0));
			//如果是围绕自身的z轴进行旋转，就是transform.Rotate(new Vector3(0, 0, 1));
			transform.Rotate(new Vector3(1, 0, 0));
		}
	}

```
## 后处理插件
![[Pasted image 20221003194609.png]]![[Pasted image 20221004163454.png]]拖进相机中即可

## 自定义函数
creat -> Amplify Shader Function
![[Pasted image 20221003202058.png]]


# 【第二章】光照模型

![[Pasted image 20221005153922.png]]![[Pasted image 20221005160726.png]]![[Pasted image 20221005160805.png]]![[Pasted image 20221005231913.png]]

```less
float3 world_LightDir = normalize(UnityWorldSpaceLightDir(i.worldPosition));
//通过这个求得的是顶点指向光源的方向，使用reflect函数时要取反
//reflect(i,n)
//i是入射方向（光指向顶点的方向），n是法线方向。
float world_Reflect = reflect(-world_LightDir, world_Normal);
```

## ASE实现
### 输入
注意设置成normalize![[Pasted image 20221007220753.png]]
### 要注意的问题
1. 单位问题，向量点积得到的都是常数，而不是向量
2. lambert/phong/BlinnPhong 点积的结果要使用max（0，x）限制
3. 运用自定义函数控制光照结果，并且没有控制光照颜色，并不是很严谨。更严谨的运算参考入门精要。本课程的方法仍符合原理。
### 自定义函数
用于参数控制，先幂再乘
![[Pasted image 20221005220249.png]]
### 漫反射
#### Lambert
![[Pasted image 20221005214517.png]]
#### Half Lambert
![[Pasted image 20221005214604.png]]
#### WarpLight
不常用
![[Pasted image 20221005214627.png]]
#### BandedLight
![[Pasted image 20221005215351.png|300]]
条带化效果常用于卡渲，一般分两段
![[Pasted image 20221005214707.png]]
![[Pasted image 20221005214731.png]]
### 高光
#### Phong
![[Pasted image 20221007222614.png]]
#### Blinn Phong
![[Pasted image 20221007222630.png]]
### 背光cheapSSS
![[Pasted image 20221005215611.png|300]]
![[Pasted image 20221005214850.png]]

### 输出
![[Pasted image 20221007223010.png]]
## 代码实现
![[Pasted image 20221007221541.png]]

```c++
Shader "Unlit/NewUnlitShader"  
{  
    Properties  
    {  
        _MainTex ("Texture", 2D) = "white" {}  
        _Value("Value", Float) = 1  
        _Color("Color",Color) = (1,1,1,1)  
          
        [Space(10)]   
        _PhongExp("PhongExp",Float) = 1  
        _PhongScale("PhongScale",Float) = 1  
        [Space(10)]   
        _BlinnPhongExp("BlinnPhongExp",Float) = 1  
        _BlinnPhongScale("BlinnPhongScale",Float) = 1  
        _WrapValue("WrapValue",Float) =1  
        [Space(10)]  //属性面板加几个空格，用于排版  
        _CheapSSSValue("CheapSSSValue",Float) =0.5  
        _CheapSSSExp("CheapSSSPhongExp",Float) = 1  
       _CheapSSSScale("CheapSSSPhongScale",Float) = 1  
        }  
    SubShader  
    {  
        Tags { "RenderType"="Opaque" "LightMode" = "ForwardBase" "Queue" = "Geometry"}  
          
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
  
            #include "UnityCG.cginc"  
            #include "AutoLight.cginc"  
            struct appdata  
            {  
                float4 vertex       : POSITION;  
                float2 uv1           : TEXCOORD0;  
                float2 uv2          : TEXCOORD1;  
                float3 normal       : NORMAL;  
                float4 tangent      : TANGENT;  
                float4 vertexColor  : COLOR;  
            };  
  
            struct v2f  
            {  
                float4 pos           : SV_POSITION;  
                float2 uv1            : TEXCOORD0;  
                float3 normal        : TEXCOORD1;  
                float3 tangent       : TEXCOORD2;  
                float3 bitangent     : TEXCOORD3;  
                float3 worldPosition : TEXCOORD4;  
                float3 localPosition : TEXCOORD5;  
                float3 localNormal   : TEXCOORD6;  
                float4 vertexColor   : TEXCOORD7;  
                float2 uv2           : TEXCOORD8;  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            float _PhongExp,_PhongScale;  
            float _BlinnPhongExp,_BlinnPhongScale;  
            float _WrapValue;  
            float _CheapSSSValue,_CheapSSSExp,_CheapSSSScale;  
              
            v2f vert(appdata v)  
            {  
                v2f o;  
                o.pos = UnityObjectToClipPos(v.vertex);  
                  
                o.uv1 = TRANSFORM_TEX(v.uv1, _MainTex); 
                o.uv2 =  TRANSFORM_TEX(v.uv2, _MainTex); 
                o.normal = UnityObjectToWorldNormal(v.normal);  
                o.worldPosition = mul(unity_ObjectToWorld, v.vertex);  
                o.localPosition = v.vertex.xyz;  
                o.tangent = UnityObjectToWorldDir(v.tangent);  
                o.bitangent = cross(o.normal, o.tangent) * v.tangent.w;;  
                o.localNormal = v.normal;  
                o.vertexColor = v.vertexColor;  
  
                return o;  
            }  
  
            float4 frag(v2f i) : SV_Target  
            {  
                float3 world_Normal = normalize(i.normal);  
                float3 world_LightDir = normalize(UnityWorldSpaceLightDir(i.worldPosition));  
                float3 world_ViewPos = normalize(UnityWorldSpaceViewDir(i.worldPosition));  
                //注意第一个参数为负数  
                float3 world_Reflect = normalize(reflect(-world_LightDir, world_Normal));  
                float3 world_HalfVector = normalize(world_LightDir + world_ViewPos);  
  
                //纹理采样  albedo:反射率 注意这里给的源氏模型必须用uv2  
                float4 albedo = tex2D(_MainTex, i.uv2);  
                  
                //Diffuse  
                float NL = dot(world_Normal ,world_LightDir);  
                float Lambert = max(0, NL);      
                float Half_Lambert = NL * 0.5 + 0.5;      
                float BandedLight = floor((NL * 0.5 + 0.5) *4)/4;      
  
                //BackLight  
                //沿着光线方向偏移法线，最后再取反  
                float3 N_Shift = -normalize(world_Normal * _CheapSSSValue + world_LightDir);  
                float BackLight = pow(saturate(dot(N_Shift, world_ViewPos)),_CheapSSSExp) * _CheapSSSScale;  
                  
                //Specular  
                float VR = dot(world_ViewPos, world_Reflect);  
                float phong = pow(max(0, VR), _PhongExp) * _PhongScale;  
                float NH = dot(world_Normal, world_HalfVector);  
                float BlinnPhong = pow(max(0, NH), _BlinnPhongExp) * _BlinnPhongScale;  
                  
                float4 Ambient = UNITY_LIGHTMODEL_AMBIENT;  
                float4 Diffuse = Half_Lambert;  
                float4 Specular = BlinnPhong;  
                float4 FinalColor = (Ambient+ Diffuse + BackLight) * albedo + Specular;  
                  
                return FinalColor;  
            }  
            ENDCG  
        }  
    }  
}
```


# 【第三章】Map
Map 都可翻译成贴图，对应实现的功能称为映射Maping。
如法线贴图->法线映射
## NormalMap
### 解析
使用法线贴图要先把坐标从切线空间转换到世界空间（TBN矩阵）![[Pasted image 20221007190257.png]]![[Pasted image 20221007190456.png]]
法线贴图通常存储为常规RGB图像，其中RGB分量分别对应于表面法线的X，Y和Z坐标。
法线的每个分量的值的范围是 [−1,1] ，而RGB分量的值的范围是 [0,1] 。所以，在将法线存储为RGB图像时，需要对每个分量做一个映射：
```
vec3rgb_normal = normal ∗ 0.5 + 0.5
```
这里要注意，**将法线存储到法线贴图的过程中，需要进行上述操作。当我们从法线贴图中读取到法线数据后，需要进行上述变换的**<font color="#ff0000">逆变换</font>，即从 [0,1] 映射到 [−1,1] 。
```
normal = 2 * vec3rgb_normal - 1
```
**Unity内置函数`UnpackNormal`，可以实现该功能（并且支持跨平台转换）。记得纹理类型改为NormalMap。**

[[图形学奇点#法线#为什么要定义切线空间]]中提到使用切线空间保存切线的一个优点：可以压缩。因为切线空间的法线z方向总是正方向，因此可以仅存储xy方向，从而推到z方向（normal是单位向量，用勾股定理由xy得出z，取z为正的一个即可）。而模型空间的法线纹理方向各异，无法压缩。**对应法线贴图在Unity中的压缩格式：**

>[!note]
>  - 在非移动平台上，会把法线贴图转化为DXRT5nm格式。这个格式只有两个有效GA通道（就是上边说的只存xy，推出z） ，分别对应法线的y、x分量可以节省空间。
>   - 在移动平台上，使用传统RGB通道。

![[Pasted image 20221023230557.png]]
![[Pasted image 20221023230559.png]]
-   关于normal.xy *= scale；的解释
-   是对法线的扰动效果进行缩放

![[Pasted image 20221007191501.png]]
**切线空间中是右手法则！！！计算副切线时需要乘上 tangent w是因为unity 引擎历史遗留问题。
>[!note]
>转置矩阵：
设有矩阵x，y。x的转置矩阵为x<sup>T</sup>，以下式子相等
mul（x<sup>T</sup>，y） = mul（y，x）

代码如下，主要区别在于采样后计算漫反射和高光都要使用NormalMap转换到世界空间后的坐标替代world_normal。

### Unity中的法线纹理类型
![[Pasted image 20221206102034.png|300]]
把纹理类型设置为Normal map才能使用UNity的内置函数`UnpackNormal`来计算法线方向。
`Create form Grayscale`适用于另一种凹凸映射的方法——高度图。整个复选框适用于从高度图生成法线纹理的。高度图本身记录的是相对高度，是一张灰度图，白色表示更高，黑色表示更低。当我们把一高度图导入unity后除了要设置normal map还要勾选这个，这样就可以把高度图和切线空间下的法线纹理同等对待了。Bumpiness控制凹凸成都，Filtering决定用哪种方式计算凹凸程度。

### 代码
![[Pasted image 20221206101713.png|300]]

```c
Shader "Unlit/NormalMap"  
{  
    Properties  
    {  
        _MainTex ("Texture", 2D) = "white" {}  
        _NormalMap("NormalMap",2D) = "white" {}  
        _Color("Color",Color) = (1,1,1,0)  
          
        [Header(BlinnPhong)]  
        [Space(15)]  
        _NormalMapScale("NormalMapScale",Float) = 1  
        _PowerValue("PowerValue", Float) = 4  
        _PowerScale("PowerScale",Float) = 1  
        }  
    SubShader  
    {  
        Tags { "RenderType"="Opaque" "LightMode" = "ForwardBase" "Queue" = "Geometry"}  
  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert   
            #pragma fragment frag  
  
            #include "UnityCG.cginc"  
            #include "AutoLight.cginc"  
  
            struct appdata  
            {  
                float4 vertex : POSITION;  
                float2 uv : TEXCOORD0;  
                float3 nomral : NORMAL;  
                float4 tangent : TANGENT;  
                float4 vertexColor : COLOR;  
            };  
  
            struct v2f  
            {  
                float4 pos : SV_POSITION;  
                float2 uv : TEXCOORD0;  
                float3 normal : TEXCOORD1;  
                float3 tangent : TEXCOORD2;  
                float3 bitangent : TEXCOORD3;  
                float4 worldPostion : TEXCOORD4;  
                float3 localPosition : TEXCOORD5;  
                float3 localNormal : TEXCOORD6;  
                float4 vertexColor : TEXCOORD7;  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _NormalMap;  
            float4 _NormalMap_ST;  
            float _NormalMapScale;  
            float _PowerValue, _PowerScale;  
  
            v2f vert (appdata v)  
            {  
                v2f o;  
                o.pos = UnityObjectToClipPos(v.vertex);  
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);  
                o.normal = UnityObjectToWorldNormal(v.nomral);  
                o.tangent = UnityObjectToWorldDir(v.tangent);  
                o.bitangent = cross(o.normal, o.tangent) * v.tangent.w;  
                o.worldPostion = mul(unity_ObjectToWorld, v.vertex);  
                o.localPosition = v.vertex.xyz;  
                o.localNormal = v.nomral;  
                o.vertexColor = v.vertexColor;  
                  
                return o;  
            }  
  
            fixed4 frag (v2f i) : SV_Target  
            {  
                // 用TBN矩阵处理NormalMap  
                float3 T = normalize(i.tangent);  
                float3 B = normalize(i.bitangent);  
                float3 N = normalize(i.normal);  
                float3x3 TBN = float3x3(T,B,N);  
                  
                float3 NormalMap = UnpackNormal((tex2D(_NormalMap, i.uv)));  
                  
                //控制凹凸程度  
                NormalMap.xy *= _NormalMapScale;  
                NormalMap.z = sqrt(1-saturate(dot(NormalMap.xy,NormalMap.xy)));  
                  
                // 将NormalMap从切线空间转换到世界空间  
                float3 world_NormalMap = normalize(mul(NormalMap, TBN));  
  
                // 光照计算  
                float3 world_LightDir = normalize(UnityWorldSpaceLightDir(i.worldPostion));  
                float3 world_ViewPos = normalize(UnityWorldSpaceViewDir(i.worldPostion));  
                float3 world_HalfVector = normalize(world_LightDir + world_ViewPos);  
                  
                float4 albedo = tex2D(_MainTex, i.uv);  
  
                // Diffuse  
                float Lambert = max(0, dot(world_NormalMap, world_LightDir));  //注意这里 法线方向 用 NormalMap 来替代  
                //Specular  
                float NH = dot(world_NormalMap, world_HalfVector);  //注意这里 法线方向 用 NormalMap 来替代  
                float BlinnPhong = pow(max(0,NH) ,_PowerValue) * _PowerScale;  
  
                float4 Ambient = UNITY_LIGHTMODEL_AMBIENT;  
                float4 Diffuse = Lambert;  
                float4 Specular = BlinnPhong;  
                float4 finalColor = (Ambient + Diffuse) * albedo + Specular;  
                return finalColor;  
            }  
            ENDCG  
        }  
    }  
}
```

凹凸控制部分的解释：
```c
NormalMap.xy *= _NormalMapScale;  
NormalMap.z *= sqrt(1-saturate(dot(NormalMap.xy,NormalMap.xy)));
```
xy分量乘上_NormalMapScale。因为z轴是原法线方向，所以可以想象一下，将向量的xy分量进行缩放后，它就更加朝着原来的偏移方向倾斜了，所以就变的更凹进或者更凸起。  
因为normal需要是一个单位向量，所以变换了xy之后需要重新计算z, 假设法线向量为(x,y,z)，它可以由(x,y,0)和(0,0,z)两条边组成，既然法线向量是一条单位向量，这两条边构成的三角形又是直角三角形，那么其实只要知道一条边长，就可以用勾股定理计算出另一条边长。实际上法线纹理只存储了xy信息.可以明白这句代码正是勾股定理。

## CubeMap
![[Pasted image 20221007232013.png]]
对NormalMap章节代码进行修改，NormalMap结合CubeMap。![[Pasted image 20221007235616.png|300]]
```c
Shader "Unlit/CubeMap"  
{  
    Properties  
    {  
        _MainTex ("Texture", 2D) = "white" {}  
        _NormalMap("NormalMap",2D) = "white" {}  
        _CubeMap("CubeMap",Cube) = "white" {}  
        _Color("Color",Color) = (1,1,1,0)  
          
        [Header(BlinnPhong)]  
        [Space(15)]  
        _NormalMapScale("NormalMapScale",Float) = (1,1,1,0)  
        _PowerValue("PowerValue", Float) = 4  
        _PowerScale("PowerScale",Float) = 1  
        }  
    SubShader  
    {  
        Tags { "RenderType"="Opaque" "LightMode" = "ForwardBase" "Queue" = "Geometry"}  
  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
  
            #include "UnityCG.cginc"  
            #include "AutoLight.cginc"  
  
            struct appdata  
            {  
                float4 vertex : POSITION;  
                float2 uv : TEXCOORD0;  
                float3 nomral : NORMAL;  
                float4 tangent : TANGENT;  
                float4 vertexColor : COLOR;  
            };  
  
            struct v2f  
            {  
                float4 pos : SV_POSITION;  
                float2 uv : TEXCOORD0;  
                float3 normal : TEXCOORD1;  
                float3 tangent : TEXCOORD2;  
                float3 bitangent : TEXCOORD3;  
                float4 worldPosition : TEXCOORD4;  
                float3 localPosition : TEXCOORD5;  
                float3 localNormal : TEXCOORD6;  
                float4 vertexColor : TEXCOORD7;  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _NormalMap;  
            float4 _NormalMap_ST;  
            samplerCUBE _CubeMap;  
            float4 _NormalMapScale;  
            float _PowerValue, _PowerScale;  
              
            v2f vert (appdata v)  
            {  
                v2f o;  
                o.pos = UnityObjectToClipPos(v.vertex);  
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);  
                o.normal = UnityObjectToWorldNormal(v.nomral);  
                o.tangent = UnityObjectToWorldDir(v.tangent);  
                o.bitangent = cross(o.normal, o.tangent) * v.tangent.w;  
                o.worldPosition = mul(unity_ObjectToWorld, v.vertex);  
                o.localPosition = v.vertex.xyz;  
                o.localNormal = v.nomral;  
                o.vertexColor = v.vertexColor;  
                  
                return o;  
            }  
  
            fixed4 frag (v2f i) : SV_Target  
            {  
                // 用TBN矩阵处理NormalMap  
                float3 T = normalize(i.tangent);  
                float3 B = normalize(i.bitangent);  
                float3 N = normalize(i.normal);  
                float3 NormalMap = UnpackNormal((tex2D(_NormalMap, i.uv)));  
  
                //对NormalMap进行插值  
                //作用：float3(0,0,1)视为初始法线方向,可以修改_NormalMapScale的w分量对其插值，实现NomalMap影响CubeMap。  
                NormalMap = lerp(float3(0,0,1), NormalMap, _NormalMapScale.w);  
  
                float3x3 TBN = float3x3(T,B,N);  
                NormalMap *= _NormalMapScale;  
                // 将NormalMap从切线空间转换到世界空间  
                float3 world_NormalMap = normalize(mul(NormalMap, TBN));  
  
                float4 cubemap = texCUBE(_CubeMap, world_NormalMap);  
                return cubemap;  
            }  
            ENDCG  
        }  
    }  
}
```
## MatCap
https://github.com/ipud2/matcaps ![[Pasted image 20221009103455.png]]![[Pasted image 20221009104221.png]]
优点：省资源，快速模拟出材质
缺点：适合固定视角，360视角查看时高光方向只能是一个方向。高光方向根据matcap图决定
代码在normalMap代码基础上进行修改：
```c
_MatCap("MatCap",2D) = "white" {}

sampler2D  _MatCap;  
float4 _MatCap_ST;

//视角空间下的法线当做uv去采样MatCap
float3 N_ViewSpace = mul(unity_MatrixV, N); 
//float3 N_ViewSpace = mul(Unity_WorldToCamera, N);

//使用NormalMap效果
//float3 N_ViewSpace = mul(unity_MatrixV, world_NormalMap); 

float3 N01_ViewSpace = N_ViewSpace * 0.5 + 0.5;

float3 MatCap = tex2D(_MatCap,N01_ViewSpace.xy);  
return float4(MatCap.xyz,1);
```
## Parallax Map
### 视差贴图
![[Pasted image 20221009111354.png]]![[Pasted image 20221009115044.png]]![[TA/assets/3.gif]]
**光栅立体画效果：**
原理：两层视差贴图lerp一下![[Pasted image 20221009111726.png]]
![[Pasted image 20221009115007.png]]![[parel (2).gif]]
### 地形
HeightMap中的uv相当于xz，存储的值相当于y（高度）
![[Pasted image 20221009111512.png]]

## FlowMap
（1）RG通道记录的是uv流动的方向
（2）FlowMap就是一张记录了**2D向量信息**的纹理，纹理颜色通常用RG两个通道来表现。
![[Pasted image 20221010221753.png|300]]
我们定义了中间（128,128）的位置为静止状态，那么（0,0）表示左下方向，（255,255）表示右上方向。同时也有相对应的颜色值。默认B通道为0，黄色（255,255,0）右上方向，（0，0，0）左下方向。我们人眼去理解FlowMap贴图，就可以这样理解。
但实际在Unity shader的应用里，颜色的范围是[0,1],那么计算机采样的时候怎么知道（1,1）就可以代表右上呢？
需要再次将[0,1]范围映射到[-1,1],那么在采样时，偏移的方向就可以通过加法直接跟原UV位置相加获得最终效果。即要进行一次重映射（代码第二行）：映射到（-1，1）有四个象限，可以表示各个方向。
（3）绘制FlowMap可以使用软件![[Pasted image 20221010222139.png]]
（3）周围黄色：uv没有流动
               尾部红色：R值比较大，向u方向流动 
               左下角绿色：G值比较大，向v方向流动

![[Pasted image 20221009205147.png]]

注意事项：
1.FlowMap是线性的，不需要勾选sRGB
![[Pasted image 20221009210426.png|300]]
2.把FlowMap贴图的压缩修改为无损压缩
![[Pasted image 20221010221610.png|300]]
```c
Shader "Unlit/FlowMap"  
{  
    Properties  
    {  
        _MainTex ("Texture", 2D) = "white" {}  
        _FlowMap ("FlowMap", 2D) = "white" {}  
        //_FlowSpeed控制流动速度，_FlowPower控制流动力度  
        _FlowSpeed("FlowSpeed",float) = 1  
        _FlowPower("FlowStrength",float) = 1  
    }  
    SubShader  
    {  
        Tags { "RenderType"="Opaque" }  
        LOD 100  
  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
            #include "UnityCG.cginc"  
  
            struct appdata  
            {  
                float4 vertex : POSITION;  
                float2 uv : TEXCOORD0;  
            };  
  
            struct v2f  
            {  
                float2 uv : TEXCOORD0;  
                float4 vertex : SV_POSITION;  
            };  
  
            sampler2D _MainTex;  
            float4 _MainTex_ST;  
            sampler2D _FlowMap;  
            float4 _FlowMap_ST;  
            float _FlowSpeed;  
            float _FlowPower;  
              
            v2f vert (appdata v)  
            {  
                v2f o;  
                o.uv = v.uv;  
                o.vertex = UnityObjectToClipPos(v.vertex);  
                return o;  
            }  
  
            fixed4 frag (v2f i) : SV_Target  
            {  
                float time01 = frac(_Time.y * _FlowSpeed);  
                float2 flowMap = tex2D(_FlowMap, i.uv) * 2.0 - 1.0;  
                float2 uv1 = i.uv - flowMap * _FlowPower * time01;  
                float2 uv2 = i.uv - flowMap * _FlowPower * frac(time01+0.5);  
                float4 color1 = tex2D(_MainTex,uv1);  
                float4 color2 = tex2D(_MainTex,uv2);  
                float4 finalColor = lerp(color1,color2,abs(time01-0.5)/0.5);  
                  
                return finalColor;  
            }  
            ENDCG  
        }  
    }  
}
```
# 【第四章】后处理
![[Pasted image 20221024155317.png]]
## 采样基本操作
1. Texture object要命名为默认名称_MainTex
2. 通过多次采样，扰动uv可以Append出不同效果（仅为演示，乱连的~）
3. 可以将_MainTex储存到register，方便采样
![[Pasted image 20221024163809.png]]
![[Pasted image 20221024160300.png]]
![[Pasted image 20221024160318.png]]
## HSV 和 RGB 
转自：[Unity Shader - HSV 和 RGB 的相互转换 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/133441623)
对于颜色值，**RGB** 可能是我们接触最多的颜色模型，图像中的任何颜色都是由**红色（R）**、**绿色（G）**、**蓝色（B）** 这三个通道合成的，这三种颜色可以组合成几乎所有的颜色。

然而，它并不直观，比如我随便说一个rgb值，你能猜到他是什么颜色吗？几乎不可能，所以，后面引入了**HSV**、**HSL**等颜色模型。 **HSV** 相对于 **RGB** 来说 是一种更加直观的颜色模型，**HSV**更加符合我们人类视觉。
### HSL和HSV 概念

**HSL** 即色相、饱和度、亮度（英语：Hue, Saturation, Lightness）。

**HSV** 即色相、饱和度、明度（英语：Hue, Saturation, Value），又称HSB，其中B即英语：Brightness。

-   色相（H）是色彩的基本属性，就是平常所说的颜色名称，如红色、黄色等。
-   饱和度（S）是指色彩的纯度，越高色彩越纯，低则逐渐变灰，取0-100%的数值。
-   明度（V），亮度（L），取0-100%

### HSL和HSV色彩空间比较

二者在数学上都是圆柱，但

**HSV** 在概念上可以被认为是颜色的倒圆锥体（白色在上底面圆心，黑点在下顶点）；

**HSL** 在概念上表示了一个双圆锥体和圆球体（白色在上顶点，黑色在下顶点，最大横切面的圆心是半程灰色）。
![[Pasted image 20221024161403.jpg|400]]
![[v2-33e2c70d429d9079c9b53e2f570032aa_1440w 2.webp]]
**以下函数由国外大神 [Inigo Quilez](https://link.zhihu.com/?target=http%3A//www.iquilezles.org/www/index.htm) 提供** [https://www.shadertoy.com/view/MsS3](https://link.zhihu.com/?target=https%3A//www.shadertoy.com/view/MsS3Wc)
### HSB/HSV 转 RGB
```c
// Official HSV to RGB conversion 
vec3 hsv2rgb( in vec3 c )
{
    vec3 rgb = clamp( abs(mod(c.x*6.0+vec3(0.0,4.0,2.0),6.0)-3.0)-1.0, 0.0, 1.0 );

    return c.z * mix( vec3(1.0), rgb, c.y);
}
// Smooth HSV to RGB conversion 
// https://www.shadertoy.com/view/MsS3Wc
vec3 hsv2rgb_smooth( in vec3 c )
{
    vec3 rgb = clamp( abs(mod(c.x*6.0+vec3(0.0,4.0,2.0),6.0)-3.0)-1.0, 0.0, 1.0 );

    rgb = rgb*rgb*(3.0-2.0*rgb); // cubic smoothing 

    return c.z * mix( vec3(1.0), rgb, c.y);
}
```
**ShaderLab版：**
```c
float3 hsb2rgb( float3 c ){
    float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
    rgb = rgb*rgb*(3.0-2.0*rgb);
    return c.z * lerp( float3(1,1,1), rgb, c.y);
}
```
### RGB 转 HSB/HSV
```c
vec3 rgb2hsb( in vec3 c ){
    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
    vec4 p = mix(vec4(c.bg, K.wz),vec4(c.gb, K.xy),step(c.b, c.g));
    vec4 q = mix(vec4(p.xyw, c.r),vec4(c.r, p.yzx),step(p.x, c.r));
    float d = q.x - min(q.w, q.y);
    float e = 1.0e-10;
    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)),d / (q.x + e),q.x);
}
```
**ShaderLab版:**
```c
float3 RGB2HSV(float3 c)
{
    float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
    float4 p = lerp(float4(c.bg, K.wz), float4(c.gb, K.xy), step(c.b, c.g));
    float4 q = lerp(float4(p.xyw, c.r), float4(c.r, p.yzx), step(p.x, c.r));

    float d = q.x - min(q.w, q.y);
    float e = 1.0e-10;
    return float3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
}
```
### 实践
下面我们在Unity Shader 中来看看

#### 笛卡尔坐标系下的SHV
由下图我们可以清晰的看到 **X 轴 决定 色相，Y 轴 决定 饱和度**
![[Pasted image 20221024162348.jpg]]
```less
Shader "lcl/shader2D/HSV"
{

    SubShader
    {
        Pass
        {
            CGPROGRAM
            // vert_img 是 UnityCG.cginc 内置的
            #pragma vertex vert_img 
            #pragma fragment frag

            #include "UnityCG.cginc"

            //  该函数由国外大神 Iñigo Quiles 提供
            //  https://www.shadertoy.com/view/MsS3Wc
            float3 hsb2rgb( float3 c ){
                float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
                rgb = rgb*rgb*(3.0-2.0*rgb);
                return c.z * lerp( float3(1,1,1), rgb, c.y);
            }

            // ---------------------------【片元着色器】---------------------------
            fixed4 frag (v2f_img i) : SV_Target
            {
                fixed4 col;
                // hsb 转换为 rgb
                // uv.x  决定 色相, 
                // uv.y  决定 亮度, 
                col.rgb = hsb2rgb(float3(i.uv.x, 1, 1-i.uv.y));
                return col;
            }
            ENDCG
        }
    }
}
```
#### 极坐标系下的SHV

在极坐标系下，我们可以看到，**角度 决定 色相， 半径 决定 饱和度， 亮度固定**
![[Pasted image 20221024162435.jpg]]

```less
Shader "lcl/shader2D/HSVInPolarCoordinate"
{

    SubShader
    {
        Pass
        {
            CGPROGRAM
            // vert_img 是 UnityCG.cginc 内置的
            #pragma vertex vert_img 
            #pragma fragment frag

            #include "UnityCG.cginc"

            #define TWO_PI 6.28318530718

            //  该函数由国外大神 Iñigo Quiles 提供
            //  https://www.shadertoy.com/view/MsS3Wc
            float3 hsb2rgb( float3 c ){
                float3 rgb = clamp( abs(fmod(c.x*6.0+float3(0.0,4.0,2.0),6)-3.0)-1.0, 0, 1);
                rgb = rgb*rgb*(3.0-2.0*rgb);
                return c.z * lerp( float3(1,1,1), rgb, c.y);
            }

            // ---------------------------【片元着色器】---------------------------
            fixed4 frag (v2f_img i) : SV_Target
            {
                fixed4 col;
                // 笛卡尔坐标系转换到极坐标系
                float2 center = float2(0.5,0.5)-i.uv;
                float angle = atan2(center.y,center.x);
                float radius = length(center)*2.0;

                // 将角度 从(-PI, PI) 映射到 (0,1)范围
                // 角度决定色相, 半径决定饱和度, 亮度固定
                col.rgb = hsb2rgb(float3((angle/TWO_PI)+0.5,radius,1.0));
                return col;
            }
            ENDCG
        }
    }
}
```
## Base原图
**RGBA：**

![[Pasted image 20221024155948.png]]
![[Pasted image 20221024155317.png]]
**R通道：**
![[Pasted image 20221024155508.png]]
**反色：
![[Pasted image 20221024160039.png]]
![[Pasted image 20221024155601.png]]
## 改变颜色
![[Pasted image 20221024163907.png]]
实现对HSV的修改，可以通过使用_Time作为值传入Add，实现动态变化。
以下例子仅对H进行改变：
![[modifycolor.gif]]
## 暗/亮视野
![[Pasted image 20221024165351.png]]
![[Pasted image 20221024165416.png]]
![[Pasted image 20221024165437.png]]
## 白噪音
方法一：floor
![[Pasted image 20221024171946.png]]
方法二：frac
![[Pasted image 20221024172429.png]]
## Glitch故障
[Content/高品质后处理：十种故障艺术（Glitch Art）算法的总结与实现 · 毛星云](https://gitee.com/liuke101/maoxingyun/tree/master/Content/%E9%AB%98%E5%93%81%E8%B4%A8%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%9A%E5%8D%81%E7%A7%8D%E6%95%85%E9%9A%9C%E8%89%BA%E6%9C%AF%EF%BC%88Glitch%20Art%EF%BC%89%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E5%AE%9E%E7%8E%B0)
Cyberpunk~
![[glitch.gif]]
核心思想：
1. 对UV做偏移
2. RGB通道分离
### 理解UV偏移
![[Pasted image 20221024223235.png]]
![[Pasted image 20221024223323.png]]
UV偏移主要发生在这里：
![[Pasted image 20221024223354.png]]
对纹理坐标add一个坐标，纹理坐标被改变，进而当采样纹理时，出现偏移现象。图中可以观察到，小圆圈位置的图像与左下角图像一致，说明该区域的uv被便宜到此处。
### 公共量
![[Pasted image 20221024221531.png]]
### 动态噪音算法
使用了两种算法，区别仅在于输出值
#### RandomNoise float1
![[Pasted image 20221024220434.png]]
#### RandomNoise vector2
![[Pasted image 20221024220602.png]]
### 噪音
![[Pasted image 20221024221000.png]]
### RGB通道UV偏移
三通道进行相同处理，变量属性不共享，最后将各自通道输入register
![[Pasted image 20221024222343.png]]
Apend将RGB组装起来即可
![[Pasted image 20221024222458.png]]
## Scan扫描
![[819AD6B83516F9D27F0ECC74109A155A.jpg]]
## 从深度重建世界坐标位置
ASE内置节点解析
![[Pasted image 20221024225644.png]]
![[Pasted image 20221024225614.png]]
直接输出如下：
![[Pasted image 20221024230304.png]]
**注意：这里使用的方法是以以相机坐标为中心进行扫描，不适合游戏模式（游戏模式应该以外部传入的位置为中心，可以实时更新）**
![[Pasted image 20221024232033.png]]
![[Pasted image 20221024232011.png]]
通过调整Float0即表现出简单的扫描效果。


## 模糊
[Content/高品质后处理：十种图像模糊算法的总结与实现 · 毛星云](https://gitee.com/liuke101/maoxingyun/tree/master/Content/%E9%AB%98%E5%93%81%E8%B4%A8%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%9A%E5%8D%81%E7%A7%8D%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E5%AE%9E%E7%8E%B0)

# 【第五章】猴子的 PBR 笔记
## PBR

**理论**

PBR (Physically Based Shading) 是基于与现实世界的物理原理所创建的一种渲染技术，相比于传统的基于经验的模型（Phong Blin-Phong 等）更具有物理准确性。基于物理的光照模型必须满足一下三个条件:

**1. 基于微平面 (Microfacet) 的表面模型。**

**2. 能量守恒。**

**3. 基于物理的 BRDF。**

**微表面模型**

微观尺度上，物体表面有无数的为表面构成。用粗糙度去衡量一个表面的粗糙程度, 越粗糙则说明微表面的法线方向越不一致，反射的光越分散，反之则越集中。

![](<images/1683732881208.png>)

较高的粗糙度值显示出来的镜面反射的轮廓要更大一些。与之相反地，较小的粗糙值显示出的镜面反射轮廓则更小更锐利。

**能量守恒**

能量守恒定律是自然界普遍的基本定律之一。一般表述为：能量既不会凭空产生，也不会凭空消失，它只会从一种形式转化为另一种形式，或者从一个物体转移到其它物体，而能量的总量保持不变。

将能量守恒定律应用到光照模型中: 出射光线的能量永远不能超过入射光线的能量。可以用渲染方程来描述:

![](<images/1683732881380.png>)

在 PBR 中考虑简化的形式即反射方程:

![](<images/1683732881797.png>)

再看这张图:

![](<images/1683732881906.png>)

从上图可以看出随着粗糙度的上升镜面反射区域的面积会增加，作为平衡，镜面反射区域的平均亮度则会下降。

![](<images/1683732882106.png>)

按照能量守恒的关系，首先计算镜面反射部分，它的值等于入射光线被反射的能量所占的百分比。然后漫反射部分就可以直接由镜面反射部分计算得出：

```
float kS = calculateSpecularComponent(...); // 镜面反射部分
float kD = 1.0 - ks;                        // 漫反射 部分
```

而在实时渲染中，会有两种光对物体表面造成影响，分别是直接光和间接光，那么与两种反射组合，会有四中光照反射情况。

![](<images/1683732882430.png>)

**基于物理的 BRDF**

双向反射分布函数（Bidirectional Reflectance Distribution Function）描述的是入射光和反射光关系。在各种 brdf 模型中，Cook-Torrance 效果更真实应用最广泛。

![](<images/1683732882588.png>)

其中 Ks 是镜面反射所占百分比，Kd 是漫反射所占百分比 Kd=1-Ks

将 Cook-Torrance 带入反射方程中可得:

![](<images/1683732882697.png>)

其中 F 菲涅尔描述了光被反射的比例，代表了反射方程的 ks，两者可以合并，所以最终的反射方程为:

![](<images/1683732883054.png>)

**直接光漫反射 + 镜面反射**

由于直接光通常是平行光或者点光源都是有限的数量，因此直接将它们的光照结果相加即是最终的积分结构。我们目前只考虑一个平行光，因此直接光的计算结构即使积分结果。而间接光从四面八方射到物体表面上来，数量是无限的，因此要用积分计算出所有间接光的计算结果。

直接光的漫反射比较简单:

```
ks = F;//F的计算参考后面
kd = 1 - ks;
Diffuse = kd*BaseColor/PI;
```

间接光需要考虑 DFG 三项

**D Distribution of normal function**

法线分布函数描述的是微表面的法线方向与半角向量对齐的概率，如果对齐那么认为该反射光可以看到，否则没有。

![](<images/1683732883298.png>)

D 的 Trowbridge-Reitz GGX 公式:

![](<images/1683732883394.png>)

```
//D
float D_DistributionGGX(float3 N,float3 H,float Roughness) {
    float a             = Roughness*Roughness;
    float a2            = a*a;
    float NH            = saturate(dot(N,H));
    float NH2           = NH*NH;
    float nominator     = a2;
    float denominator   = (NH2*(a2-1.0)+1.0);
    denominator         = PI * denominator*denominator;
    
    return              nominator/ max(denominator,0.001) ;//防止分母为0
}
```

仅有 D 项

```
float Roughness = 0.356;
FinalColor = D_DistributionGGX(N,H,Roughness);
```

![](<images/1683732883468.png>)

**F Frenel function**

如果你站在湖边，低头看脚下的水，你会发现水是透明的，反射不是特别强烈；如果你看远处的湖面，你会发现水并不是透明的，但反射非常强烈。这就是 “菲涅尔效应”。简单的讲，就是视线垂直于表面时，反射较弱，而当视线非垂直表面时，夹角越小，反射越明显。如果你看向一个圆球，那圆球中心的反射较弱，靠近边缘较强。

![](<images/1683732883538.png>)

F 的 Schlick 公式:

![](<images/1683732883633.png>)

n 代表介质的折射率, 1 为空气的折射率，以下为真实材质测量的 F0 数值表

![](<images/1683732883722.png>)

非金属的 F0 数值较小，金属 F0 的数值较大，出于简化计算的原因，通过金属度在一个预设的 F0 和自身颜色之间经行插值。

```
float3 F0 = 0.04;
F0 = lerp(F0, BaseColor, Metallic);
```

```
//F
float3 F_FrenelSchlick(float HV,float3 F0) {
    return F0 +(1 - F0)*pow(1-HV,5);
    //return lerp(pow(1-HV,5),1,F0);
}
```

仅有 F 项:

```
float3 BaseColor = float3(1,0.782,0.344);
 float MEtallic = 0.874;
 float3 F0 = 0.04;
 F0 = lerp(F0, BaseColor, Metallic);
 FinalColor = F_FrenelSchlick(HV,F0);
```

从背面观察:

![](<images/1683732883789.png>)

**G Geometry function**

几何项体现了微表面的自我遮蔽现象，即入射光线或者反射光线会被自身凹凸不平的表面遮蔽。一般而言，这一项也跟材质的粗糙程度有关，可以理解为越粗超的材质表面越有可能发生自我遮蔽现象。

![](<images/1683732883956.png>)

G 的 Schlick-GGX 公式:

![](<images/1683732884254.png>)

k 在直接光与间接光中分别为:

![](<images/1683732884314.png>)

如前面的示意图所示 Smith 认为 G 项分应该分为为两部分: 第一部分是 Geometry Obstruction 第二部分是 Geometry Shadowing 即:

![](<images/1683732884517.png>)

```
//G
float GeometrySchlickGGX(float NV,float Roughness) {
    float r = Roughness +1.0;
    float k = r*r / 8.0;      //直接光
    float nominator = NV;
    float denominator = k + (1.0-k) * NV;
    return nominator/ max (denominator, 0.001) ;//防止分母为 0
}

float G_GeometrySmith(float3 N,float3 V,float3 L,float Roughness) {
    float NV = saturate(dot(N,V));
    float NL = saturate(dot(N,L));

    float ggx1 = GeometrySchlickGGX(NV,Roughness);
    float ggx2 = GeometrySchlickGGX(NL,Roughness);

    return ggx1*ggx2;

}
```

仅有 G 项:

```
float Roughness = 0.356;
FinalColor = G_GeometrySmith(N,V,L,Roughness);
```

![](<images/1683732884564.png>)

直接光的最后效果:

```
//================== PBR  ============================================== //
// float3 BaseColor = float3(0.5,0.3,0.2);
float3 BaseColor = _BaseColor;
float Roughness = _Roughness;
float Metallic = _Metallic;
float3 F0 = lerp(0.04,BaseColor,Metallic);
float3 Radiance = _LightColor0.xyz;

//================== Direct Light  ============================================== //
//Specular
//Cook-Torrance BRDF
float HV = saturate(dot(H,V));
float NV = saturate(dot(N,V));
float NL = saturate(dot(N,L));

float D = D_DistributionGGX(N,H,Roughness);
float3 F = F_FrenelSchlick(HV,F0);
float G = G_GeometrySmith(N,V,L,Roughness);

float3 KS = F;
float3 KD = 1-KS;
KD*=1-Metallic;
float3 nominator = D*F*G;
float denominator = max(4*NV*NL,0.001);
float3 Specular = nominator/denominator;

//Diffuse
float3 Diffuse = KD * BaseColor / PI;
float3 DirectLight = (Diffuse + Specular)*NL *Radiance;
FinalColor.rgb = DirectLight.rgb;
```

![](<images/1683732884614.png>)

**间接光漫反射 + 镜面反射**

间接光是用 IBL (Image Based Lighting) 来模拟的。与直接光相比，IBL 把周围环境整体视为一个大光源，IBL 通常使用（取自现实世界或从 3D 场景生成的）环境立方体贴图 (Cubemap) ，我们可以将立方体贴图的每个像素视为光源，在渲染方程中直接使用它。这种方式可以有效地捕捉环境的全局光照和氛围，使物体**更好地融入**其环境。

表示环境或场景辐照度的一种方式是（预处理过的）环境立方体贴图，给定这样的立方体贴图，可以将立方体贴图的每个纹素视为一个光源。使用一个方向向量 wi 对此立方体贴图进行采样，就可以获取该方向上的场景辐照度。

给定方向向量 wi ，获取此方向上场景辐射度的方法就简化为：

```
float3 radiance = tex2D(_CubemapEnvironment, lightDirection).rgb;
```

虽然这么简化了，但是如果要求解反射方程的话，我们依然需要计算球面积分，这对于实时渲染来说太昂贵了。解决这个问题，我们可以通过预计算一些结果并存储起来，然后在运行时利用这些中间结果计算最终值。首先将反射方程拆分一下。

![](<images/1683732884676.png>)

通过将积分分成两部分，可以分开研究漫反射和镜面反射部分。

间接光漫反射部分：

![](<images/1683732884791.png>)

间接光镜面反射部分：

![](<images/1683732884844.png>)

**漫反射部分**

颜色 c 、折射率 kd 和 π 在整个积分是常数，不依赖于任何积分变量。基于此，可以将常数项移出漫反射积分：

![](<images/1683732884942.png>)

这给了我们一个只依赖于 wi 的积分（假设 p 位于环境贴图的中心）。有了这些知识，我们就可以计算或预计算一个新的立方体贴图，它在每个采样方向——也就是纹素——中存储漫反射积分的结果，这些结果是通过卷积计算出来的。

卷积的特性是，对数据集中的一个条目做一些计算时，要考虑到数据集中的所有其他条目。这里的数据集就是场景的辐射度或环境贴图。因此，要对立方体贴图中的每个采样方向做计算，我们都会考虑半球 Ω 上的所有其他采样方向。

为了对环境贴图进行卷积，我们通过对半球 Ω 上的大量方向进行离散采样并对其辐射度取平均值，来计算每个输出采样方向 wo 的积分。以 wo 方向所在的半球，采样方向 wi 。

![](<images/1683732884990.png>)

这个预计算的立方体贴图，在每个采样方向 wo 上存储其积分结果，可以理解为场景中所有能够击中面向 wo 的表面的间接漫反射光的预计算总和。这样的立方体贴图被称为**辐照度贴图**，因为经过卷积计算的立方体贴图能让我们从任何方向有效地直接采样场景（预计算好的）辐照度。

![](<images/1683732885056.png>)

对于一点 P 它所受间接光来自整个 CubeMap (以 CubeMap 中的每个像素为一个光源) ，假设 P 点的法线 N 为光线的出射方向，那么可以离线计算出 P 点所受环境光照的影响。给定任何方向向量 wi ，我们可以对预计算的辐照度图采样以获取方向 wi 的总漫反射辐照度。为了确定片段上间接漫反射光的数量（辐照度），我们获取以表面法线为中心的半球的总辐照度。获取场景辐照度的方法就简化为：

```
float3 irradiance = tex3D(irradianceMap, N);
```

**生成辐照度贴图**

实时进行积分计算太消耗，可以先离线计算出来。然而，理论上在半球上采样方向是无限的 , 因此不可能从半球上的所有方向采样环境光照。不过我们可以对有限数量的方向采样以近似求解，在半球内均匀间隔或随机取方向可以获得一个近似精确的辐照度值，从而离散地计算积分结果。

伪代码:

```
//Normal为当前点P的 采样方向
以Normal方向为半球，获取一组随机的方向 且将其定义为Normals 
float3 avg =0
foreach( N in Normals)
{
    avg = SampleCube(CubeMap,N)
}
avg /= Normals.Count
//avg 则是 所有环境光 对当前点P的最终影响结果
IrradianceMap.SetValue(avg,Normal) //将结果储存在辐照度贴图中
```

**LightProbe 与球协函数**

辐照度贴图是固定的，如果游戏中有多个场景，比如室内室外那么肯定是不能为每一个场景都单独弄一个辐照度贴图的，会消耗大量内存。游戏引擎中使用 LightProbe 放置在场景中，去近似采样并存储以该 LightProbe 为中心的 "辐照度贴图"，但不是单独存一张贴图，而是用球协函数存储相应的信息，最终存储的是球协函数的参数，通常是 9 个 float，这比单独存一张贴图节省多了。

在 Unity 中放置 LightProbe，并且烘培后，使用 ShadeSH9 函数即可获取当前的点的 "辐照度"。

![](<images/1683732885110.png>)

仅显示球协函数的光照:

```
//注意需要设置 Tags{ "LightMode"="ForwardBase"} 才能正确得到球鞋函数值
//否则ShadeSh9返回值为0 
float3 irradianceSH = ShadeSH9(float4(N,1)));
FinalColor.rgb = irradianceSH;
```

![](<images/1683732885172.png>)

HDR 图可以在这里下载: [https://hdrihaven.com/hdris/](https://hdrihaven.com/hdris/)

![](<images/1683732885293.png>)

仅显示间接光漫反射:

```
float3 irradianceSH = ShadeSH9(float4(N,1));
return irradianceSH.rgbb;
float3 Diffuse_Indirect = irradianceSH * BaseColor / PI *KD_IndirectLight;
FinalColor.rgb = Diffuse_Indirect;
```

![](<images/1683732885374.png>)

骚操作一下:

将上面的 HDR 图直接在 PS 里做一个高斯模糊，然后再去采样

![](<images/1683732885432.png>)

```
float3 EnvCubeMap = texCUBE(_EnvCubeMap,N).xyz;
return (EnvCubeMap.xyzz);
```

得到下面结果:

![](<images/1683732885488.png>)

会比较暗，这是因为在 PS 做模糊的时候，将 HDR 从 32 位转为了 16 位，因此手动把精度加回来 (不准确，但是可以理解这个过程)

```
float3 EnvCubeMap = texCUBE(_EnvCubeMap,N).xyz;
//用ToneMaping HDR=>LDR
//x3.75 是为了补救损失的精度
return ACESToneMapping(EnvCubeMap.xyzz*3.75);
```

和球协的有点区别，但是明显这张图比球协的更准确地反映了环境光的 "黄"

![](<images/1683732885551.png>)

球协函数原理参考：

[https://zhuanlan.zhihu.com/p/50208005](https://zhuanlan.zhihu.com/p/50208005)

[https://pdfs.semanticscholar.org/83d9/28031e78f15d9813061b53d25a4e0274c751.pdf](https://pdfs.semanticscholar.org/83d9/28031e78f15d9813061b53d25a4e0274c751.pdf)

[https://basesandframes.files.wordpress.com/2016/05/spherical-harmonic-lighting-gdc-2003.pdf](https://basesandframes.files.wordpress.com/2016/05/spherical-harmonic-lighting-gdc-2003.pdf)

[http://web.cs.wpi.edu/~emmanuel/courses/cs563/S05/talks/mark_w5_spherical_harmonic_lighting.pdf](http://web.cs.wpi.edu/~emmanuel/courses/cs563/S05/talks/mark_w5_spherical_harmonic_lighting.pdf)

**镜面反射部分**

![](<images/1683732885654.png>)

  
将镜面反射的公式近似地拆成两部分（EpicGames SplitSum）

![](<images/1683732885769.png>)

**间接光镜面积分第一部分**

![](<images/1683732885871.png>)

对于高光部分而言，如果材质表面越光滑，则该点出射光大部分贡献来源于入射光的镜面反射，很小一部分来源于各个方向的漫反射。所以，这次我们在计算积分的时候，需要把粗糙度也考虑进去。如果粗糙度越低，那么积分的贡献范围就越集中，相当于卷积核的面积越小，大权重集中在核中心，卷积结果尺寸越大，产生越清晰的反射效果。反之亦然。

![](<images/1683732885919.png>)

于是可以根据材质的粗糙度，映射到某个粗糙度区间，然后把计算结果保存到不同的 LOD 等级中。这张具有不同 LOD 等级的立方体贴图也称为 pre-filtered environment map。

![](<images/1683732885974.png>)

后续在运行时只需要根据粗糙等级做一次采样就可以得到高光积分的第一部分。

```
//UNITY_SPECCUBE_LOD_STEPS 在  "UnityStandardConfig. cginc"中 
// #define UNITY_SPECCUBE_LOD_STEPS 6
float mip = Roughness*(1.7 - 0.7*Roughness) * UNITY_SPECCUBE_LOD_STEPS ; 
float4 rgb_mip = UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0,R,mip);
//间接光镜面反射采样的预过滤环境贴图
//unity_SpecCube0_HDR储存的是 最近的ReflectionProbe
float3 EnvSpecularPrefilted = DecodeHDR(rgb_mip, unity_SpecCube0_HDR);
FinalColor.rgb = EnvSpecularPrefilted.rgb;
```

仅显示 ReflectionProbe 信息，即间接光镜面积分第一部分结果

![](<images/1683732886038.png>)

**ReflectionProbe**

Reflection Probe 是六个相机分别捕捉它所在位置的 6 个方向的场景信息，最后储存在一张 Cubemap 贴图里。

![](<images/1683732886093.png>)

![](<images/1683732886446.png>)

在场景中放置 ReflectionProbe Bake 之后才会有信息。

![](<images/1683732886502.png>)

当用一个未烘培过的 ReflectionProbe 去靠近物体 (仅显示 ReflectionProbe 信息)，明显发现物体变黑了，因为这个未烘培过的 ReflectionProbe 没有信息，而 unity_SpecCube0 是最近的一个 ReflectionProbe。

![](<images/1683732886578.png>)

**间接光镜面积分第二部分**

![](<images/1683732886666.png>)

经过推导后可得如下：

![](<images/1683732886718.png>)

计算这个积分有两种办法，第一种是 BRDF 积分图第二种是函数拟合

**BrdfLut**

假设每个方向的入射光都是白色的（L (p, x)=1.0 ），就可以在给定粗糙度、光线 ωi 法线 n 夹角 n⋅ωi 的情况下，预计算 BRDF 的响应结果。以 X 轴为法线与入射光的夹角 (dot (N, L))，以 Y 轴为粗糙度，将计算的结果存储在一张 2D 贴图上 (Lut)，该贴图称为 BRDF 积分贴图。积分的结果分别储存在贴图的 RG 通道中。使用的时候可以直接采样该贴图即可。

![](<images/1683732886768.png>)

```
float3 F_IndirectLight = FresnelSchlickRoughness(NV,F0,Roughness);
float2 env_brdf = tex2D(_BRDFLUTTex, float2(NV, Roughness)).rg;
float3 IndirectLightSpecularPartTwo = F_IndirectLight * env_brdf.r + env_brdf.g;
FinalColor.rgb = IndirectLightSpecularPartTwo ;
```

仅显示 Specular PartTwo

![](<images/1683732886829.png>)

上面代码中的菲涅尔系数计算和前面的有两点不同，第一点是这里没有用于计算微片元朝向的 D 函数，计算菲涅尔系数使用的是真正的 nv 而不是 vh，第二点是考虑了粗糙度。使用 nv 是由于环境光来自半球内围绕法线 N 的所有方向，因此无法和直接光照中的法线分布函数 D 一样使用单个半角向量来确定微平面分布，所以在此我们只能使用法线和视线的夹角（即 nv）来计算菲涅尔效果。

```
float3 FresnelSchlickRoughness(float NV,float3 F0,float Roughness) {
    return F0 + (max(float3(1.0 - Roughness, 1.0 - Roughness, 1.0 - Roughness), F0) - F0) * pow(1.0 - NV, 5.0);
}
```

**数值拟合**

PartTwo 的结果出了可以预计算出来外，还可以用函数拟合来实时计算。

```
// 这是使命召唤黑色行动2的函数拟合 Black Ops II
float2 EnvBRDFApprox_BlackOp2(float Roughness, float NV) {
    float g = 1 -Roughness;
    float4 t = float4(1/0.96, 0.475, (0.0275 - 0.25*0.04)/0.96, 0.25);
    t *= float4(g, g, g, g);
    t += float4(0, 0, (0.015 - 0.75*0.04)/0.96, 0.75);
    float A = t.x * min(t.y, exp2(-9.28 * NV)) + t.z;
    float B = t.w;
    return float2 ( t.w-A,A);
}
```

```
//UE4 在 黑色行动2 上的修改版本
float2 EnvBRDFApprox_UE4(float Roughness, float NoV ) {
    // [ Lazarov 2013, "Getting More Physical in Call of Duty: Black Ops II" ]
    // Adaptation to fit our G term.
    const float4 c0 = { -1, -0.0275, -0.572, 0.022 };
    const float4 c1 = { 1, 0.0425, 1.04, -0.04 };
    float4 r = Roughness * c0 + c1;
    float a004 = min( r.x * r.x, exp2( -9.28 * NoV ) ) * r.x + r.y;
    float2 AB = float2( -1.04, 1.04 ) * a004 + r.zw;
    return AB;
}
```

```
float3 F_IndirectLight = FresnelSchlickRoughness(NV,F0,Roughness);
float2 env_brdf = EnvBRDFApprox_UE4(Roughness,NV);
float3 IndirectLightSpecularPartTwo = F_IndirectLight * env_brdf.r + env_brdf.g;
FinalColor.rgb = IndirectLightSpecularPartTwo ;
```

用函数拟合的效果比 BrdfLut 的效果更好，且更节省性能。

![](<images/1683732886879.png>)

关于 BrdfLut 的生产参考:

[https://learnopengl.com/PBR/IBL/Specular-IBL](https://learnopengl.com/PBR/IBL/Specular-IBL)

数值拟合的参考:

[https://blog.selfshadow.com/publications/s2013-shading-course/lazarov/s2013_pbs_black_ops_2_slides_v2.pptx](https://blog.selfshadow.com/publications/s2013-shading-course/lazarov/s2013_pbs_black_ops_2_slides_v2.pptx)

公式推导参考：

[https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf](https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf)

最终效果:

```
//================== Direct Light  ============================================== //
//Specular
//Cook-Torrance BRDF
float HV = saturate (dot (H, V));
float NV = saturate(dot(N,V));
float NL = saturate(dot(N,L));

float D = D_DistributionGGX(N,H,Roughness);
float3 F = F_FrenelSchlick(HV,F0);
float G = G_GeometrySmith(N,V,L,Roughness);

float3 KS = F;
float3 KD = 1-KS;
KD*=1-Metallic;
float3 nominator = D*F*G;
float denominator = max(4*NV*NL,0.001);
float3 Specular = nominator/denominator;
//Diffuse
float3 Diffuse = KD * BaseColor / PI;

float3 DirectLight = (Diffuse + Specular)*NL *Radiance;
//================== Indirect Light  ============================================== //
float3 IndirectLight = 0;
//Specular
float3 R = reflect(-V,N);
float3 F_IndirectLight = FresnelSchlickRoughness(NV,F0,Roughness);
// float3 F_IndirectLight = F_FrenelSchlick(NV,F0);
float mip = Roughness*(1.7 - 0.7*Roughness) * UNITY_SPECCUBE_LOD_STEPS ;
float4 rgb_mip = UNITY_SAMPLE_TEXCUBE_LOD(unity_SpecCube0,R,mip);

//间接光镜面反射采样的预过滤环境贴图
float3 EnvSpecularPrefilted = DecodeHDR(rgb_mip, unity_SpecCube0_HDR);

//LUT采样
// float2 env_brdf = tex2D(_BRDFLUTTex, float2(NV, Roughness)).rg; //0.356

//数值近似
float2 env_brdf = EnvBRDFApprox(Roughness,NV);
float3 Specular_Indirect = EnvSpecularPrefilted  * (F_IndirectLight * env_brdf.r + env_brdf.g);

//Diffuse           
float3 KD_IndirectLight = 1 - F_IndirectLight;
KD_IndirectLight *= 1 - Metallic;

float3 irradianceSH = ShadeSH9(float4(N,1));
float3 Diffuse_Indirect = irradianceSH * BaseColor / PI *KD_IndirectLight;

//float3 EnvCubeMap = texCUBE(_EnvCubeMap,N).xyz;

IndirectLight = Diffuse_Indirect + Specular_Indirect;

float4 FinalColor =0;
FinalColor.rgb = DirectLight + IndirectLight;
//HDR => LDR aka ToneMapping
FinalColor.rgb = ACESToneMapping(FinalColor.rgb);

//Linear => Gamma
// FinalColor = pow(FinalColor,1/2.2);
return FinalColor
```

![](<images/1683732886958.png>)

与 Unity 默认的对比 BaseColor=(255,199,88) Metallic=0.95 Roughness=0.21 参数一致用屏幕后处理统一做 ToneMapping

![](<images/1683732887029.png>)

可以看出 Unity 的效果偏亮一点，因为 Unity 在实现 PBR 算法的时候直接光漫反射与间接光漫反射都没有除以 PI (为了与老版本效果兼容)，而我们的算法是标准的 PBR 算法，在表现金属上会有更细腻的亚光效果。

完整的 PBR 效果: (BaseColor + Metallic +Roughness + Normal + AO)

![](<images/1683732887165.png>)

完整的 PBR 代码链接:

[https://github.com/ipud2/Unity-Basic-Shader/blob/master/PBR_BetterThanUnity.shader](https://github.com/ipud2/Unity-Basic-Shader/blob/master/PBR_BetterThanUnity.shader)

# 【第六章】日式卡通渲染
## 6.1 日式卡通渲染介绍
塞尔达
![[Pasted image 20221211145628.png]]
罪恶装备
![[Pasted image 20221211145759.png]]
## 6.2 NPR特性实现
![[Pasted image 20221211163746.png]]
### 裁边漫反射（StepDiffuse）
![[Pasted image 20221211163549.png]]
![[Pasted image 20221211163604.png]]
**半兰伯特颜色分布：**
![[Pasted image 20221211153311.png|200]]
**简单的亮暗硬边实现:**
- 当halfLambert＞=  _ StepValue时，值为1
- 当halfLambert＜ _ StepValue时，值为0
![[Pasted image 20221211153234.png|200]]
```c
float halfLambert = NL * 0.5 + 0.5;  
float diffuse = step(_StepValue, halfLambert);
```


采样一张Ramp图，注意采样时的uv写为 `float2(halfLambert, 0.5)`
![[Pasted image 20221211153525.png]]
![[Pasted image 20221211153652.png|200]]
理解：halfLambert越白的地方对应采样的u值越大，v值随意设置即可，因为图中v方向颜色不会放生变化
```c
float halfLambert = NL * 0.5 + 0.5;  
float3 RampMap = tex2D(_RampMap, float2(halfLambert, 0.5));  
return float4(RampMap, 1);
```

### 裁边高光（StepSpecular）
![[Pasted image 20221211163619.png]]
原理类似裁边漫反射，blinnphong高光颜色分布如下：
![[Pasted image 20221211155514.png|200]]
亮暗硬边实现：
![[Pasted image 20221211155457.png|200]]
```c
float blinnphong = pow(max(0, NH),_SpecularExp) * _SpecularScale;  
return step(_StepValue,blinnphong);
```
这种写法变量太多，对美术调参不友好
**简化如下：** 只需要调节_StepValue就可以控制高光范围
```c
float blinnphong = NH;  
float specular = step(_StepValue, blinnphong);  
return specular;
```
### 高光形变
![[Pasted image 20221211163728.png]]
### 裁边边缘光（StepRim）
![[Pasted image 20221211163628.png]]
利用fresnel原理
![[Pasted image 20221211160706.png|200]]
```c
float fresnnel = 1 - NV;  
float StepRim= step(_StepValue, fresnnel);  
return StepRim;
```
### 裁边视角视角光（StepViewLight）
光随视角懂
![[Pasted image 20221211163642.png]]
### 裁边光源光（StepLight）
![[Pasted image 20221211163656.png]]
和裁边漫反射一样的实现方法，目的不同
裁边漫反射是为了表示亮面暗面
裁边光源光只是为了做一个点的高光
### 描边（OutLine）
![[Pasted image 20221211163210.png]]
多写一个Pass
- 前向裁剪：Cull Front
- 顶点沿法线挤出：v.vertex.xyz += v.normal.xyz * _OutLineWidth * 0.01;
- 不适用于正方体、圆柱体等模型，因为法线不平滑，需要使用法线平滑工具进行处理
```c
Pass  
{  
    Cull Front  
    CGPROGRAM    #pragma vertex vert  
    #pragma fragment frag  
    #include "UnityCG.cginc"  
  
    struct appdata  
    {  
        float4 vertex : POSITION;  
        float2 uv : TEXCOORD0;  
        float4 normal : NORMAL;  
    };  
  
    struct v2f  
    {  
        float4 vertex : SV_POSITION;  
        float2 uv : TEXCOORD0;  
        float3 normalWS : TEXCOORD1;  
        float3 positionWS : TEXCOORD2;  
    };  
  
    float _OutLineWidth;  
    float4 _OutLineColor;  
      
    v2f vert (appdata v)  
    {  
        v2f o;  
        v.vertex.xyz += v.normal.xyz * _OutLineWidth * 0.01;  
        o.vertex = UnityObjectToClipPos(v.vertex);  
        o.uv = v.uv;  
        return o;  
    }  
  
    fixed4 frag (v2f i) : SV_Target  
    {  
        return _OutLineColor;  
    }  
    ENDCG  
}
```
## 描边法线平滑工具
![[Pasted image 20221211163946.png]]
![[Pasted image 20221211163830.png]]
```c#
using System.Collections;  
using System.Collections.Generic;  
using UnityEngine;  
using UnityEditor;  
  
public class NPRUtilityEditor  
{  
    [MenuItem("TA/平滑法线写入顶点颜色")]  
    public static void WirteAverageNormalToVertexColor()  
    {  
        MeshFilter[] meshFilters = Selection.activeGameObject.GetComponentsInChildren<MeshFilter>();  
        foreach (var meshFilter in meshFilters)  
        {  
            Mesh mesh = meshFilter.sharedMesh;  
            WriteAverageNormalToVertexColor(mesh);  
        }  
        SkinnedMeshRenderer[] skinMeshRenders = Selection.activeGameObject.GetComponentsInChildren<SkinnedMeshRenderer>();  
        foreach (var skinMeshRender in skinMeshRenders)  
        {  
            Mesh mesh = skinMeshRender.sharedMesh;  
            WriteAverageNormalToVertexColor(mesh);  
        }  
        Debug.Log("Done:平滑法线写入顶点颜色");  
    }  
        [MenuItem("TA/平滑法线写入切线")]  
    public static void WirteAverageNormalToTangent()  
    {  
        MeshFilter[] meshFilters = Selection.activeGameObject.GetComponentsInChildren<MeshFilter>();  
        foreach (var meshFilter in meshFilters)  
        {  
            Mesh mesh = meshFilter.sharedMesh;  
            WriteSmoothNormalToTangent(mesh);  
        }  
  
        SkinnedMeshRenderer[] skinMeshRenders = Selection.activeGameObject.GetComponentsInChildren<SkinnedMeshRenderer>();  
        foreach (var skinMeshRender in skinMeshRenders)  
        {  
            Mesh mesh = skinMeshRender.sharedMesh;  
            WriteSmoothNormalToTangent(mesh);  
        }  
        Debug.Log("Done:平滑法线写入切线");  
    }  
    /// <summary>  
    /// 将平滑法线写入 顶点色的GB通道，RA不变  
    /// </summary>  
    /// <param name="mesh"></param>    private static void WriteAverageNormalToVertexColor(Mesh mesh)  
    {  
        Dictionary<Vector3, Vector3> vertexNormalDic = new Dictionary<Vector3, Vector3>();  
        for (int i = 0; i < mesh.vertexCount; i++)  
        {  
            if (!vertexNormalDic.ContainsKey(mesh.vertices[i]))  
            {  
                vertexNormalDic.Add(mesh.vertices[i],mesh.normals[i]);  
            }  
            else  
            {  
                vertexNormalDic[mesh.vertices[i]] += mesh.normals[i];  
            }  
        }  
  
        Color[] colors = null;  
        bool hasVertexColor = mesh.colors.Length == mesh.vertexCount;  
        if (hasVertexColor)  
        {  
            colors = mesh.colors;  
        }  
        else  
        {  
            colors = new Color[mesh.vertexCount];  
        }  
        // length =1  
        // 1 = sart(x*x +y*y+z*z);        for (int i = 0; i < mesh.vertexCount; i++)  
        {  
            Vector3 averageNormal = vertexNormalDic[mesh.vertices[i]].normalized;  
            //colors[i] = new Color(averageNormal.x*0.5f+0.5f,averageNormal.y*0.5f+0.5f,averageNormal.z*0.5f+0.5f, hasVertexColor? colors[i].a:1.0f);  
            colors[i] = new Color( averageNormal.x*0.5f+0.5f,averageNormal.y*0.5f+0.5f,hasVertexColor? colors[i].b:1.0f, hasVertexColor? colors[i].a:1.0f);  
        }  
        mesh.colors = colors;  
        SaveMesh(mesh, mesh.name+"_SmoothNormalToVertexColor",true,true);  
    }  
    /// <summary>  
    /// 平滑法线，即是求出一个顶点 所在的所有三角面的法线的平均值  
    /// </summary>  
    /// <param name="mesh"></param>    private static void WriteSmoothNormalToTangent(Mesh mesh)  
    {  
        //建立一个 Position到Nomral 的索引字典  
        //将相同Position所对应的所有法线求和  
        //将求和后的法线normalize即得到平滑法线  
        //将平滑法线写入Tangent  
        Dictionary<Vector3, Vector3> vertexNormalDic = new Dictionary<Vector3, Vector3>();  
          
        for (int i = 0; i < mesh.vertexCount; i++)  
        {  
            if (!vertexNormalDic.ContainsKey(mesh.vertices[i]))  
            {  
                vertexNormalDic.Add(mesh.vertices[i],mesh.normals[i]);  
            }  
            else  
            {  
                vertexNormalDic[mesh.vertices[i]] += mesh.normals[i];//将相同 Position的所有法线求和  
            }  
        }  
  
        Vector4[] tangents = null;  
        bool hasTangent = mesh.tangents.Length == mesh.vertexCount;  
        if (hasTangent)  
        {  
            tangents = mesh.tangents;  
        }  
        else  
        {  
            tangents = new Vector4[mesh.vertexCount];  
        }  
        for (int i = 0; i < mesh.vertexCount; i++)  
        {  
            Vector3 averageNormal = vertexNormalDic[mesh.vertices[i]].normalized;//将求和后的法线normalize即得到平滑法线  
            tangents[i] = new Vector4(averageNormal.x,averageNormal.y,averageNormal.z, 0f);//如果写入到顶点色需要将值映射到[0,1]，再在Shader中重新映射到[-1,1]  
        }  
        mesh.tangents = tangents;  
          
        SaveMesh(mesh, mesh.name+"_SmoothNormalToTangent",true,true);  
    }  
  
    private static void SaveMesh(Mesh mesh,string Path)  
    {  
            }  
    public static void SaveMesh (Mesh mesh, string name, bool makeNewInstance, bool optimizeMesh)   
    {  
        string path = EditorUtility.SaveFilePanel("Save Separate Mesh Asset", "Assets/", name, "asset");  
        if (string.IsNullOrEmpty(path)) return;  
          
        path = FileUtil.GetProjectRelativePath(path);  
  
        Mesh meshToSave = (makeNewInstance) ? Object.Instantiate(mesh) as Mesh : mesh;  
        
        if (optimizeMesh) MeshUtility.Optimize(meshToSave);  
          
        AssetDatabase.CreateAsset(meshToSave, path);  
        AssetDatabase.SaveAssets();  
    }  
    }
```
## 6.3 罪恶装备
### 特性分析
![[Pasted image 20221211204248.png]]
### 贴图信息

![[Pasted image 20221211204323.png]]
本村线：<font color="#ff0000">uv垂直水平展开，可以减少锯齿</font>
在PS中画一个长方形和一个圆形，可以看到圆形是有锯齿的的，而长方形就没有。
![[Pasted image 20221211204956.png]]
另外由于使用了本村线，无法在uv贴图上绘画，所以一些装饰部件用了单独的mesh
![[Pasted image 20221211211114.png|200]]
![[Pasted image 20221211205056.png]]
![[Pasted image 20221211205600.png]]
VertexColor.r ：通过顶点颜色的方式控制暗部。
或者直接画进贴图，用贴图对模型精度要求低（移动端），但是会有插值引起锯齿

### 高光类型
![[Pasted image 20221211205306.png]]
### 裁边漫反射
#### shadowmap
Basecolor乘shadowmap是为了符合美术直觉，这里也可以直接用一张右边的shadow图完成（碧蓝幻想就是这样做的）
![[Pasted image 20221211205404.png]]
```c
lerp(BaseMap*ShadowMap,BaseMap,step(_LightThreshold,halfLambert));
```
阴影效果如下：
![[Pasted image 20221211221709.png|300]]
#### AO常暗阴影
首先处理一下vertexColor.r
![[Pasted image 20221211222412.png]]
```c
float ShadowAOMask = VertexColor.r>0.5; //AO 常暗部分，大于0.5的部分为1
```
然后：
```c
lerp(BaseMap*ShadowMap,BaseMap,step(_LightThreshold,halfLambert) * ShadowAOMask);
```
![[Pasted image 20221211222020.png]]
![[Pasted image 20221211222040.png]]

#### Ramp偏移
![[Pasted image 20221211205150.png]]
主要给美术改阴影效果
```c
lerp(BaseMap*ShadowMap,BaseMap,step(_LightThreshold,halfLambert + RampOffsetMask + _RampOffset) * ShadowAOMask);
```

卡渲中，脸部需要有三角的暗面和亮面，原神使用的sdf图实现。
罪恶装备中的面部阴影是通过编辑法线来控制的。
![[Pasted image 20221211205635.png]]
![[Pasted image 20221211205828.png]]
### 描边
![[Pasted image 20221211205841.png]]
### 代码
```c
Shader "NPR/GGXStrive_Body"  
{  
    Properties  
    {  
        _BaseMap    ("_BaseMap", 2D)    = "white" {}  
        _LightMap   ("_LightMap", 2D)   = "white" {}  
        _LineMap    ("_LineMap", 2D)    = "white" {}  
        _MixMap     ("_MixMap", 2D)     = "black" {}  
        _ShadowMap  ("_ShadowMap", 2D)  = "white" {}  
        _DecalMap   ("_DecalMap", 2D)  = "white" {}  
          
        _LightThreshold("光阈值",Range(-2,2))=1    //控制裁边  
        _RampOffset("Ramp偏移",Range(-2,2)) =0  
        _DarkIntensity("暗部强度",Range(0,1)) = 0  
        [Space(30)]  
        _SpecularIntensity("高光强度",Float) =1  
        _SpecularPowerValue("高光曲率",Float) =1  
        [Space(30)]  
        _MetallicStepSpecularWidth("金属裁边高光宽度",Float) =0.5  
        _MetallicStepSpecularIntensity("金属裁边高光强度",Float) =0.3  
        [Space(30)]  
        _LeatherStepSpecularWidth("皮革裁边视角光宽度",Float) =0.5  
        _LeatherStepSpecularIntensity("皮革裁边视角光强度",Float) =0.3  
        [Space(30)]  
        _CommonStepSpecularWidth("普通材质 裁边高光宽度",Float) =0.5  
        _CommonStepSpecularIntensity("普通材质 裁边高光强度",Float) =0.3  
  
        [Space(30)]  
        _LineIntensity("损旧线条强度",Range(0,1)) = 0  
        [Space(30)]  
        _RimWidth("边缘光宽度",Float) =0.5  
        _RimIntensity("边缘光强度",Float) =0.3  
                [Space(30)]  
        _OulineScale("描边粗细",Float) =1  
        _OutlineColor ("描边颜色",Color) = (0,0,0,0)  
          
        [Space(50)]  
         _TestValue("_TestValue",Range(0,1)) = 0  
         [Space(50)]  
        _LumIntensity("Lum Intenisty",Float) = 1          
}  
  
    SubShader  
    {  
        Tags { "RenderType"="Opaque" "LightMode"="ForwardBase" }  
  
        //base Pass  
        Pass  
        {  
            CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
              
            #include "UnityCG.cginc"  
  
            sampler2D _BaseMap,_LightMap,_LineMap,_MixMap,_ShadowMap,_DecalMap;  
  
            int _TestMode;  
            #pragma shader_feature _TESTMODE_NONE  
  
            float4 _ShadowColor,_SpecularColor;  
  
            float _LightThreshold,_RampOffset;  
            float _LineIntensity;  
            float _DarkIntensity;  
              
            //高光  
            float _SpecularIntensity,_SpecularPowerValue;  
            //金属裁边高光曲率  
            float _MetallicStepSpecularIntensity,_MetallicStepSpecularWidth;  
            //皮革  
            float _LeatherStepSpecularWidth,_LeatherStepSpecularIntensity;  
            //普通材质 裁边视角光  
            float _CommonStepSpecularWidth ,_CommonStepSpecularIntensity;  
  
            //边缘光  
            float _RimWidth,_RimIntensity;  
            float _TestValue;  
            float _LumIntensity;  
              
            struct MeshData  
            {  
                float4 vertex       : POSITION; //局部坐标  
                float2 uv           : TEXCOORD0;//UV  
                float2 uv2          : TEXCOORD1;//UV2  
                float4 tangent      :TANGENT;   //切线  
                float3 normal       : NORMAL;   //法线  
                float4 vertexColor  : Color;    //顶点颜色  
            };  
  
            struct VertexToFragmentData  
            {  
                float4 pos          : SV_POSITION;  
                float2 uv           : TEXCOORD0;  
                float3 tangent      : TEXCOORD1;  
                float3 normal       : TEXCOORD3;   
                float3 worldPosition: TEXCOORD4;  
                float4 vertexColor  : TEXCOORD5;  
                float2 uv2          : TEXCOORD6;  
            };  
              
            VertexToFragmentData vert (MeshData v)  
            {  
                VertexToFragmentData o;  
                o.pos           = UnityObjectToClipPos(v.vertex);  
                o.uv            = v.uv;  
                o.uv2           = v.uv2;  
                o.normal        = UnityObjectToWorldNormal(v.normal);  
                o.worldPosition = mul(unity_ObjectToWorld,v.vertex);  
                o.tangent       = UnityObjectToWorldDir(v.tangent);  
                o.vertexColor   = v.vertexColor;  
                return o;  
            }  
  
            float4 frag (VertexToFragmentData i) : SV_Target  
            {  
                float3 T = normalize(i.tangent);  
                float3 N = normalize(i.tangent);  
                float3 B = normalize( cross(N,T));  
                float3 L = normalize( UnityWorldSpaceLightDir(i.worldPosition.xyz));  
                float3 V = normalize( UnityWorldSpaceViewDir(i.worldPosition.xyz));  
                float3 H = normalize(V+L);//半角向量  
                float2 uv = i.uv;  
                float2 uv2 = i.uv2;  
  
                float4 VertexColor = i.vertexColor;  
                // return VertexColor.xyzz;  
                float HV = dot(H,V);  
                float NV = dot(N,V);  
                float NL = dot(N,L);  
                float NH = dot(N,H);  
  
                float TL = dot(T,L);  
                float TH = dot(T,H);  
  
/*==========================Texture ==========================*/  
  
                float3 FinalColor   = 0;  
                float4 BaseMap      = tex2D(_BaseMap,uv);  
                float4 LightMap     = tex2D(_LightMap,uv);  
                float4 LineMap      = tex2D(_LineMap,uv);  
                float4 MixMap       = tex2D(_MixMap,uv);  
                float4 ShadowMap    = tex2D(_ShadowMap,uv);  
                float4 DecalMap     = tex2D(_DecalMap,uv);  
  
                float LayerMask                 = LightMap.r;//材质类型  
                float RampOffsetMask            = LightMap.g *2-1;//Ramp偏移值  //值域重新映射 [0,1]-> [-1,1]                float SpecularIntensityMask     = LightMap.b;//高光强度mask  
                float InnerLineMask             = LightMap.a;//内勾线Mask  
  
                float ShadowAOMask                = VertexColor.r>0.5;//AO 常暗部分  
                // VertexColor.g;//用来区分身体的部位, 比如 脸部=88  
                // VertexColor.b;//渲染无用  
                float OutlineIntensity            = VertexColor.a  ;//描边粗细  
                //罪恶装备Strive的特殊材质,单独做Shader  
                //自发光单独做的Mesh  
                //描边Pass仅显示背面，如果去掉模型正常显示，那么效果就是一个纯黑，为了方便观察，将模型显示为纯白  
                /*==========================Diffuse ==========================*/  
                float halfLambert = 0.5*NL+0.5;  
                float Threshold = step(_LightThreshold,(halfLambert + _RampOffset +RampOffsetMask )*ShadowAOMask);  //区分亮部和暗部  
                BaseMap*= InnerLineMask;  
                  
                BaseMap = lerp(BaseMap,BaseMap*LineMap,_LineIntensity);  
                float3 BrightSide = BaseMap;  
                float3 DarkSide = lerp(  ShadowMap*BaseMap,BaseMap,_DarkIntensity); //_DarkIntensity  
                float3 Diffuse = lerp( DarkSide,BrightSide,Threshold);  
/*==========================Specular ==========================*/  
                float3 Specular =0;  
                  
                //BlinPhong高光  
                Specular = pow(saturate(NH),_SpecularPowerValue)*_SpecularIntensity * SpecularIntensityMask*BaseMap;  
                Specular = max(Specular,0);  
                //用LayerMask区分高光类型  
                // 0            : 普通  无高光  
                // 50           : 普通  无高光 有边缘光  
                // 100          : 皮革  高光   有边缘光   
// >=200        ：金属  有裁边高光  
  
                //边缘光  
                //普通材质  -BlingPhong高光 -裁边视角光  
                //皮革     -裁边视角光  
                //金属     -裁边视角光(ViewSpace) 模拟反射 (matcap)                float Layer = LayerMask * 255;  
                //边缘光 仅在暗部显示  
                float3 N_ViewSpaceS = mul((float3x3)UNITY_MATRIX_V, T);//将平滑后的法线转到 视角空间下  
                float3 Rim = step(1-_RimWidth,abs( N_ViewSpaceS.x))  
                *_RimIntensity*BaseMap;  
                Rim *=  1 - Threshold;  
                //金属 裁边高光  
                if(Layer>190)  
                {  
                    float3 MetallicStepSpecular = step(abs( N_ViewSpaceS.x),_MetallicStepSpecularWidth)*_MetallicStepSpecularIntensity*BaseMap; //裁边视角光(模拟反射,ViewSpace)  
                    MetallicStepSpecular = max(0,MetallicStepSpecular);  
                    Specular += MetallicStepSpecular;  
                }  
                // return 0;  
                float SpecularIntensity = SpecularIntensityMask*255;  
                  
                //  
                //鞋子上的高光 (普通材质高光)  
                if(Layer>0  && Layer<=60)  
                {  
                   float StepSpecularMask = float(SpecularIntensity>0  && SpecularIntensity<180);// step(128,SpecularIntensity)* step(0,SpecularIntensity)  
                   float3 LeatherSpecular = step(1-_CommonStepSpecularWidth,NV)*_CommonStepSpecularIntensity*BaseMap * StepSpecularMask;  
                   LeatherSpecular = max(0,LeatherSpecular);  
                   Specular = lerp(Specular, LeatherSpecular,StepSpecularMask);  
                }  
                  
                //皮革:裁边视角光  
                if(Layer>60 && Layer<190)  
                {  
                   float StepSpecularMask = float(SpecularIntensity>180);  
                   float3 LeatherSpecular = step(1-_LeatherStepSpecularWidth,NV)*_LeatherStepSpecularIntensity*BaseMap * StepSpecularMask;  
                   LeatherSpecular = max(0,LeatherSpecular);  
                   Specular = lerp(Specular, LeatherSpecular,StepSpecularMask);  
                }  
                  
                //自发光是单独的Mesh  
                //float3 Emission = 0;  
                FinalColor = Diffuse + Specular + Rim;  
  
                return float4(FinalColor,1)*_LumIntensity;  
            }  
            ENDCG  
        }  
          
        //Outline Pass  
        Pass //"OutLine"  
        {  
            Name "TANGENT"  
            Cull Front  
                        CGPROGRAM  
            #pragma vertex vert  
            #pragma fragment frag  
            #pragma multi_compile_fwdbase  
  
            #include "UnityCG.cginc"  
          struct appdata  
            {  
                float4 vertex : POSITION;  
                float4 vertexColor : COLOR;  
                float4 tangent :TANGENT;  
            };  
  
            struct v2f  
            {  
                float4 pos : SV_POSITION;   
            };  
  
            float _OulineScale;  
            float4 _OutlineColor;  
            v2f vert(appdata v)  
            {  
                v2f o;  
                v.vertex.xyz += v.tangent.xyz *_OulineScale*0.01*v.vertexColor.a; //用顶点色的alpha通道控制描边粗细  
                o.pos = UnityObjectToClipPos(v.vertex);  
                return o;  
            }  
            float4 frag(v2f i) : SV_Target  
            {  
                return _OutlineColor;  
            }  
            ENDCG  
        }  
         
    }  
}
```