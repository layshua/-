
主要内容：**PCSS 算法思路和其他生成软阴影方法 vssm***


本节主要内容是关于 pcf 和 pcss 的深度了解以及 vssm.

A Deeper Look at PCF

![[dc3782a557a214b21a2f192321c4dd71_MD5.jpg]]

**我们先来回顾一下 PCF 做了什么事**:

对于实际渲染的点 X, 我们找到其投影到 shadow map 上对应的像素点 ---p, 我们不只考虑点 p, 还要考虑其周围一圈范围内的像素, 区域内各像素的根据到点 p 的距离进行加权平均, 离得远贡献小, 离得近贡献大.

区域内除点 p 的其他像素在 shadow map 上记录的最小深度, 也与 x 的实际深度进行比较, 从而判断区域内有多少 fragments 是遮挡物 (Blocker), 然后算出平均的 visilibity, 从而得到了一个在 0 到 1 之间的软阴影效果.

得到卷积
![[Pasted image 20230622230807.png]]
$$
[w*f](p)=\sum_{q\in\mathcal{N}(p)}w(p,q)f(q)
$$

**这个公式的意义就是:**

对于任意一点 p, 我们取其周围一圈作为邻域, 也就是图中的 $N(p)$, 在邻域中取一点 $q$, 我们考虑邻域中的所有点 $q$, 并将各点 $q$ 的值, 根据点 $q$ 与点 $p$ 间的距离做一个加权处理, 最后把加权所有点 $q$ 后的值写入点 $p$ 的值, 也就是做了一个 filter.(也就是卷积).

**PCF 的公式:**
![[Pasted image 20230622230951.png]]
$$
V(x)=\sum\limits_{q\in\mathcal{N}(p)}w(p,q)\cdot\chi^+[D_{\text{SM}}(q)-D_{\text{scene}}(x)]
$$
![[55ba08e5ef4b0ffc8d8f8b546695e457_MD5.png]]

如果图中的公式值 > 0, 那么
![[Pasted image 20230622231017.png]]
的值为 1, 反之小于 0, 值为 0.

将每一个点 q 与 x 的实际深度比较后, 知道了各自的 visilibity 是 0 还是 1, 将所有点 q 对应的 visilibity 进行一个平均, 就得到了点 x 在经过 pcF 后的效果.

![[d482edf183ac2215513ac1a64353ca7c_MD5.jpg]]

从图中公式可知, pcf 并非在 filter Shadow map, 图中下方为 filter shadow map, 从公式中可知, 最后我们得到的值仍然是非 0 即 1 的, 得到的仍然是硬阴影.

以上就是关于 pcf 的数学公式方面的知识.

**那么在 PCSS 里我们做了什么事呢?**

![[eca34849024822bf9deb6e6cab66dba2_MD5.jpg]]

首先将 shading point 点 x 投应到 shadow map 上, 找到其对应的像素点 p.

a) 在点 p 附近取一个范围 (这个范围是自己定义或动态计算的), 将范围内各像素的最小深度与 x 的实际深度比较, 从而判断哪些像素是遮挡物，把所有遮挡物的深度记下来取个平均值作为 blocker distance。（Blocker search）

第二步：用取得的遮挡物深度距离来算在 PCF 中 filtering 的范围。

第三步：进行 pcf 操作.

步骤 1 和步骤 3 需要对整个区域的各个 texels 与点 x 的深度进行比较，所以会导致很慢。

如果觉得区域过大不想对每一个 texels 都进行比较, 就可以通过随机采样其中的 texels，而不是全部采样，会得到一个近似的结果, 近似的结果就可能会导致出现噪声。

工业的处理的方式就是先稀疏采样得到一个有噪声的 visibility 的图, 接着再在图像空间进行降噪。至于如何降噪在 real-time ray tracing 讲.

由于需要在一个范围内进行比较，那么步骤 1 和 3 的时间开销会决定整个算法的时间开销，此外为了得到越 “软” 的阴影意味着需要使用更大的 filtering size，会导致速度越慢。为了解决这两步慢的问题, 就有人提出了 Variance Soft Shadow Mapping。

**Variance soft shadow mapping**

Variance soft shadow mapping 主要解决了 PCSS 中第一步和第三步慢的问题.

我们回到第三步 PCF 之中, 我们要在 shadow map 上对其周围的一圈像素的各个最小深度与 Shading point 比较, 从而判断是否遮挡, 也就是要求出范围内有百分之多少的像素比它浅.

这个过程很像在考试成绩出来后, 你知道了自己的成绩, 你想知道自己在班级中的排名, 因此你需要知道班级中所有人的成绩从而进行比较来判断自己是百分之几, 这就是 PCF 的做法.

但现在我们就是为了避免这种时间消耗大的做法.

那么一个不错的办法就是, 对班级所有人的成绩做成一个直方图, 根据直方图我们可判断出自己的成绩排名.

![[865bca175a5c303432127076a6172f51_MD5.jpg]]

如果我们不需要那么准的话就可以当做一个正态分布，正态分布就只需要方差和平均值就能得出, 更加的方便快速, 这也就是 VSSM 的核心思想, 通过**正态分布**来知道自己大约占百分之几.

VSSM 的 **key idea** 是快速计算出某一区域内的均值和方差.

![[a8fd6f934fd559fa5b6ae5569dd753ee_MD5.jpg]]

**均值:**

对于快速的求一个范围内的求均值, 我们可以想到在 games101 中学到的 mipmap 方法. 但是 **mipmap** 毕竟是**不准**的, 而且只能在正方形区域内查询. 因此引入 Summed Area Tables (SAT）.

**方差:**

VSSM 用结合了**期望**与**方差**之间的关系的一个公式来得到方差:

$Var(X) = E(X^2) - E^2(X)$

这个公式的含义是用 **平方值的期望 - 期望值的平方** = 方差.

用这个公式的原因是:

在 shadow map 中我们存储的是 depth, 因此 depth 也就是公式中的 x, 在指定区域范围后, 可以快速的求出区域范围的平均值 (期望), 因此也可以很快求出区域范围内平均值的平方, 也就是求出了 $E^2(X)$ .

那么求 $E(X^2)$ , 我们就需要额外生成一张 shadow map, 但是这张图上存的不是 depth, 而是 $depth^2$ , 然后再在指定范围区域内快速求出平均值, 也就是求出了平方值的期望, 求出了 $E(X^2)$ , 这张存储了 $depth^2$ 的 shadow map 叫做 square-depth map.

**也就是为了求方差, 需要在生成 shadow map 时再存储一张 square-depth map。**

到此为止我们就快速获得了均值和方差。那么回到问题本身:

有多少百分比的像素是比 Shading point **大** 也就是 **不会挡住** Shading point 的只需要计算出下图 **PDF 中白色面积** 的值就行了。

有多少百分比的像素是比 Shading point **小** 也就是 **会挡住** Shading point 的只需要计算出下图 **PDF 中灰色面积** 的值就行了。

注：

PDF：概率密度函数（probability density function）, 在数学中，**连续型随机变量**的概率密度函数是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。

CDF : 累积分布函数 (cumulative distribution function)，又叫分布函数，是**概率密度函数的积分**，能完整描述一个实随机变量 X 的概率分布。

![[26cc4d6bb7e90132a788c0be72fd113a_MD5.jpg]]

其实想知道 CDF，也就是求出 PDF 曲线下对应的面积.

对于一个通用的高斯的 PDF，对于这类 PDF，可以直接把 CDF 结果，输出为一个表，叫误差函数 Error Fuction，误差函数有数值解，但是没有解析解，在 C++ 中的函数 ERF(lower_limit,[upper_limit]) 函数可以计算 CDF。

![[786557ce2647da193a698593274a578b_MD5.jpg]]

我们用切比雪夫不等式, 来近似地求出在知道 **期望** 和 **方差** 时候, 不考虑是不是正态分布, 图中红色面积不会超过等式右边，这里使用了一个 Trick 的方法，将这个**不等式近似为相等.**

那么就可以通过均值和方差获得图中红色面积的值。因此就可以不用计算 CDF 了，而是通过 1 - 求出的 x>t 的面积值得到 CDF. 但是**切比雪夫不等式有一个苛刻的条件：t 必须在均值右边，也就是 t 大于均值。**

**加速第三步总结:**

**1. 我们通过生成 shadow map 和 square-depth map 得到期望值的平方和平方值的期望再根据公式 得到方差**

**2. 通过 mipmap 或者 SAT 得到期望**

**3. 得到期望和方差之后, 根据切比雪夫不等式近似得到一个 depth 大于 shading point 点深度的面积., 也就是求出了未遮挡 Shading point 的概率, 从而可以求出一个在 1-0 之间的 visilibity.**

也就是省去了在这个范围内进行**采样**或者**循环**的操作, 大大加速了第三步.

如果场景 / 光源出现移动 就需要更新 MIPMAP，本身还是有一定的开销，但是生成 MIPMAP 硬件 GPU 支持的非常到位，生成非常快（几乎不花时间），而是 SAT 会慢一点，这个后面进行分析。

到目前为止 VSSM 也只解决了第三步 PCF Filter 的问题，PCSS 在第一步要需要求在范围内将所有像素的深度走一遍从而求平均遮挡深度 Average Blocker Depth 的问题并未解决。

![[ff71fc3e1b5db0ba4d574cfab58e86f3_MD5.jpg]]

我们以图中的 5*5 范围为例, 假设我们的 Shading point 的深度是 7.

![[591a59fe543f032f045869e154072e18_MD5.jpg]]

我们将其分为两个区域, **蓝色**是深度小于 shading point 的遮挡区域, 其平均深度为 Zocc **红色**是深度大于 shading point 的非遮挡区域. 其平均深度为 Zunocc. 并且我们认为区域内的像素总数为 N, 非遮挡的像素为 N1 个, 遮挡的像素为 N2 个.

![[af0a943880fdda0082b50c81bc7dee58_MD5.jpg]]

核心思路:

我们需要去计算求出 $Z_{unocc}$ 和 $Z_{occ}$ , 通过他们之间的关系我们可以得出一个数学公式:

$\frac{N1}{N} * Z_{unocc} + \frac{N2}{N} * Z_{occ} =Z_{Avg}$

**非遮挡像素占的比例 * 非遮挡物的平均深度 + 遮挡像素占的比例 * 遮挡物的平均深度 = 总区域内的平均深度.**

总区域内的平均深度我们用 mipmap 或者 SAT 去求, 然后用 shadow map 和 square-depth map 方差, 最后根据切比雪夫不等式近似求出 $\frac{N1}{N}$ 和 $\frac{N2}{N}$ 。

$\frac{N1}{N} = P(x > t)$

$\frac{N2}{N} = 1 - P(x > t)$

此时公式中的 $Z_{unocc}$ 和 $Z_{occ}$ 仍然是不知道的, 我们做一个大胆的假设, 我们认为非遮挡物的平均深度 = shading point 的深度, 至此我们只剩下 $Z_{occ}$ 的深度, 将所有值代入可求出遮挡物的平均深度,$Z_{occ}$. 但是接受平面是曲面或者与光源不平行的时候就会出问题。

![[d718e036d63eddda6323d60ad246f4ba_MD5.jpg]]

VSSM 的做法实在是十分聪明, 采用了非常多的大胆假设，同时非常的快，没有任何噪声，本质上其实也没有用正态分布，是直接用切比雪夫不等式来进行近似。但是现在最主流的方法仍然是 PCSS, 因为人们对噪声的容忍度变高加上降噪的技术越来越高明, 因此大多数人采用 PCSS.

**MIPMAP 和 SAT**

VSSM 中如何加速第一步和第三步的我们知道了, 那么如何在区域范围内快速的求出均值呢?

有两个方法: MIPMAP 和 SAT.

![[e9c61825507642135a1db35e6f8af0df_MD5.jpg]]

最简单的方法自然是 MIPMAP, 我们在 GAMES101 里学过, 他是一个**快速的, 近似的, 正方形的范围查询,** 由于他要做插值, 因此即便是方形有时也会不准确. 同时当插值的范围不是 2 的次方时，也就是在两个 MIPMAP 之间时，还要再进行一次插值，也就是 “三线性插值”，这样会让结果更加不准确, 因此局限性太大且准确度也不算高.

但是 SAT 是百分百准确的一个数据结构. SAT 的出现是为了解决范围查询 (在区域内快速得到平均值), 并且, 范围内求平均值是等价于范围内求和的, 毕竟总和除以个数 = 平均值.

在 1 维情况下其实就是一维数组, SAT 这种数据结构就是做了预处理，也就是在得到一维数组时, 先花费 O(n) 的时间从左到右走一遍, 并且在走的同时把对应的累加和存入数组 SAT 中，那么 SAT 上任意的一个元素就等于原来数组从最左边的元素加到这个元素的和, 如图 SAT 数组第 2 个元素表示原数字前 2 个元素之和。

那么查询下图中 SUM 区域总和时候，就是 SAT 数组中第六个元素减去第三个元素。相当于使用了_O_(_n_) 的时间，把预计算做了一遍。

![[e24210f070f4b69e9289d8e791bfeb4a_MD5.jpg]]

那么在 2 维（二维数组）情况下 有一个任意矩形（横平竖直），蓝色矩形内的总和为两个绿色矩形内的总和减去两个橙色矩形内的总和。同样可以采用 SAT 的方法，做一个表，做出从左上角到这个元素的和。因此只需要**查表 4 次**就可以得出精准的区域求和。

在 2 维情况下，可以通过建立 m 行中每行的 SAT 和在每行的 sat 基础上再建立 n 列中每列的 SAT，最终可以获得一个 2 维的 SAT 因此最终的 SAT, 但是由于 gpu 的并行度很高, 行与行或列与列之间的 sat 可并行, 因此具有 m×n 的时间复杂度。

![[1414c5e759ee9428cec0f0ca375143a0_MD5.jpg]]

其实这个算法就是 leetcode 1314 matrix block sum 的算法.

## **Moment shadow mapping**

VSSM 是为了解决 PCSS 的问题, 但 vssm 由于做了很多假设，当假设不对的时候会有问题。

![[cecf3e01215ce550560213f43777dadc_MD5.jpg]]

比如右图，只有三个片的遮挡的情况下，那么深度的分布就在这三个遮挡度深度周围，形成了三个峰值，自然就会出现假设描述的不准。

![[1aa2457474073a47deeb8b5a4dd3246f_MD5.jpg]]

不是正态分布强行按正态分布算就会出现漏光和过暗的结果。在阴影的承接面不是平面的情况下也会出现阴影断掉的现象。

![[7e59a0d5979208ff854c7406c42103a9_MD5.jpg]]

我们看图中小车可以发现, 在车的底部阴影部分出现了一部分偏白的阴影, 这是因为车是一个镂空的状态, 如果从底部向 LIGHT 处看去会发现底板遮挡一部分, 车顶附近会遮挡一部分, 这就导致了不是正态分布情况, 因此才出现 light leaking 这种情况.

因此人们为了避免 VSSM 中不是正态分布情况下的问题, 就引入了更高阶的 moments 来得到更加准确的深度分布情况. 想要描述的更准确，就要使用更高阶的 moment(矩)，矩的定义有很多，最简单的矩就是记录一个数的次方，VSSM 就等于用了前两阶的矩。这样多记录几阶矩就能得到更准确的结果。

![[381e4a046d373866c3fa002ba228a086_MD5.jpg]]

如果保留前 M 阶的矩，就能描述一个阶跃函数，阶数等 2/M, 就等于某种展开。越多的阶数就和原本的分布越拟合。一般来说 4 阶就够用。

![[74a6eb00a5d364975967928ccb278c9e_MD5.jpg]]