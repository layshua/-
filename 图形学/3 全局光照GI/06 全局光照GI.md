
---
title: 06 全局光照GI
aliases: []
tags: []
create_time: 2023-07-15 16:19
uid: 202307151619
banner: "![[Pasted image 20230715162230.png]]"
---



全局光照是增强真实感的重要部分, 因此也是十分复杂的一部分.

从下图中我们会发现, 没有任何一处是全黑的看不见东西的, 比如书本的下方, 蜡烛内部等. 也就是光线 bounce 了很多次才到达我们的眼里, 在 GAMES101 中我们在布林冯模型中, 假设 ambient 项, 认为来自四面八方的间接光照都是相同的, 且最后的 shading 和 normal 是无关的, 这样得到的结果是十分不真实的。
![[Pasted image 20230715161900.png]]
图中的全局光照就不能这么假设了, 大家可以看到书本下方各位置的亮度不同, 还可以看到一些焦散等从金属球反射出的间接光, 他们之间是不一样的, 如果还做 Ambient 项项那种假设从而只提升了一点亮度是无法得到图中的结果的.

---

在实时渲染中, 全局光照是**比直接光照多一次光线弹射的间接光照**

![[Pasted image 20230715162643.png]]
如图中, 光线弹射两次, 先打到红色的墙壁上, 在达到 box 面上, 最后被 camera/eye 看到, 这就是在 rtr 中要解决的所谓的 "全局光照".

我们希望他:
**①简单 -> 实现起来不麻烦**
**②快速 -> 因为全局光照非常难算**

# 实时 GI （世界空间）
![[Pasted image 20230715162802.png]]
前面提到过，在 path tracing 时, 从 camera 出发打出一条光线到点 P, P 点又往场景中不同的方向发射光线, 如果打到光源则表示接受的是**直接光照.**
如果没打到光源而是打到了点 Q, 那么我们认为 P 点接收到的光照是从 $Q$ 点反射到 P 点的 Radiance, 也就是 Q 点接收到的直接光照所反射出的光照打到 P 点上.
点 $Q$ 接受的是直接光照, 我们则认为接收到直接光照的表面可以被当作**虚拟点光源 (Secondary Light Sourse)** 用自身反射的光照来照亮其他物体.
**总之把 $Q$ 当成光源（虚拟点光源）**

![[def7c012709fdb3a0d19310869b53be0_MD5.jpg|650]]
>我们可以看到 $P$ 点在柱子后面, 不可能接收到直接光照, 我们稀疏的标示出虚拟点光源。将所有照射到 $P$ 点的虚拟点光源加起来，就是 $P$ 点的着色结果。

## RSM 反射阴影贴图
Reflective Shadow Map 

[Monica 的小甜甜：【论文复现】Reflective Shadow Maps](https://zhuanlan.zhihu.com/p/357259069)
本质就是 shadowmap，不过是多存了一些信息，注意它不是用来解决阴影问题的，而是用来解决间接光照问题的：**shadowmap 中存的像素就是场景中可以被照亮的像素，而这些被照亮的物体也可以作为光源发出间接光照照亮其他物体。**

> [!NOTE] RSM 数据存储
> RSM 在每一个像素 $p$ 中都需要存储深度值 $d_p$，世界坐标 $x_p$，法线 $n_p$，反射光功率 $\phi _p$，如下图的可视化效果，四个 map 对应像素 p 的四个参数.
> 
> ![[e64145f9c3a27bcc60c8831b9b276982_MD5.jpg]]

### **虚拟点光源**

RSM 的核心思想是把直接光源照亮的区域又作为发光物（虚拟点光源）来进行计算。

- 第一步：先单独计算直接光照对环境的影响。
- 第二步：要获得直接光照亮的区域，那么该如何获得这块区域呢？其实有个很简单的办法，**从光源的视角进行一次渲染就可以得到从光源视角看的区域**，本质是一个shadowmap（渲染之后我们保存位置信息，法线信息和颜色信息到纹理中）。
- 第三步：用第二步保存的信息用于计算间接光照，**RSM 的核心就是把这个发光区域的每一个像素都看成一个光源叫做虚拟点光源**（Virtual point light：VPL），然后用这所有的虚拟点光源来计算间接光照
- 第四步：将间接光照和直接光照融合起来（直接相加即可）。


- ? **那么为了计算点 $P$ 的 shading 需要知道什么？**
1. 哪些表面位置会被直接照到？=>使用 shadowmap
2. 如何计算每个虚拟点光源对着色点 $P$ 的贡献？=>渲染方程
### 问题 1
**Reflective Shadow Map (RSM)假设: 所有的反射物 (虚拟点光源) 都是 diffuse 的，但不要求点 $P$ 是 diffuse**

虚拟点光源如果想照亮点 $P$, 观察方向是从 $P$ 点去观察虚拟点光源的, 也就是对于不同的 P 点来说出射方向是未知的, 因此是无法计算 $P$ 点的 shading 的, 为了不依赖于观察方向, **在 RSM 中我们假设，所有被当作虚拟点光源的反射物都是 diffuse，不要求点 $P$ 是 diffuse，故点 P 的反射方向仍是未知的。这样不管从 camera 看过去还是从点 $P$ 看过去所得到的结果是一样的。**

**如何判断虚拟点光源能否看到着色点?**
渲染方程中的 V 是指虚拟点光源到着色点是否可见，如果想解决这个问题，需要为每个虚拟点光源算一次 shadow map，这个运算无法算。**RSM 中忽略虚拟点光源到着色点的可见性判断，认为都是可见的**

### 问题 2

**考虑所有虚拟点光源的贡献，进行求和；并且每个虚拟点光源可以看成是一个面光源。**

学习路径追踪时提到了一个方法 [[04 路径追踪#提高效率->直接采样光源]]，**在着色点采样寻找光源效率太低了，我们可以直接采样光源！直接计算光源对着色点的贡献**，需要将 $d\omega$ 换成换成 $dA$，渲染方程转换如下：
$$
\begin{aligned}
L_o(\text{p},\omega_o)& =\int_{\Omega_\mathrm{patch}}L_i(\mathrm{p},\omega_i)V(\mathrm{p},\omega_i)f_r(\mathrm{p},\omega_i,\omega_o)\cos\theta_i\mathrm{d}\omega_i  \\
&=\int_{A_\text{patch}} L _ i ( {q}\to{p})V({p},\omega_i)f_r({p},{q}\to{p},\omega_o)\frac{\cos\theta_p\cos\theta_q}{\|q-{p}\|^2}\mathrm{d}A
\end{aligned}
$$
![[Pasted image 20230713185739.png|400]]

对于每个虚拟点光源点来说, 由于我们假设它的 brdf 是 diffuse 的, 因此：
- $f_{r}=\rho/\pi$
- $\displaystyle L_i=f_r\cdot\frac{\Phi}{dA}$（$\Phi$ 为入射的辐射通量）

 $E_p$ 表示虚拟点光源对着色点贡献的入射辐照度：
$$
E_{p}(x,n)=\Phi_{p}\frac{\max\{0,\left<n_{p}|x-x_{p}\right>\}\max\{0,\left<n|x_{p}-x\right>\}}{||x-x_{p}||^{4\textbf{ ->2}}}.\quad(1)
$$

求出了一个虚拟点光源 $p$ 对着色点所得到的 shading 结果, 再将积分域中所有的结果加在一起, 就是着色点最后被间接光照照亮所得到的 shading 值.

*   值得注意的是原文公式中的分母是 4 次方，闫老师认为是作者考虑了虚拟点光源发射的光线有衰减，这里应该是 2 次形式。(他们后来说闫老师吃键盘了, 我毕竟还没看到后面所以我先留着.) 更新: **闫老师确实吃键盘了, 但是老师没有错, paper 也没有错, 因为在分子中有两个 Xp-X，当把这两个放到分母中后，结果与我们推导的结果一致，同为 2 次方。**

### shadowmap 像素的贡献
![[Pasted image 20230715172836.png|500]]
由于可见性、方向性以及距离的不同，对于某一个着色点，认为 shadow map 上并不是所有的 pixel 都有贡献:
*  可见性测试项（仍然非常难算）；
*  方向：比如 $X_{-1}$ 点在 shadowmap 中记录的是桌子的表面，而且这个表面的点法线方向是朝上的，因此根本不可能照亮 X 点；
*  距离：因为远处的虚拟点光源贡献很少，通常只要找距离足够近的虚拟点光源就行了。
    * 为了加速这一过程, 我们认为在 shadow map 中着色点 $x$ 的位置和间接光源 $x_p$ 的距离可以近似为它们在世界空间中的距离。所以我们认为，对着色点 $x$ 影响大的间接光源在 shadow map 中一定也是接近的。![[Pasted image 20230715173053.png|350]]
    * 于是我们决定先获取着色点 $x$ 在 shadow map 中的投影位置 $(s,t)$，在该位置附近采样间接光源，多选取一点离着色点近的 VPL，并且为了弥补越往外采样数越少可能会带来的问题，引入了权重，越近了权重越小，越远的权重越大。那么对于一个 shading point 差不多找 400 个虚拟点光源来计算是比较合适的。

### 应用：手电筒
RSM 效果通常应用于游戏中手电筒的次级光照，如图:

![[96d94721b441e925d1265fe33774371d_MD5.jpg]]

在此可以更加理解我上文写的对于式子的理解
屋顶某个点亮了的区域就是手电筒直接照亮区域对屋顶那个点的贡献, 屋顶点积分的时候积分域就是手电筒直接照亮的位置.

**优点：**
*   易于实现

**缺点：**
*   性能随着直接光源数的增加而降低 (因为需要计算更多的 shadow map)
*   对于间接光照，没有做可见性检查
*   有许多假设：反射物需要是 diffuse 等
*   需要在质量和采样率上做一个平衡



## LPV 光传播体积
光传播体积：Light Propagation Volumes

**在 3D 空间中去传播光线, 从而利用它做出间接光照从而实现 GI.**

LPV 快速且高质量

- **主要问题:**
    *   如果我们能获得任何一个 Shading point 上来自四周的 radiance 的话, 就可以立刻得到其间接光照
- **核心思路:**
    *   光在传播过程中, 辐射率 radiance 是不变的（辐照度是按距离平方衰减的）
- **核心解法:**
    *   将场景划分为**若干个 3D 网格, 每个网格叫做 Voxel (体素),** 在计算完直接光照后, 将接受到直接光照的表面看作间接光照在场景中传播的起点.

![[532dad92206587f6adcb1b3a55f6fe12_MD5.jpg]]
### 步骤
- **步骤:**
    1.  找出接收直接光照的点
    2.  把这些点注入 (inject) 到 3D 网格中作为间接光照 (虚拟光源) 的传播起点.
    3.  在 3D 网格中传播 radiance
    4.  传播完后, 渲染场景

- **具体步骤:**
1. **生成**
    - 这是为了找到直接被照亮的表面
    - 与 RSM 一样, 首先通过 Shadow Map 找出接受直接光照的表面或物体
    - 对得到的光源数量可以通过采样一些进行简化从而降低次级光源数量, 最后获得一系列虚拟光源 ![[Pasted image 20230715182911.png|450]]
2. **注入**
*   预先把场景划分为若干个 3D 网格 (体素)，工业界使用 3D 纹理
*   把虚拟光源注入到其对应的格子内
*   一个格子内可能包含许多不同朝向的虚拟光源, 把格子内所有虚拟光源的不同朝向的辐射率算出来相加
*   由于是在空间上的分布, 也就可以看作是球面函数, 自然可以用 SH 来表示 (工业界用两阶 SH 就可以表示各个方向上的辐射率初始值) ![[Pasted image 20230715183123.png|400]]
3. **传播**
    *   由于是 3D 网格, 因此可以向六个面进行传播 (上下左右前后), 由于 radiance 是沿直线传播的, 我们认为 radiance 是从网格中心往不同方向进行传播的, 穿过哪个表面就往哪个方向传播, 比如穿过右表面的 radiance, 就传播到右边的格子里 (不考虑斜角, 比如右上方向, 我们认为是先到右边格子, 再到上面格子)
    *   每个格子计算收到的 radiance, 并用 SH 表示
    *   迭代四五次之后, 场景中各 voxel 的 radiance 趋于稳定 ![[Pasted image 20230715183339.png|400]]
4. **渲染**
    *   对于任意的 shading point，找到他所在的网格
    *   获得所在网格中所有方向的 Radicae；
    *   渲染。

### 问题
LPV 也有自己的问题, 那就是和 VSSM 一样的问题: 漏光（Light Leaking）

由于我们认为 radiance 是从格子正中心向四周发散的, 当遇到这种情况时,
![[Pasted image 20230715183919.png]]
按理说点 P 反射的 radiance 是无法照亮墙壁的背后, 但是由于我们的假设, 会导致墙壁后面也被间接光照照亮, 也就是所谓的漏光现象.
![[Pasted image 20230715183952.png]]
如图, 你看房屋的下部本不应该被照亮, 但由于使用了 LPV 导致了 light leaking 现象.

**解决漏光现象：划分的格子足够小** 
但是这样会导致存储量增多, 而且传播过程中传播的格子量增多, 也就导致了速度慢。
对于两个格子之间的可见性也进行了假设，假设相邻格子都能看见，同时工业界会用不同大小的格子也就是 **Cascade 层级加速结构**，来优化 LPV 的方法。

## VXGI  体素全局光照
体素全局光照：Voxel Global Illumination

VXGI 也是一个 2-pass 的算法, 但是与 RSM 有一些区别:

**区别 1: 次级光源从 RSM 中的 Pixel 变成了 Voxel (体素)**
![[Pasted image 20230715184511.png|400]]
RSM 中次级光源是像素中所包含的微小表面，这些表面是根据 Shadow Map 来划分的.
**VXGI 把场景完全离散化成了一系列微小的格子**，可以理解为场景是由一堆乐高堆起来的, 如图, 这些是最细的层级, 也就是最小的格子我们可以在这一层基础上去建立一层大点的格子, 依此类推从而根据场景的不同划分建立出一个 Hierachical 树形结构的体素。

**区别 2: 光线从传播变为了追踪**
在 LPV 中, 我们将受到直接光照的点注入到场景划分的 Voxel 之后进行传播, 只需要传播一次就可以知道场景中任何一个 shading point 收到间接光照的 radiance.
而在 VXGI 中第二趟我们从 camera 出发, 就像有一个 Camera Ray 打到每一个 pixel 上, 根据 pixel 上代表的物体材质做出不同的操作, 如果是 glossy 则打出一个锥形区域, diffuse 则打出若干个锥形区域, 打出的锥形区域与场景中一些已经存在的 voxel 相交, 这些 voxel 对于 Shading point 的贡献可以算出来, 也就是我们要对每一个 shading point 都做一个 cone tracing, 可想而知, 这个速度比起 LPV 来说是很慢的, 但是是可以优化的, 暂且不提.

![[2e21f65b7af858c1ba6dd3b661e14ffe_MD5.jpg]]

左图将场景划分为一系列的 voxel, 之后再划分成一个 Hierachical 树形结构, 右图就是 Hierachical 的体素.

**具体步骤:**

**Pass1：Light pass**

不管如何我们首先肯定是先要算直接光照找到哪些 voxel 会被照亮, 那么我们要先从接收到直接光照的 patch 开始, 不管是 RSM 还是什么先找出接受直接光照的 Patch.

但是由于场景是由 voxel 来表示的, 那么对于任何一个格子, 跟 LPV 的注入很像, 但是这里不在记录格子里表面的出射分布或者说认为表面是 diffuse 的半球分布, 也就是不再像 LPV 一样将所有的 radiance 加在一起求各方向的初始值, 那么也就是说可以支持反射物 (patch) 也是 Glossy 的.

![[d19bdb5cb1026db75c20d46f8adafc2f_MD5.jpg]]

记录的是直接光源从哪些范围来（绿色部分），记录各个反射表面的法线（橙色部分），通过**输入方向**和**法线范围**两个信息然后通过表面的材质，来准确的算出出射的分布，这样就比 LPV 认为格子表面是 diffuse 再用 SH 来压缩的方法要准确，然后建立更高层级格子的这些特性。

**Pass 2 : Camera pass**

从这一步开始考虑场景的渲染了, 对于任何一个像素，知道了 Camera Ray 的方向，

**I)** 对于 Glossy 的表面，向反射方向追踪出一个锥形 (cone) 区域；

![[decae715e889f95a6298423ba5d07dbe_MD5.jpg]]

基于追踪出的圆锥面的大小，对格子的层级进行查询，就是对于场景中的所有体素都要判断是不是与这个锥形相交，如果相交的话就要把对于这个点的间接光照的贡献算出来 (我们存储了体素的光照输入方向和法线方向, 因此可以算出其输出的 radiance, 将 cone 区域内所有体素的 radiance 都算出来从而在 shading point 得到间接光照)，也就是根据传播出的距离远近找对应层级的体素，然后找覆盖的范围。(论文中说查询相当于是 mipmap 的操作, 但是我个人没有看完, 等回头有时间将 vxgi 的论文好好看一遍)

**II)** 对于 diffuse 的情况来说, 通常考虑成若干圆锥，忽略圆锥 Tracing 时的重叠和空隙。

![[6bbd1b8a02d2ea0ffe3e5c3b98aaf7e6_MD5.jpg]]

总结：

LPV 是把所有的次级光源发出的 Radiance 传播到了场景中的所有位置，只需要做一次从而让场景每个 Voxel 都有自己的 radiance，但是由于 LPV 使用的 3D 网格特性，并且采用了 SH 进行表示和压缩，因此结果并不准确，而且由于使用了 SH 因此只能考虑 diffuse 的, 但是速度是很快的。

VXGI 把场景的次级光源记录为一个层次结构，对于一个 Shading Point，我们要去通过 Corn Tracing 找到哪些次级光源能够照亮这个点。

![[fcc55a86a8a96421a8dbaa1bd8db8707_MD5.jpg]]

![[65aafe9147790b43ad78c0ff1a58d75b_MD5.jpg]]

![[010009f41f89643ecb2a2634b6d774c7_MD5.jpg]]

结果的质量非常好，与光线追踪的结果非常接近，但是开销还是太大，应用受到了限制。对于 VXGI 我们需要预先对场景体素化，也是一个非常大的问题，由于每一个 Shading point 都要做一些 cone Tracing，操作已经非常像离线渲染了。
