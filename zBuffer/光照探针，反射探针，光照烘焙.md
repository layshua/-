# Reflcetion Probe 反射探针
![[Pasted image 20230716134831.png]]
URP 开启反射探针混合和 Box Projection 功能

每个反射探针都有一个盒子体积。反射探针探针只影响 GameObject 在在 box 体积内的部分。当物体的像素在box体积之外时，Unity 使用 skybox 反射。
在URP中，Unity根据像素相对于探针体积边界的位置，评估每个探针对每个单独像素的贡献。

![[Pasted image 20230716135225.png|450]]
1. **Blend Distance 混合距离**：从 Box 的面到 Box 中心的距离。Unity 使用“混合距离”特性来确定反射探针的贡献。
2. **当一个游戏对象在多个反射探测体积内时，最多两个探测可以影响游戏对象。** Unity 使用以下标准选择影响游戏对象的探测器：
    1. UnitBoxy 选择两个 importance 值较高的探针，忽略其他探针。
    2. 如果重要性值相同，Unity 会选择 Box 体积最小的探针
    3. 如果 importance值和 Box 体积相同，选择包含Gameobject的较大表面积的探针。

## 采样反射探针
**默认不勾选 Box Projection：默认反射光来自无限远的地方，适合采样室外室外场景：**
`unity_SpecCube0` 定义在 UnityInput. hlsl，在 shader 中只需要声明采样器即可
若没有设置反射探针，默认采样SkyBox
```c file:采样skybbox
//声明采样器采样Skybox
SAMPLER(sampler_unity_SpecCube0);

//片元着色器计算
float3 R = normalize(reflect(-V, N)); 
//用反射向量采样cubemap
float4 environment = SAMPLE_TEXTURECUBE(unity_SpecCube0,sampler_unity_SpecCube0, R); 
//立方体贴图包含高动态范围的颜色，这允许它包含大于1的亮度值。我们必须将样本从HDR格式转换为RGB格式。否则可能发生过曝
//unity_SpecCube0_HDR为解码指令
float3 envcolor = DecodeHDREnvironment(environment, unity_SpecCube0_HDR); 
```

### 采样自定义 CubeMap 
采样 CubeMap 贴图步骤上上面一样：
```c file:采样自定义CubeMap
_CubeMap("CubeMap", CUBE) = "white" {}

TEXTURECUBE(_CubeMap)
SAMPLER(sampler_CubeMap);

float3 R = normalize(reflect(-V, N)); 
float4 cubeMap = SAMPLE_TEXTURECUBE(_CubeMap,sampler_CubeMa, R); 
float3 cubeMapcolor = DecodeHDREnvironment(environment, unity_SpecCube0_HDR); 
```

![[Pasted image 20230716115448.png|210]] ![[Pasted image 20230716115453.png|210]]
>使用法线和反射方向采样

## Box Projection
启用 Box Projection，Unity 假定反射光来自探测器的盒子内部，适用于盒状的室内环境：
![[Pasted image 20230716132938.png|500]]
调整好 Box 体积后，使用 `BoxProjectedCubemapDirection` 函数计算反射向量再进行采样：
```c h:3
float3 R = normalize(reflect(-V, N));
 
float3 Reflect = BoxProjectedCubemapDirection(R,i.positionWS,unity_SpecCube0_ProbePosition,unity_SpecCube0_BoxMin,unity_SpecCube0_BoxMax);

float4 environment = SAMPLE_TEXTURECUBE(unity_SpecCube0,sampler_unity_SpecCube0, Reflect);  
float3 envcolor = DecodeHDREnvironment(environment, unity_SpecCube0_HDR);
```

## mipmap 级别

我们可以使用 `UNITY_SAMPLE_TEXCUBE_LOD` 宏在特定的 mipmap 级别上对立方体贴图进行采样。环境立方体贴图使用三线性过滤，因此我们可以在相邻级别之间进行混合。这使我们可以**基于材质的粗糙度来选择 mipmap。**
材质越粗糙，我们应该使用的 mipmap 级别就越高。

当粗糙度从0到1时，我们必须根据我们使用的 mipmap 范围对其进行缩放。Unity 使用 `UNITY_SPECCUBE_LOD_steps` 宏（默认值为 6，为最后一个 mipmap 索引，共 0~6 七级 mipmap）来确定这个范围。

实际上，粗糙度和 mipmap 水平之间的关系不是线性的。Unity 使用转换公式 $1.7r-0.7r^2$ ，其中 $r$ 是原始粗糙度。
![[Pasted image 20230716124752.png|200]]
>蓝色为转换曲线

```c h:2,5
float roughness = 0.5; //粗糙度范围0~1
roughness *= 1.7 - 0.7 * roughness;
float3 R = normalize(reflect(-V, N));

float4 environment = SAMPLE_TEXTURECUBE_LOD(unity_SpecCube0,sampler_unity_SpecCube0, R, roughness * UNITY_SPECCUBE_LOD_STEPS);

float3 envcolor = DecodeHDREnvironment(environment, unity_SpecCube0_HDR);
```

![[Pasted image 20230716133244.png]]



# 光照探针
```c file:光照探针
float4 frag(VertexOutput i): SV_Target 
{
    return  SampleSH(i.normalWS);
}
```


# 烘焙光照
```c
Shader "Universal Render Pipeline/CRLuo/CRLuo_URP_13_LightBaked" //URP路径名
{
     //面板属性
    Properties
    {
    }
        SubShader
        {
			//渲染类型为URP
           Tags { "RenderType" = "Opaque" "RenderPipeline" = "UniversalRenderPipeline"}
			//多距离级别
            LOD 100 

		 Pass
        {

            HLSLPROGRAM  //URP 程序块开始

			//顶点程序片段 vert
			#pragma vertex vert

			//表面程序片段 frag
            #pragma fragment frag
    		#pragma multi_compile _ LIGHTMAP_ON  关键字

			//URP函数库
            #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
			      #include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"

			CBUFFER_START(UnityPerMaterial) 

            CBUFFER_END 

            struct VertexInput          
            {
                float4 positionOS : POSITION; 
                float2 uv : TEXCOORD0;
				float2 uvLM : TEXCOORD1;    //光照uv
				float4 normalOS  : NORMAL;
            };

            struct VertexOutput 
            {
                float4 positionCS : SV_POSITION; 
                float2 uv : TEXCOORD0;
				float3 positionWS :  TEXCOORD1;
				float3 normalWS : TEXCOORD2;
				float2 uvLM : TEXCOORD3;  //光照uv
				float3 vertexSH   : TEXCOORD4;
            };

            VertexOutput vert(VertexInput v)
            {
                VertexOutput o;

                VertexPositionInputs positionInputs = GetVertexPositionInputs(v.positionOS.xyz);
                o.positionCS = positionInputs.positionCS;
                o.positionWS = positionInputs.positionWS;
                VertexNormalInputs normalInputs = GetVertexNormalInputs(v.normalOS.xyz);
                o.normalWS = normalInputs.normalWS;

                OUTPUT_LIGHTMAP_UV(v.uvLM, unity_LightmapST, o.uvLM); 

                return o;
            }

            //表面程序片段
            float4 frag(VertexOutput i): SV_Target 
            {
                float3 normalWS = i.normalWS;
                half3 bakedGI = SAMPLE_GI(i.uvLM, i.vertexSH, normalWS);
                return float4(bakedGI,1);
            }
            
            ENDHLSL  //URP 程序块结束
        }
    }
}
```