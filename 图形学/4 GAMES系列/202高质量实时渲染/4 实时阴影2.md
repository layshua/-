
主要内容：**PCSS 算法思路和其他生成软阴影方法 vssm***


本节主要内容是关于 pcf 和 pcss 的深度了解以及 vssm.

**Variance soft shadow mapping**

Variance soft shadow mapping 主要解决了 PCSS 中第一步和第三步慢的问题.

## 解决第三步
PCSS 第三步我们使用 PCF 的方法绘制软阴影，我们要在 shadow map 上对其周围 Filter Size 内的像素的各个最小深度与 Shading point 比较，从而判断是否遮挡, 也就是要求出 Filter Size 内有百分之多少的像素比它浅。

这个过程很像在考试成绩出来后, 你知道了自己的成绩, 你想知道自己在班级中的排名, 因此你需要知道班级中所有人的成绩从而进行比较来判断自己是百分之几，这就是 PCF 的做法.

但现在我们就是为了避免这种时间消耗大的做法.

那么一个不错的办法就是, 对班级所有人的成绩做成一个**直方图**，根据直方图我们可判断出自己的成绩排名。

![[Pasted image 20230623114042.png]]

如果我们不需要那么准的话，就可以当做一个正态分布，正态分布就只需要知道均值 $\mu$ 和标准差 $\sigma$, 更加的方便快速。

**而 VSSM 使用了切比雪夫不等式，更快速的计算。**

VSSM 的 **key idea** 是快速计算出某一区域内的均值和方差.

**均值:**

对于快速的求一个范围内的求均值, 我们可以想到在 games101 中学到的 mipmap 方法. 但是 **mipmap** 毕竟是**不准**的, 而且只能在正方形区域内查询. 因此引入 **Summed Area Tables (SAT）**

**方差:**

VSSM 用结合了**期望**与**方差**之间的关系的一个公式来得到方差:
[[概率论与数理统计#4 方差 D(X)和标准差#计算方法]]
$D(X) = E(X^2) - [E(X)]^2$

这个公式的含义是用 **方差 = 平方值的期望 - 期望值的平方** .

用这个公式的原因是:

在 shadow map 中我们存储的是 $depth$, 因此 $depth$ 也就是公式中的 $X$, 在指定区域范围后, 可以快速的求出区域范围的平均值 (期望), 因此也可以很快求出区域范围内平均值的平方, 也就是求出了 $E^2(X)$ .

那么求 $E(X^2)$ , 我们就需要**额外生成一张 shadow map**, 但是这张图上存的不是 $depth$, 而是 $depth^2$ , 然后再在指定范围区域内快速求出平均值, 也就是求出了平方值的期望, 求出了 $E(X^2)$ , 这张存储了 $depth^2$ 的 shadow map 叫做 **square-depth map**.

**也就是为了求方差, 需要在生成 shadow map 时再存储一张 square-depth map。**

到此为止我们就快速获得了均值和方差。那么回到问题本身:
- 有多少百分比的像素是比 Shading point **大** 也就是 **不会挡住** Shading point 的只需要计算出下图 **PDF 中白色面积** 的值就行了。
- 有多少百分比的像素是比 Shading point **小** 也就是 **会挡住** Shading point 的只需要计算出下图 **PDF 中灰色面积** 的值就行了。

![[Pasted image 20230624144757.png]]

> [!quote] CDF 和 PDF
> **CDF** [[概率论与数理统计#3 随机变量的分布函数]]: **累积分布函数 (cumulative distribution function)**，又叫**概率分布函数，分布函数**，是**概率密度函数的积分**，能完整描述一个实随机变量 X 的概率分布。
> **PDF**[[概率论与数理统计#4 连续型随机变量及其分布]]：**概率密度函数（probability density function）**, 在数学中，**连续型随机变量**的概率密度函数是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。

其实想知道 CDF，也就是求出 PDF 曲线下对应的面积.

对于一个通用的高斯的 PDF，对于这类 PDF，可以直接把 CDF 结果，输出为一个表，叫误差函数 Error Fuction，误差函数有数值解，但是没有解析解，在 C++ 中的函数 `ERF(lower_limit,[upper_limit])` 函数可以计算 CDF。

![[Pasted image 20230624144956.png]]
$$
P(x>t) \le \frac{\sigma^2}{\sigma^2 + (t-\mu)^2}
$$
**切比雪夫不等式不需要知道随机变量满足什么分布（即图中我们不知道函数曲线是什么样子），只需要知道期望（$\mu$: mean）和方差（$\sigma$: variance）就可以算一个随机变量取的值（$x$）超过某个值（$t$）的概率不会超过 $\displaystyle\frac{\sigma^2}{\sigma^2 + (t-\mu)^2}$**
- 切比雪夫不等式是一个粗略的概率估计
- 必须满足 $t>\mu$

这里使用了一个 Trick 的方法，将这个**不等式近似为相等.**

那么就可以通过均值和方差获得图中红色面积的值。因此就可以不用计算 CDF 了，而是通过 `1 - 求出的 x>t 的面积值得到 CDF`. 

**加速第三步总结:**

**1. 通过生成 shadow map 和 square-depth map 得到期望值的平方和平方值的期望再根据 $D(X) = E(X^2) - [E(X)]^2$ 得到方差**

**2. 通过 mipmap 或者 SAT 得到期望**

**3. 得到期望和方差之后, 根据切比雪夫不等式近似得到一个 depth 大于 shading point 点深度的面积., 也就是求出了未遮挡 Shading point 的概率, 从而可以求出一个在 1-0 之间的 visilibity.**

也就是省去了在这个范围内进行**采样**或者**循环**的操作, 大大加速了第三步.

如果场景 / 光源出现移动 就需要更新 MIPMAP，本身还是有一定的开销，但是生成 MIPMAP 硬件 GPU 支持的非常到位，生成非常快（几乎不花时间），而是 SAT 会慢一点，这个后面进行分析。

## 解决第一步
到目前为止 VSSM 也只解决了第三步 PCF Filter 的问题，PCSS 在第一步要需要求在范围内将所有像素的深度走一遍从而求平均遮挡深度 Average Blocker Depth 的问题并未解决。

我们以图中的 $5*5$ 范围为例, 假设我们的 Shading point 的深度是 7.

我们将其分为两个区域, **蓝色**是深度小于 shading point 的遮挡区域, 其平均深度为 $Z_{occ}$ **红色**是深度大于 shading point 的非遮挡区域. 其平均深度为 $Z_{unocc}$. 并且我们认为区域内的像素总数为 $N$, 非遮挡的像素为 $N_1$ 个, 遮挡的像素为 $N_2$ 个。

![[Pasted image 20230624150706.png]]

核心思路:

我们需要去计算求出 $Z_{unocc}$ 和 $Z_{occ}$ , 通过他们之间的关系我们可以得出一个加权平均公式:

$\displaystyle\frac{N_1}{N} * Z_{unocc} + \frac{N_2}{N} * Z_{occ} =Z_{Avg}$

**非遮挡像素占的比例 * 非遮挡物的平均深度 + 遮挡像素占的比例 * 遮挡物的平均深度 = 总区域内的平均深度.**

**计算步骤：**

1. 通过生成 shadow map 和 square-depth map 得到期望值的平方和平方值的期望再根据 $D(X) = E(X^2) - [E(X)]^2$ 得到**方差**

2. 通过 mipmap 或者 SAT 得到**期望**，即总区域的平均深度 $Z_{Avg}$

3. 有了期望和方差，就可以根据切比雪夫不等式近似求出 $\displaystyle\frac{N1}{N}$ (非遮挡物的比例)和 $\displaystyle\frac{N2}{N}$  (遮挡物的比例)。

$\displaystyle \frac{N1}{N} = P(x > t)$

$\displaystyle \frac{N2}{N} = 1 - P(x > t)$

4. 此时公式中的 $Z_{unocc}$ 和 $Z_{occ}$ 仍然是不知道的, 这里有一个 Trick：
我们假设非遮挡物的平均深度  $Z_{unocc}$ = shading point 的深度（该假设的合理性：绝大多数阴影的接收者为平面。但也以为如此，在曲面和与光源不平行时会出现问题）

5. 至此我们只剩下 $Z_{occ}$ 的深度, 将所有值代入可求出遮挡物的平均深度 $Z_{occ}$ 

VSSM 的做法实在是十分聪明, 采用了非常多的大胆假设，同时非常的快，没有任何噪声，本质上其实也没有用正态分布，是直接用切比雪夫不等式来进行近似。但是**现在最主流的方法仍然是 PCSS, 因为人们对噪声的容忍度变高加上降噪的技术越来越高明, 因此大多数人采用 PCSS.**

## MIPMAP 和 SAT 

VSSM 中如何加速第一步和第三步的我们知道了, 那么如何在区域范围内快速的求出均值?

有两个方法: MIPMAP 和 SAT.

最简单的方法自然是 MIPMAP, 我们在 GAMES101 里学过, 他是一个**快速的, 近似的, 正方形的范围查询,** 由于他要做插值, 因此即便是方形有时也会不准确. 同时当插值的范围不是 2 的次方时，也就是在两个 MIPMAP 之间时，还要再进行一次插值，也就是 “三线性插值”，这样会让结果更加不准确, 因此局限性太大且准确度也不算高.

SAT 是百分百准确的方式. SAT 的出现是为了解决**范围查询 (在区域内快速得到平均值)**, 并且, **范围内求平均值是等价于范围内求和的, 毕竟总和除以个数 = 平均值**.

在 1 维情况下其实就是一维数组, SAT 这种数据结构就是做了预处理，也就是在得到一维数组时, 先花费 O(n) 的时间从左到右走一遍, 并且在走的同时把对应的累加和存入数组 SAT 中，那么 SAT 上任意的一个元素就等于原来数组从最左边的元素加到这个元素的和, 如图 SAT 数组第 2 个元素表示原数字前 2 个元素之和。

那么查询下图中 SUM 区域总和时候，就是 SAT 数组中第六个元素减去第三个元素。相当于使用了$O(n)$ 的时间，把预计算做了一遍。

![[Pasted image 20230624153444.png]]

那么在 2 维（二维数组）情况下 有一个任意矩形（横平竖直），蓝色矩形内的总和为两个绿色矩形内的总和减去两个橙色矩形内的总和。同样可以采用 SAT 的方法，做一个表，做出从左上角到这个元素的和。因此只需要**查表 4 次**就可以得出精准的区域求和。

在 2 维情况下，可以通过建立 m 行中每行的 SAT 和在每行的 sat 基础上再建立 n 列中每列的 SAT，最终可以获得一个 2 维的 SAT 因此最终的 SAT, 但是由于 gpu 的并行度很高, 行与行或列与列之间的 sat 可并行, 因此具有 $O(m×n)$ 的时间复杂度。

![[Pasted image 20230624153637.png]]
>图中坐标系有误，应该是左上角为原点

其实这个算法就是 leetcode 1314 matrix block sum 的算法.

## **Moment shadow mapping**

VSSM 是为了解决 PCSS 的问题, 但 vssm 由于做了很多假设，当假设不对的时候会有问题。

![[cecf3e01215ce550560213f43777dadc_MD5.jpg]]

比如右图，只有三个片的遮挡的情况下，那么深度的分布就在这三个遮挡度深度周围，形成了三个峰值，自然就会出现假设描述的不准。

![[1aa2457474073a47deeb8b5a4dd3246f_MD5.jpg]]

切比雪夫不等式虽然不需要知道分布，但他大概的分布形状和正态分布类似，当分布的形状和切比雪夫的分布形状差别过大时，如图。
蓝色为实际的分布，涂蓝色的部分为未遮挡的比例，但通过切比雪夫推算的为遮挡的比例
算就会出现漏光和过暗的结果。在阴影的承接面不是平面的情况下也会出现阴影断掉的现象。

![[7e59a0d5979208ff854c7406c42103a9_MD5.jpg]]

我们看图中小车可以发现, 在车的底部阴影部分出现了一部分偏白的阴影, 这是因为车是一个镂空的状态, 如果从底部向 LIGHT 处看去会发现底板遮挡一部分, 车顶附近会遮挡一部分, 这就导致了不是正态分布情况, 因此才出现 light leaking 这种情况.

因此人们为了避免 VSSM 中不是正态分布情况下的问题, 就引入了更高阶的 moments 来得到更加准确的深度分布情况. 想要描述的更准确，就要使用更高阶的 moment(矩)，矩的定义有很多，最简单的矩就是记录一个数的次方，VSSM 就等于用了前两阶的矩。这样多记录几阶矩就能得到更准确的结果。

![[381e4a046d373866c3fa002ba228a086_MD5.jpg]]

如果保留前 M 阶的矩，就能描述一个阶跃函数，阶数等 2/M, 就等于某种展开。越多的阶数就和原本的分布越拟合。一般来说 4 阶就够用。

![[74a6eb00a5d364975967928ccb278c9e_MD5.jpg]]