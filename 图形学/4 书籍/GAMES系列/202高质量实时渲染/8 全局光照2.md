主要内容：**3D空间GI的LPV算法和VXGI算法 屏幕空间的SSAO算法**

本文是闫令琪教授所教授的 Games-202:Real-Time High Quality Rendrting 学习笔记的第八讲 Real-Time Global Illumination (In 3D)，本人属于新手上路暂无驾照，有错误欢迎各位大佬指正.

本节课内容:

![[ad3b60a7dd954af6b799470d338bc8ad_MD5.jpg]]

## **Light Propagation Volumes （LPV）**

LPV: 在 3D 空间中去传播光线, 从而利用它做出间接光照从而实现 GI.

![[cfaed3c5e5b56ea4644cf4799d4e7111_MD5.jpg]]

LPV 历史: 最早是在 Cry Engine 3 中被引入的, 其初衷是用来做 Crysis 系列 (孤岛危机). 如果你是一名系列爱好者应该知道 2007 年用 Cry Engine2 做出来的显卡危机, 其使用了我们下文要讲的 SSAO 技术, 而 Cry Engine3 中的一项主要技术是 LPV.

LPV 有两个不错的优点:

*   Fast
*   Good quality

RSM 有他自己本身的问题, LPV 可以很好的解决一部分 RSM 的问题.

![[912a2d3a7340232a079afb3faed10185_MD5.jpg]]

**主要问题:**

*   如果我们能获得任何一个 Shading point 上来自四周的 radiance 的话, 就可以立刻得到其间接光照.

**核心思路:**

*   我们假设光在传播过程中, radiance 是 uniform 的.(intensity 会平方衰减)

**核心解法:**

*   将场景划分为若干个 3D 网格, 每个网格叫做 Voxel(体素), 在计算完直接光照后, 将接受到直接光照的表面看作间接光照在场景中传播的起点.

![[532dad92206587f6adcb1b3a55f6fe12_MD5.jpg]]

**大概步骤:**

![[cb02193dc583a6fd3605fb81d33d1832_MD5.jpg]]

1.  找出接收直接光照的点
2.  把这些点注入 (inject) 到 3D 网格中作为间接光照 (虚拟光源) 的传播起点.
3.  在 3D 网格中传播 radiance
4.  传播完后, 渲染场景

**具体步骤:**

**1. 生成**

![[6e07d51c6bcee76591c14007a0401b53_MD5.jpg]]

*   与 RSM 一样, 首先通过 Shadow Map 找出接受直接光照的表面或物体
*   对得到的光源数量可以通过采样一些进行简化从而降低次级光源数量, 最后获得一系列虚拟光源

**2. 注入**

![[41c15f5e6f3719fd997aaf781441c248_MD5.jpg]]

*   预先把场景划分为若干个 3D 网格 (体素)
*   把虚拟光源注入到其对应的格子内
*   一个格子内可能包含许多不同朝向的虚拟光源, 把格子内所有虚拟光源的不同朝向的 radiance 算出来并 sum up 从而得到一个往四面八方的 radiance
*   由于是在空间上的分布, 也就可以看作是球面函数, 自然可以用 SH 来表示 (工业界用两阶 SH 就可以表示各个方向上的 radiance 初始值)

![[2355a598c641a2004882e064e8ab9a3c_MD5.jpg]]

**3. 传播**

![[5022bda35d4e647d1773dfa9e0036afc_MD5.jpg]]

*   由于是 3D 网格, 因此可以向六个面进行传播 (上下左右前后), 由于 radiance 是沿直线传播的, 我们认为 radiance 是从网格中心往不同方向进行传播的, 穿过哪个表面就往哪个方向传播, 比如穿过右表面的 radiance, 就传播到右边的格子里 (不考虑斜角, 比如右上方向, 我们认为是先到右边格子, 再到上面格子)
*   每个格子计算收到的 radiance, 并用 SH 表示
*   迭代四五次之后, 场景中各 voxel 的 radiance 趋于稳定

**4. 渲染**

![[57a0814f35827f2c9411034a27194281_MD5.jpg]]

*   对于任意的 shading point，找到他所在的网格
*   获得所在网格中所有方向的 Radicae；
*   渲染。

LPV 也有自己的问题, 那就是和 VSSM 一样的问题: 漏光

由于我们认为 radiance 是从格子正中心向四周发散的, 当遇到这种情况时,

![[a18844ff1857c5c71b209c449bcd6fec_MD5.jpg]]

按理说点 P 反射的 radiance 是无法照亮墙壁的背后, 但是由于我们的假设, 会导致墙壁后面也被间接光照照亮, 也就是所谓的漏光现象.

![[f4479d025c1941de6f8c23ae3518e762_MD5.jpg]]

如图, 你看房屋的下部本不应该被照亮, 但由于使用了 LPV 导致了 light leaking 现象.

我们是可以解决漏光现象的, 那样需要我们划分的格子足够小, 这样会导致存储量增多, 而且传播过程中传播的格子量增多, 也就导致了速度慢.

对于两个格子之间的可见性也进行了假设，假设相邻格子都能看见，同时工业界会用不同大小的格子 也就是 **Cascade 层级加速结构**，来优化 LPV 的方法。

老师放出了两个小视频来向我们证明 LPV 的效果很稳定, 对于动态的物体处理的也非常好.

**Q1: 这是预计算吗?**

*   不是, 这是实时的, 在任意一帧都要去做这个计算.

**Q2: 每个格子存储的是 light transport 吗?**

*   可以这么理解.

## **Voxel Global Illumination （VXGI）**

VXGI 也是一个 2-pass 的算法, 但是与 RSM 有一些区别:

![[86244aa89ec21b21f374a99a74496ed7_MD5.jpg]]

**区别 1: 次级光源从 RSM 中的 Pixel--->VXGI 中的 Voxel(格子)**

RSM 中次级光源是像素中所包含的微小表面，这些表面是根据 Shadow Map 来划分的.

VXGI 把场景完全离散化成了一系列微小的格子，可以理解为场景是由一堆乐高堆起来的, 如图, 这些是最细的层级, 也就是最小的格子我们可以在这一层基础上去建立一层大点的格子, 依此类推从而根据场景的不同划分建立出一个 Hierachical 树形结构的体素。

**区别 2: 光线从传播变为了追踪**

在 LPV 中, 我们将受到直接光照的点注入到场景划分的 Voxel 之后进行传播, 只需要传播一次就可以知道场景中任何一个 shading point 收到间接光照的 radiance.

而在 VXGI 中第二趟我们从 camera 出发, 就像有一个 Camera Ray 打到每一个 pixel 上, 根据 pixel 上代表的物体材质做出不同的操作, 如果是 glossy 则打出一个锥形区域, diffuse 则打出若干个锥形区域, 打出的锥形区域与场景中一些已经存在的 voxel 相交, 这些 voxel 对于 Shading point 的贡献可以算出来, 也就是我们要对每一个 shading point 都做一个 cone tracing, 可想而知, 这个速度比起 LPV 来说是很慢的, 但是是可以优化的, 暂且不提.

![[2e21f65b7af858c1ba6dd3b661e14ffe_MD5.jpg]]

左图将场景划分为一系列的 voxel, 之后再划分成一个 Hierachical 树形结构, 右图就是 Hierachical 的体素.

**具体步骤:**

**Pass1：Light pass**

不管如何我们首先肯定是先要算直接光照找到哪些 voxel 会被照亮, 那么我们要先从接收到直接光照的 patch 开始, 不管是 RSM 还是什么先找出接受直接光照的 Patch.

但是由于场景是由 voxel 来表示的, 那么对于任何一个格子, 跟 LPV 的注入很像, 但是这里不在记录格子里表面的出射分布或者说认为表面是 diffuse 的半球分布, 也就是不再像 LPV 一样将所有的 radiance 加在一起求各方向的初始值, 那么也就是说可以支持反射物 (patch) 也是 Glossy 的.

![[d19bdb5cb1026db75c20d46f8adafc2f_MD5.jpg]]

记录的是直接光源从哪些范围来（绿色部分），记录各个反射表面的法线（橙色部分），通过**输入方向**和**法线范围**两个信息然后通过表面的材质，来准确的算出出射的分布，这样就比 LPV 认为格子表面是 diffuse 再用 SH 来压缩的方法要准确，然后建立更高层级格子的这些特性。

**Pass 2 :Camera pass**

从这一步开始考虑场景的渲染了, 对于任何一个像素，知道了 Camera Ray 的方向，

**I)** 对于 Glossy 的表面，向反射方向追踪出一个锥形 (cone) 区域；

![[decae715e889f95a6298423ba5d07dbe_MD5.jpg]]

基于追踪出的圆锥面的大小，对格子的层级进行查询，就是对于场景中的所有体素都要判断是不是与这个锥形相交，如果相交的话就要把对于这个点的间接光照的贡献算出来 (我们存储了体素的光照输入方向和法线方向, 因此可以算出其输出的 radiance, 将 cone 区域内所有体素的 radiance 都算出来从而在 shading point 得到间接光照)，也就是根据传播出的距离远近找对应层级的体素，然后找覆盖的范围。(论文中说查询相当于是 mipmap 的操作, 但是我个人没有看完, 等回头有时间将 vxgi 的论文好好看一遍)

**II)** 对于 diffuse 的情况来说, 通常考虑成若干圆锥，忽略圆锥 Tracing 时的重叠和空隙。

![[6bbd1b8a02d2ea0ffe3e5c3b98aaf7e6_MD5.jpg]]

总结：

LPV 是把所有的次级光源发出的 Radiance 传播到了场景中的所有位置，只需要做一次从而让场景每个 Voxel 都有自己的 radiance，但是由于 LPV 使用的 3D 网格特性，并且采用了 SH 进行表示和压缩，因此结果并不准确，而且由于使用了 SH 因此只能考虑 diffuse 的, 但是速度是很快的。

VXGI 把场景的次级光源记录为一个层次结构，对于一个 Shading Point，我们要去通过 Corn Tracing 找到哪些次级光源能够照亮这个点。

![[fcc55a86a8a96421a8dbaa1bd8db8707_MD5.jpg]]

![[65aafe9147790b43ad78c0ff1a58d75b_MD5.jpg]]

![[010009f41f89643ecb2a2634b6d774c7_MD5.jpg]]

结果的质量非常好，与光线追踪的结果非常接近，但是开销还是太大，应用受到了限制。对于 VXGI 我们需要预先对场景体素化，也是一个非常大的问题，由于每一个 Shading point 都要做一些 cone Tracing，操作已经非常像离线渲染了。

## **Real-Time Global Illumination (screen space) 屏幕中的实时全局光照**

首先我们介绍一下我们讲了这么多的几种方法都是什么类型的:

*   LPV 和 VXGI 是属于在 3D 空间的 GI
*   RSM 是属于在图像空间的 GI
*   SSAO 和 SSDO 是属于屏幕空间的 GI

那么我们首先需要知道 **什么是屏幕空间**？

1.  使用的所有信息都来自 “屏幕”，也就是做全局光照之前屏幕上能看到的信息，这些信息也就是做全局光照之前的直接光照信息；
2.  也就相当于对这张图做一个后期处理，从而来 “弄” 出全局光照。
3.  为了与此区别我们把 RSM 与 SM 的方法称为图像空间，因为信息是来自从灯光看向的场景 所获得的信息。

接下来我们开始讲屏幕空间如何去做全局光照, 首先来讲 SSAO 再讲 SSDO:

## **Screen Space Ambient Occlusion** 屏幕空间环境光遮蔽

在开始介绍的时候我们说过 CRY ENGINE,SSAO 最早应用的游戏是使用 CRY ENGINE2 做出来的孤岛危机一代, AKA 显卡杀手.

![[a1c9217e8b73cd56287aa092016d3d81_MD5.jpg]]

那么我们为什么要来搞这个环境光遮蔽呢?

**首先我们来知道什么是 AO:**

![[701517ab4656f295fca4d7688c389a26_MD5.jpg]]

左边是进行了 AO 的, 右边是没有进行 AO 的, 之间的差别还是很明显的.

*   通过一系列的 **contact shadow** 让物体与物体之间的相对位置表示的更明显, 从而让**物体相对位置感更强**

![[5991264b2e2780db51e0e5d6dd0a1e22_MD5.jpg]]

*   AO 是非常非常容易去实现的

**SSAO:**

1.  AO 是一个对于全局光照的近似
2.  在屏幕空间意味着从 camera 渲染场景得到信息, 而非是场景中的所有信息

overall, 在屏幕空间对于全局光照的近似就是 **SSAO.**

**三个重要的假设:**

*   由于我们不知道间接光照是什么，因此我们假设任何一个 **shading point** 上来自**任何方向**的**间接光照** (incident lighting) 是一个**常数**.
*   虽然我们考虑了任何一个 **shading point** 上来自**任何方向**的**间接光照**是一样的, 但并不是每个方向都可能接收到间接光照 (incident lighting)，也就是不同位置的 Visibility 是不同的。
*   假设物体是 Diffuse 的, 即使是一个 glossy 物体我们也以 diffuse 去渲染

![[19296c6b933ba70e288b5a96ed3f22b9_MD5.jpg]]

我们可以看到:

左边是任何一个 shading point 上来自任何方向的间接光照 (incident lighting) 是一个常数.

右边是我们考虑了任何一个 shading point 上不同方向的 visibility 后得到的结果.

**在环境光一样的情况下考虑遮挡关系.**

![[903624e814b0a239a0c04f35b13bd551_MD5.jpg]]

图中红色部分表示被遮挡, 黄色部分表示未被遮挡, 我们可以明显的得出一个结论, 左边的 Shading point 要比右边的亮一点.

接下来我们来理解一下它背后的理论为什么说他是一个对 GI 的近似:

![[c3e2528f5431db6b8cf10613e48744a2_MD5.jpg]]

回到我们的老朋友 rendering equation 来, Lighjt(蓝),brdf(黄),visibility(橙).

![[88072cefbc1636b7d5c497f778067bb1_MD5.jpg]]

还记得我们之前说的 RTR 中最常用的近似吗, 把一个 product integral 中的一项拆除去并除以一个空积分进行归一化, 由于这里我们要考虑的是各个方向的 visibility, 因此把 visibility 项拆出去:

![[299d97ace1312e96a846ea8beb6961f9_MD5.jpg]]

蓝色方框中分母再将立体角 $d\omega i$ 拆成 $sin\theta d \theta d \varphi$ 之后对 $\theta$ 和 $\varphi$ 分别积分得到的结果是π，整个积分结果我们称其为 $k_{A}$ ，其实际意义是从一个点往所有方向看去按 cos 加权平均的平均 visibility。

![[698114b5af63caa5342f0c63c62659ae_MD5.jpg]]

橙色方框中积分的结果，由于我们假设了所有方向的间接光照是一个常数，架设了物体是 Diffuse 的, 因此 BRDF 也是常数. 因此最终结果就是漫反射系数 × 间接光照强度 Li, 由于也间接光照强度 Li 你可以随便指定, 漫反射系数也是你可以随便指定的, 因此就是橙色部分的结果是你自己来定义的一个数。

![[74d3082250cc98d5d0b2208bf322487e_MD5.jpg]]

AO 就是: shading point 的加权平均 visibility * 一个你自己定义的颜色

**深入理解:**

1. 我们可以把_f(x)_整个积分中拆出来并归一化这个操作，换成求_f(x)_在_g(x)_的覆盖范围 (Support 内) 的平均值, 由于 brdf 是 diffuse 的, 是一个常数, 间接光照也是一个常数, 因此 g(x)就是一个常数, 所以 AO 做这么一个拆分是完全没问题的.

![[acba5f19c7854f9af3fbbd7458e5cf26_MD5.jpg]]

2. 一个比较难的理解, 在之前的公式中我们可以看到, 老师并不是对 dwi 进行积分, 而是对 cosθ dw 进行积分, 那么我们是怎么把_cosθi×_d_wi_都拆分拿出来的呢？

![[bc5d70ba3b7b3988a7192f9e6875dfbc_MD5.jpg]]

这里我们需要引入投影立体角这个概念:

![[6d47abc4c67a6ed60184ce0348cc9d82_MD5.png]]

立体角是单位球上的一个面积, 关于 cos 中的θ, 我们认为θ从北极开始到南极是 180 度, 那么立体角 * cosθ 得到的是什么呢?

![[0da730e52858ab6bba39692981b7d5e3_MD5.jpg]]

是我们把**单位球上的面积投影到了单位圆上.**

![[21cd85fa0552f2d53a8f32b24d8f1b03_MD5.jpg]]

**SSAO 终极简单理解：**

*   间接光照是常数—Li 为常数
*   BRDF 是 Diffuse 的—BRDF（_fr_）是常数_ρ/π_
*   因此这两项可以直接从积分里面拿出来，最后 Rendering Equation 就成了下面的形式, 也就是算 Visibility 的积分。

![[310728caa01c0112c5ccc1a36d319987_MD5.jpg]]

但是将 Brdf 和 lighting 提出来后积分里剩下的部分由于缺少了分母归一化这个操作, 所以得到的结果并不是加权平均的 visibility, 如果在一开始这么讲的话, 会不理解 kA 的来源.

那么接下来我们只需要去求得 visibility 部分就可以了, 也就是算加权平均的 visibility, 在世界空间下可以通过 ray tarcing 做，但是在屏幕空间下面我们该怎么做？

![[2d045cd126d6852db61e72056c72264d_MD5.jpg]]

我们需要在 shading point 往不同方向 trace 判定究竟有多少方向被挡, 这样说其实是不准确的, 我们以一个极端的例子来看, 在一个封闭的屋子里, 不管你从哪一个 shading point 去 trace 哪个方向, 不论 trace 的光线会不会打到周围的物体, 我们这跟光线不会出去这个封闭的屋子, 也就是最后的结果只能是被遮挡住, 所得到的 Ambient Occlusion 只会是 0.

这是因为, 反射光肯定是在有限的距离里反射过来的, 也就是间接光照是从一定范围内来的, 不可能是从无限远处, 因此如果我们做 tracing 肯定也是在一定范围内的，这样就解决了 tracing 无限远的话一定会被遮挡住这个问题.

但是出现了新问题, 就是超出这个范围的光照就被我们忽略了, 也就是我们忽略了那些在距离外的间接光照，如果我们限制范围太大, 那么所有东西都有可能遮挡住, 如果范围太小, 我们会忽略大部分的 incident lighting. 因此我们限制在一定范围内, 这是一个 trade off, 通常会选一个合适的范围, 也就是找一个合适的球的半径 - R.

![[6f68bdb082dcb24d2e3aa2c6b22f9f6d_MD5.jpg]]

但是在 SSAO 中我们不是这么去计算 visibility 的, 它做了很聪明的假设, 他并没有去往四周 trace 光线, 因为那是一个很麻烦的事:

*   任何一个 Shading Point 在以 sp 为圆心, 半径为 R 的球的内部随机撒一些点, 然后判断这些点能不能被 Shading Point 直接看到；
*   从 camera 出发渲染, 我们肯定是可以得到深度图的, 而且深度图 Z-buffer 我们是可以把他看成是场景的一个简单近似，也就是我们从 camera 看到的下图中的白线, 球内部的点是可以投影到 Camera 然后找之前记录的深度, 如果深度更深, 则表示在物体内部, 被遮挡, 反之则未被遮挡.

![[8d6dfc38fe926b8c81b6cf6c09f0985e_MD5.jpg]]

上图中蓝色区域部分表示的是场景物体, 也就是说蓝色区域外的绿点是可以被 shading point 直接看到的.

但是我们可以看到中间图的一个红点出现了问题，因为我们从 camera 看过去, 这个点比所圈部分的深度深, 因此虽然这个红点是能够被 Shading Point 看到的，但是由于是从 camera 出发，这里被判断为了看不到；

![[4ea1f27b676163714debd915d32b333f_MD5.jpg]]

同时并没有考虑 COS，也就是没有考虑法线, 没有进行加权，因此这个假设并不是物理准确的，但是在实时渲染中看起来问题并不太大。

因为 Rendering Equation 通常只考虑法线所在的那半边，因此做这个判断也只判断法线所在的那半边也是没有问题的，也就是后面那个半球的的采样点没有用处。而由于 SSAO 的时代并不能获得场景的法线信息，因此 SSAO 采用了另一种方法来替代，也就是在整个球采样红点过半的时候才开始考虑 AO 问题。

![[f9cdc39dd78fc5b14dc05ad45e89db17_MD5.jpg]]

以中间的为例, 半边一共五个点, 两红三绿, 因此其 visibility 就是 0.6, 但这是未加权平均的 visibility.

由于是在场景深度上做的，因此在地板上由于临近屏幕空间中凳子的遮挡，也出现了错误的 AO。

![[df14bdd65f7a25f734a2eb1c289deffb_MD5.jpg]]

入图中所圈部分, 我们是知道那一片的地板是不可能被石椅所遮挡的, 但是在开启了 SSAO, 由于我们是从 camera 出发去判断深度的, 所以这一块不可避免的出现了错误的 AO.

**采样中的问题：**

![[12d4bc0da0bcdb3a09955415a352c8fe_MD5.jpg]]

选 Sample 数量与 Pcss 一样, 也就是越多的 Sample 效果越好，但是这也会越慢

但我们可以用少量的 Sample，得到一个 noisy 的结果, 然后再这个 noisy 的结果上进行一个 denoising 来实现降噪，这些降噪的模糊和噪声在和场景中其他效果与光照叠加后就会变得非常不明显，从而获得比较好的综合效果。

![[d376b80ab85e9a8d4f036f904d78ca96_MD5.jpg]]

但是我们上面说的是没有法线的方法，当有了场景 normal 之后，我们就知道去采样哪半球, 就可以只去算半球的情况了，同时也可以对不同的方向来加权（靠近中间大，靠近两边小），也就是 Horizon Based ambient occlusion----HBAO.

![[ad99d1b558f5e3f7db8729e89894e655_MD5.jpg]]

HBAO 的效果明显要比 SSAO 效果要好一点, 有效的减少了错误遮挡的情况（柱子后面尤为明显），但是要多存一个屏幕空间的法线。

![[30fe10c63004f3d831100edfa0139271_MD5.jpg]]

HBAO 好的最重要原因就是因为只考虑了一个半球。