
> [!NOTE] 约定
> - 本文用**列向量/右手坐标**系进行说明以及推导 
> - Camera 的 LookAt（Forward） 方向为自身的 $- z$ 轴方向
> - NDC 空间采用 OpenGL 标准，范围 $[-1,1]$
> - ZBuffer 在近平面处为 0.0，在远平面处为 1.0。(传统平台标准，未使用 Reversed direction 技术)
> - 若需转换到行向量/左手坐标系，需要对变换矩阵做转置

# 深度
深度是指像素到摄像机的距离，观察空间的深度为**线性深度**
![[Pasted image 20230708110316.png]]
假如在 MV 变换后，**观察空间（View Space）** 下的某个点对应的齐次坐标为 $(x,y,z,1)$，那么经过透视投影变换和 GPU 裁剪后转换到**齐次裁剪空间（Clip Space）**，变换过程如下：

![[02 视图变换#^qj7odx]]

我们只关注深度，即 $\displaystyle z'=(\frac{n+f}{n-f})z-\frac{2nf}{n-f}$

然后进行**齐次除法**转换到**NDC 空间**，$$ z''=\frac{z'}{w'}=(\frac{n+f}{n-f})-\frac{2nf}{(n-f)z}\tag{1}$$
$z''$ 值范围为 $[-1,1]$ ，而 ZBuffer 中存储的值应该为 $[0,1]$，所以我们将 NDC 空间的 Z 值范围转换到 $[0,1]$：（$NonLinearDepth$ 与 $\frac{1}{z}$ 相关，是非线性的，即**非线性深度**）
$$NonLinearDepth = z''\times0.5+0.5=\frac{n}{{n-f}}-\frac{nf}{(n-f)z}\tag{2}$$

![[Pasted image 20230708123806.png]]
>范围转换前后对比，横轴为 z 值。可以看出靠近摄像机的十个单位占了 90%的深度缓冲区精度，故离摄像机越远的值精度越低

## 线性深度

当我们想要精确表达物体的深度差异或者重建像素世界坐标位置，就需要使用线性深度。
前面提到，线性深度即观察空间的深度 $z$
由方程（1）（2）可得：
$$ z''=(\frac{n+f}{n-f})-\frac{2nf}{(n-f)z}$$
$$z'' = NonLinearDepth\times2-1$$
联立可以求出 $z$，我们将其标记为 $LinearDepth$

## 深度计算

我们知道物体要显示在屏幕上要进过 MVP 变换到裁剪空间（Clip Space），在裁剪空间做完裁剪后，再做一次透视除法变成标准化设备坐标（NDC），我们来看看这个过程坐标发生了什么变换。

注：由于 OpenGL 和 DirectX 的投影矩阵和 NDC 范围有所不同，所以分开来说。有关 OpenGL 和 DirectX 的投影变换矩阵可参考：

[王江荣：视图变换和投影变换矩阵的原理及推导，以及 OpenGL，DirectX 以及 Unity 的对应矩阵](https://zhuanlan.zhihu.com/p/362713511)

由于我们一开始在 Window 平台，所以先来看看 DirextX 的深度计算方式。

假设某个顶点在 MV 变换后坐标为 $(x_v,y_v,z_v)$ （其中 $z_v$ 的值也被称之为：eye Z value），那么 P 变换后得到的齐次坐标为：

$Clip Space=\begin{bmatrix}x_v&y_v&z_v&1\end{bmatrix}\begin{bmatrix} \frac{2n}{r-l} &0 & 0 & 0 \\ 0 &\frac{2n}{t-b} & 0 &0 \\ 0&0 &\frac{f}{f-n} & 1\\ 0 &0 &\frac{-fn}{f-n} &0 \end{bmatrix}=\begin{bmatrix}\frac{2nx_v}{r-l} &\frac{2ny_v}{t-b}&\frac{fz_v-fn}{f-n}&z_v\end{bmatrix}$

上面得到的齐次坐标即是顶点在**齐次裁剪空间**下的坐标。

注：DirectX 的视图空间是左手坐标系，式子中的 f 代表 far clip plane 的 z 的值，n 代表 near clip plane 的 z 的值， $0<n<z_v<f$ 。

我们将 $z_v=n$ 和 $z_v=f$ 分别代入 z 的值中

$\left\{\begin{matrix} \frac{fn-fn}{f-n}=0 &&z_v=n\\ \frac{ff-fn}{f-n}=f &&z_v=f \end{matrix}\right.$

因此**在裁剪空间中，z 值的取值范围为 (0,f)**。

裁剪空间的坐标要转成 **NDC** 坐标还需要做一次**透视除法**，即齐次坐标 (x,y,z,w) 内所有值都除以 w。那么上面的齐次坐标做完透视除法后的值即为：

$NDC=\begin{bmatrix}\frac{2nx_v}{(r-l)z_v} &\frac{2ny_v}{(t-b)z_v}&\frac{fz_v-fn}{(f-n)z_v}&1\end{bmatrix}$

由于要计算的是深度，我们不用管 x，y 的值，只需要关注 NDC 中 z 的值即可：

$z_{NDC}=\frac{fz_v-fn}{(f-n)z_v}$

将它们分别代入到上面的式子中可得到：

$\left\{\begin{matrix} \frac{fn-fn}{(f-n)n}=0 &&z_v=n\\ \frac{ff-fn}{(f-n)f}=1&&z_v=f \end{matrix}\right.$

因此 DirectX 下 $z_{NDC}$ 的取值范围为 0 到 1，其中 0 代表物体在 near clip plane 上，1 代表在 far clip plane 上。而 DirectX 下的深度值即是 $z_{NDC}$ 的值， $depth=z_{NDC}$ 。

但是不对啊？按照前面深度图的显示，明明是 1 代表物体在 near clip plane 上，0 代表在 far clip plane 上，怎么和计算出来的结果正好**相反，这是因为 Unity 为我们做了一次反转的操作**，即：

$depth=1-z_{NDC}$

官方文档说明如下：

在 DirectX 11, DirectX 12, PS4, Xbox One, Metal 这些平台上反转了深度的方向，使得在 near clip plane 上深度值为 1.0，逐渐减小到 far clip plane 上深度值为 0.0。并且在裁剪空间下 z 的范围也由 (0,far) 变为了 (near,0) 。

为什么要进行反转操作呢？我们来看一个例子，假设 n=0.1，f=10，那么不反转的话， $z_{NDC}$ 和 $z_v$ 的关系如下：

![[c93a44373b646c1b68a2d3723eba3d2d_MD5.png]]

从曲线图中看出深度随着距离的增长是一个**非线性**的增长（有点像 log 函数），当 $0.1<z_v<1$ 时， $z_{NDC}$ 的取值范围大概在 (0, 0.95) 之间，而当 $1<z_v<10$ 时， $z_{NDC}$ 的取值范围大概在 (0.95, 1) 之间。也就是说**当物体越接近 near clip plane 那么深度值的精度就越高，而越接近 far clip plane 精度就越低**。例如当两个物体距离分别是 9 和 9.1 的时候，如果精度不够，就很难通过深度来判断两个物体到底谁在前面，就可能会发生闪烁的现象（一下认为你在前面，一下子认为它在前面），这种由精度产生的问题我们称之为 **z-fight**。

然后我们来看看反转后的曲线，如下：

![[e83c2eb2781312ed5e262d2fd92faba8_MD5.png]]

好像没什么软用，不还是接近 near clip plane 时精度越高么，只不过值从接近 0 变成了接近 1。事情并不是这么简单，这里我们要引入**浮点数精度分布**的知识，即**浮点数本身在越接近于 0 的时候精度越高**，也就是说越接近 0 浮点数的分布越密集。这样你就会发现反转后，虽然当 $1<z_v<10$ 时， $z_{NDC}$ 的取值范围大概在 (0.05, 0) 之间，但是这个区间内分布的浮点数却非常的多，从而保证深度值的精度不会受到特别的大的影响。


因此反转操作有利于在 near 特别小而 far 特别大时，整体保证不错的精度效果，从而减少 z-fight 现象。

其他避免 z-fight 的方法：

*   物体不要放的太近，防止使用深度无法区分两者的远近关系。
*   near clip plane 设置的尽可能远。但这样可能造成离 camera 很近的物体被裁剪掉，需要多测试找到一个适合的距离。
*   使用更高精度的 depth buffer，例如 Unity5.5 的更新里说到将 24 bit 的 depth buffer 更换为了 32 bit，当然这样会增加内存的开销。
*   尽量缩短 n 和 f 之间的距离，例如 n=1，f=8 的曲线示意图如下。

![[385de96ab07851c7efb3586de7efbc02_MD5.jpg]]

因此最终结论就是 **Unity 在 DirectX 平台上（Metal 与之一样），depth 的取值范围是 1 到 0，当在 near clip plane 上时 depth=1，在 far clip plane 上时 depth=0**，其计算公式为：

$depth=\frac{(f-z_v)n}{(f-n)z_v}$

我们可以简单的验证下是否正确，例如之前的测试场景，我们设置 Camera 的 Clipping Planes 的 Near 为 6，Far 为 100，对应公式中的 n 和 f：

![[dd81b78262b920929f03c7f3b38d6850_MD5.jpg]]

然后创建一个 Cube 使其离摄像机的距离为 10.5，因为 Cube 的宽度为 0.5，因此此时 Cube 离 Camera 最近的一个面的距离正好为 10，对应场景和深度图如下：

![[7dddbbae50da7b810b3bb5bafbd01075_MD5.jpg]]

将这些值代入公式得到 depth 为：

$depth=\frac{(100-10)*6}{(100-6)*10}=0.574$

换算成 r 通道的值即为：0.574*255=146，我们采样一下深度图中小方块的颜色，可以发现正好是对应的，如下图：

![[e3a76291e0401f7a880d043610294c22_MD5.jpg]]

同时这个公式也可以解释为什么有些时候深度图是全黑色的，因为默认的 Camera 的 n=0.3，f=1000，如果代入公式会发现小方块的 depth 变为了 0.03，接近黑色。对应示意图如下：

![[8604fb123bad281f316e6f189b85c3be_MD5.jpg]]

接下来我们再来看看 OpenGL 的，同样假设在 MV 变换后坐标为 $(x_v,y_v,z_v)$ ，那么 P 变换后得到的齐次坐标为：

$Clip Space=\begin{bmatrix} \frac{2n}{r-l} &0 & 0 & 0 \\ 0 &\frac{2n}{t-b} & 0 &0 \\ 0 &0 &\frac{-(f+n)}{f-n} & \frac{-2fn}{f-n} \\ 0 &0 &-1 &0 \end{bmatrix}\begin{bmatrix}x_v\\y_v\\z_v\\1\end{bmatrix}=\begin{bmatrix}\frac{2n}{r-l} x_v\\\frac{2n}{t-b}y_v\\\frac{-(f+n)z_v-2fn}{f-n}\\-z_v\end{bmatrix}$

这里需要注意的是 OpenGL 的视图空间是右手坐标系，而式子中的 f 和 n 分别代表 far clip plane 和 near clip plane 离原点的距离， $0<n<f$ 且 $-f<z_v<-n$

我们将 $z_v=-n$ 和 $z_v=-f$ 分别代入 z 的公式中得：

$\left\{\begin{matrix} \frac{-(f+n)*(-n)-2fn}{f-n}=\frac{n*n-fn}{f-n}=-n &&z_v=-n\\ \frac{-(f+n)*(-f)-2fn}{f-n}=\frac{f*f-fn}{f-n}=f &&z_v=-f \end{matrix}\right.$

因此**在裁剪空间中，z 值的取值范围为 (-n,f)**。

然后转换为 NDC 坐标即为：

$NDC=\begin{bmatrix}\frac{-2nx_v}{z_v(r-l)} \\\frac{-2ny_v}{z_v(t-b)}\\\frac{(f+n)z_v+2fn}{(f-n)z_v}\\1\end{bmatrix}$  
$z_{NDC}=\frac{(f+n)z_v+2fn}{(f-n)z_v}$

继续将 $z_v=-n$ 和 $z_v=-f$ 分别代入公式中得：

$\left\{\begin{matrix} \frac{(f+n)*(-n)+2fn}{(f-n)*(-n)}=\frac{-n^2+fn}{-nf+n^2}=-1&&z_v=-n\\ \frac{(f+n)*(-f)+2fn}{(f-n)*(-f)}=\frac{-f^2+fn}{-f^2+nf}=1&&z_v=-f \end{matrix}\right.$

因此 $z_{NDC}\in(-1,1)$ ，由于深度值的范围为 (0,1)，所以我们还需要做一个转换，即： $depth=\frac{z_{NDC}+1}{2}$ ，并且由于 Unity 并没有对 OpenGL 的深度值进行反转（可见之前发的官方文档连接），因此 **Unity 在 OpenGL 下最终的深度值计算公式为**：

$depth=\frac{(f+n)z_v+2fn+(f-n)z_v}{2(f-n)z_v}=\frac{(z_v+n)f}{(f-n)z_v}$

depth 的取值范围是 0 到 1，当在 near clip plane 上时 depth=0，在 far clip plane 上时 depth=1。

同样我们可以用之前的方法切到 Android 平台下验证一下，将 n=6，f=100， $z_v=-10$ （因为 OpenGL 是右手，Unity 是左手，所以在 Unity 中 Cube 相对 Camera 的 z 为 + 10 但是代入 OpenGL 的公式时要取反）代入公式当中得到：

$depth=\frac{(-10+6)*100}{(100-6)*(-10)}=0.426$

对应的 r 通道值即为 0.426*255=108，参考图如下：

![[e44837874b533457bd1f7257c72dbf3a_MD5.jpg]]

![[cef1be47dc30a9ae816c8096e6cf56ce_MD5.jpg]]

总结一下：

在类似 Direct3D 的平台上，例如 Direct3D, Metal 和 consoles，它们的裁剪空间 z 值范围为 (0, f)，深度值范围为 (0,1)。Unity 平台对 DirectX 11, DirectX 12, PS4, Xbox One, Metal 进行的深度反转，使得这些平台下裁剪空间 z 值范围为 (n, 0)，深度值范围为 (1,0)。

在类似 OpenGL 的平台上，例如 OpenGL, OpenGL ES2 和 OpenGL ES3，它们的裁剪空间 z 值范围为 (-n, f)，深度值范围为 (0,1)。

上面所有的范围，第一个数指的都是 near clip plane 所在的值，第二个数为 far clip plane 所在的值。

## 获取 / 采样深度图



当然了，我们也可以在 C# 端利用 **Shader.GetGlobalTexture** 来获取深度图，然后用 **Graphics.Blit** 方法将其复制到 RenderTexture 上（这也是做 Hiz 剔除时重要的一环）。

这里需要注意的是，在 Unity 的生命周期中有很多的事件函数，例如 Start，Update，OnRenderObject 等等，官方文档介绍如下：

[https://docs.unity.cn/2021.1/Documentation/Manual/ExecutionOrder.html](https://docs.unity.cn/2021.1/Documentation/Manual/ExecutionOrder.html)

那么我们应该在哪个事件中获取_CameraDepthTexture 才能保证是当前帧的深度图呢？经过测试，**建议在 OnPostRender 中获得到当前帧的深度图**，如下：

```
void OnPostRender() {
    Graphics.Blit(Shader.GetGlobalTexture("_CameraDepthTexture"), renderTexture);
}
```

![[f0a1eb5076c260137185e5717bb453f5_MD5.jpg]]

注：有时在 OnPreRender 或者 Update 函数中获取_CameraDepthTexture，那么得到的深度图将会是 Scene 窗口下的深度图，具体原因暂时不明~

![[df90e7cc813db252b7e9aacfcd53044d_MD5.jpg]]


当然了，我们做东西肯定要考虑跨平台，前面提到了不同平台生成的深度图是不同的，如 DirctX 近到远是 1 到 0，OpenGL 近到远是 0 到 1，那么怎么统一采样的值呢？根据前面的介绍我们知道 DirctX 等平台之所以是 1 到 0 是因为 unity 为其做了反转，那么我们再把它们转回来不就得了么。而对于这些进行了深度反转的平台，unity 都定义了名为 **UNITY_REVERSED_Z** 的宏，因此如果想要各个平台近到远都是 0 到 1，就可以这么处理：

```
sampler2D _CameraDepthTexture;
float4 frag(v2f input) : Color
{
    float depth = tex2D(_CameraDepthTexture, input.uv);
    #if defined(UNITY_REVERSED_Z)
        depth = 1.0f - depth; //d3d, metal to do it
    #endif
    return float4(depth, 0.0f, 0.0f, 1.0f);
}
```

## 非线性转线性

Depth texture 中每个像素代表的深度值是一个非线性的变化，例如前面 n=0.1，f=10 的深度变化曲线如下图：

![[e83c2eb2781312ed5e262d2fd92faba8_MD5.png]]

这样有一个坏处，比方说我们想用深度图做一个扫描线的效果，如下图：

![[11c2d177fb06d55d0108f851ee2da5f9_MD5.gif]]

我们的扫描线应该随着深度的变化而变化，那么就会有个问题，例如曲线图所示，当我们深度从 1 变化到 0.05 的时候，实际上代表的距离仅仅离相机不到 1，我们的扫描线只能匍匐前进，甚至都看不到。而深度从 0.05 变化到 0 的时候，啪的一下就瞬移的。而我们期望的肯定是**随着深度的变化，扫描线的移动（也就是距离）也匀速的变化，这就是所谓的线性关系**。

为了解决这个问题，Unity 为我们提供了一个 **Linear01Depth** 的方法，可以得到一个线性变化的深度值。

```c
//UnityCG.cginc
// Z buffer to linear 0..1 depth
inline float Linear01Depth( float z ) {
    return 1.0 / (_ZBufferParams.x * z + _ZBufferParams.y);
}
```

里面的_ZBufferParams 的参数定义如下：

```c
//UnityShaderVariables.cginc
// Values used to linearize the Z buffer (http://www.humus.name/temp/Linearize%20depth.txt)
// x = 1-far/near
// y = far/near
// z = x/far
// w = y/far
// or in case of a reversed depth buffer (UNITY_REVERSED_Z is 1)
// x = -1+far/near
// y = 1
// z = x/far
// w = 1/far
float4 _ZBufferParams;
```

z 值的计算公式我们前面已经提到过了，我们代入到 Linear01Depth 方法中来看看为什么它返回的结果是线性的。

对于 DirectX 这类深度反转的，_ZBufferParams.x = -1+far/near，_ZBufferParams.y = 1，得到公式：

$depth=\frac{1}{\frac{(f-z_v)n}{(f-n)z_v}*(-1+\frac{f}{n})+1}=\frac{z_v}{f}$

对于 OpenGL，_ZBufferParams.x = 1-far/near，_ZBufferParams.y = far/near，得到公式：

$depth=\frac{1}{\frac{(z_v+n)f}{(f-n)z_v}*(1-\frac{f}{n})+\frac{f}{n}}=\frac{z_v}{f}$

好家伙，**就是视图空间下的 z 值除以 far clip plane 的值**，对应的函数图即为：

![[8499d5db7af9c5936cd72315b8b74e58_MD5.jpg]]

从中可以看出，使用 Linear01Depth 需要注意的有两点：

*   不管深度是否反转，得到的结果都是从近到远是从 0 到 1。
*   深度和 near clip plane 的值无关，等于 0 时，代表在相机原点，而不是在 near clip plane。

除了 Linear01Depth 方法外还有个 **LinearEyeDepth** 方法，**其实就是通过深度反推出视图空间下 z 的值**（ $z_v$ ），方法体如下：

```
//UnityCG.cginc
// Z buffer to linear depth
inline float LinearEyeDepth( float z ) {
    return 1.0 / (_ZBufferParams.z * z + _ZBufferParams.w);
}
```

简单的套一下 Direct 的公式：

$eyedepth=\frac{1}{\frac{(f-z_v)n}{(f-n)z_v}*\frac{-1+\frac{f}{n}}{f}+\frac{1}{f}}=z_v$

