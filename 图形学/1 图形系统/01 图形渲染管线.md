


---
title: 01 图形渲染管线
aliases: []
tags: []
create_time: 2023-06-19 20:09
uid: 202306192009
banner: "![[]]"
---


> [!NOTE]
> 本文是对 RTR4 第二章图形渲染管线 的总结

# 概述

## Pipleline

> [!NOTE] Pipeline 的翻译
>Pipleline 也叫流水线，图形渲染领域，更多翻译为**“管线”** , 后文也采用管线的译法。

当我们谈到管线时，我们指的是一个**由多个阶段组成的过程，每个阶段都完成任务的一部分**。在现实世界中，流水线的概念在许多不同的领域中都有应用，比如工厂的生产线和快餐厅的厨房等。

管线的各个阶段都是平行的，这意味着**各个阶段依次依赖于上一个阶段的输出**。理想情况下，将一个非管道系统划分为 n 个流水线阶段可以提供 n 倍的加速。这种性能提升是使用流水线的主要原因。

例如，一系列人可以快速准备大量的三明治，其中一个人负责准备面包，另一个人添加肉，另一个人添加浇头。每个人将结果传递给排队的下一个人，立即开始制作下一个三明治。如果每个人完成任务需要 20 秒，那么每 20 秒可以制作三个三明治。

管线的速度取决于管线中最慢阶段的速度，最慢的阶段被称为**瓶颈 (bottleneck)**。此时，其他的阶段会等待瓶颈的工作完成，称其他阶段此时处于 **starved** 状态。因此，优化管线中最慢的阶段可以提高整个管线的性能。

## 图形渲染管线
**图形渲染管线（graphics rendering pipeline）

在计算机图形学中，我们使用渲染管线来实现将 3D 场景转换成 2D 图像的过程。如果给出一台具有确定位置和朝向的摄像机以及某个场景的几何描述，那么渲染管线则是以摄像机为视角进行观察，并据此生成给定 3D 场景 2D 图像的一整套处理步骤。

具体来说，把渲染管线想象为一个工厂里的流水线，里面有不同的**加工环节（渲染阶段）**，可以根据用户需求对每个环节灵活**改造或拆卸（可编程或可配置）**，以此把**原始材料（CPU 端向 GPU 端提交的纹理等资源以及指令等）** 加工为成品出售给**消费者（在 GPU 端，资源流经流水线里的各个阶段, 经指令的调度对其进行处理，最终计算出像素的颜色，将其呈现在用户屏幕上）**。

事实上，渲染管线是种模型，将 3D 场景变换至 2D 场景的处理流程抽象分离为不同的流水线阶段，供用户使用。其本质即指令从 CPU 端的应用程序层发送至 API 运行时、驱动层及至 GPU 端（包括二者间的通信，连接都靠 PCle 接口，实质上就是围绕这种总线传递数据），资源数据在内存与显存间游走，最后是 GPU 内部各种引擎、缓存、命令队列等根据指令配合运作将数据转化为显示器可视信号。

# 功能性阶段划分

在划分渲染管线阶段之前，首先需要区分**渲染管线的功能性阶段**和 **GPU 硬件管线阶段**区分。
- **功能性阶段是概念性的，是我们为了给一个渲染流程进行基本的功能划分而提出来的。**
- **GPU 硬件管线则是硬件层上真正用于实现上述功能的流水线**。
- 一个图形单元 / Core 可能处理多个功能性阶段，一个功能性阶段可能也会拆分成几个硬件单元。

实时渲染管线（real-time rendering pipeline）一般分为如下四个功能性阶段：**应用程序阶段 (Application)**、**几何处理阶段 (Geometry Processing)**、**光栅化阶段 (Rasterization)** 和**像素阶段 (Pixel Processing)**。
- **这些阶段中的每个阶段本身也可以是一条管线**（如本书描述的几何处理阶段），这意味着它会由几个子阶段组成。
- 这些阶段也可以是（部分的）并行化阶段（如本书描述的像素处理阶段）
- 本书中应用程序阶段是单个过程，但是该阶段也可以进行管线化或并行化。
- 需要注意的是，光栅化阶段可以调用到图元（如三角形）内部的像素。

![[Pasted image 20230619202118.png]]
## 应用程序阶段 The Application Stage

应用程序阶段是**完全可控制**的，因为它在 CPU 上执行。并且可以在之后对它进行修改以提高性能表现，另外，此处的修改也会影响后续阶段的性能表现。

**应用程序阶段的主要任务是输入装配**。输入装配阶段会从显存中读取几何数据 (顶点和索引)，再将它装配为**几何图元 (geometry primitive)**。简单来说，应用程序阶段通过索引将顶点装配在一起，构成图元传递给几何处理阶段。 图元拓扑可以分为：点列表，线条带，线列表，三角形带和三角形列表。 这通常在多个处理器核心上执行，被称为**超标量结构 (superscalar construction)**。

应用程序阶段的其他任务包括：粗粒度剔除 (将完全不可见的物体剔除)，碰撞检测、处理其他源输入 (键盘、鼠标等)、加速算法...

**DrawCall** 也是在应用程序阶段产生的。DrawCall 见后面的补充。

另外，应用程序阶段也可以通过计算着色器在 GPU 上运行。

> [!NOTE] compute shader
> 某些应用程序阶段的工作可以由 GPU 执行，使用一种被称为计算着色器（compute shader）的单独模式。此模式会将 GPU 视为高度并行的通用处理器，而忽略它专门用于渲染图形的特殊功能。

## 几何处理阶段 Geometry Processing

**几何处理阶段在 GPU 上运行，它处理应用程序阶段发送的渲染图元，负责大部分的逐三角形和逐顶点操作。**

**主要任务：就是把顶点坐标变换到屏幕空间中，再交给光栅器进行处理**。通过对输入的渲染图元进行多步处理后，这一阶段将会输出屏幕空间的二维顶点坐标、每个顶点对应的深度值、着色等相关信息，并传递给光栅化阶段。

几何处理阶段可以细分为 4 个子阶段：**顶点着色阶段 (Vertex Shading)**，**投影阶段 (Projection)**，**裁剪阶段 (Clipping)** 和**屏幕映射阶段 (Screen Mapping)**。

![[1683366277741.png]]

### **顶点着色阶段**

**顶点着色器两个主要任务：**
1. 计算顶点位置，通过 MVP 矩阵从mo'x 变换到齐次裁剪空间
2. 是传递后续流水线需要的用来插值的数据，如法线和纹理坐标

其中，顶点从模型空间。不同图形 API 的 MVP 变换可能不同，具体体现在透视投影变换中，NDC 空间的不同。 具体的 MVP 变换这里不再赘述。

**可选顶点阶段**

可选顶点阶段包括：细分，几何着色器，流输出。并不是所有 GPU 都支持它们。

**裁剪**

通过透视投影后的顶点处于标准立方体中，如果该顶点处于视锥体中，则需要满足 $-w\leq (x,y,z) \leq w$。任何不满足上述条件的图元都会被裁剪。

![](<images/1683366277863.png>)

如果对顶点进行齐次除法，那么顶点将处于 **NDC 空间**中。如下图所示，图元可以分为三类：完全在 NDC 内，完全在 NDC 外，部分在 NDC 内。 完全在 NDC 内的被保留，完全在 NDC 外的被裁剪，部分在 NDC 内的和 NDC 形成新图元。

![](<images/1683366277920.png>)

不同图形 API 的 NDC 空间的 z 分量不同。在 DirectX 中，NDC 空间的 X 和 Y 分量的范围是 [-1, 1]，而 Z 分量的范围是 [0, 1]。而在 OpenGL 中，NDC 空间的 X、Y 和 Z 分量的范围都是 [-1, 1]。

**屏幕映射阶段**

通过裁剪阶段的处于标准立方体内图元的顶点进入屏幕映射阶段，它将处于 NDC 空间图元的 3D 顶点的 xy 坐标转换到**屏幕坐标系 (Screen Space)** 下。

![](<images/1683366277993.png>)

由于输入的是 NDC 的 3D 坐标，所以我们分别讨论 xy 坐标和 z 坐标。 首先，xy 坐标会从 [-1,1] 拉伸到屏幕坐标系 $[0,width]\times[0,height]$ 下。 然后，z 坐标不会做任何处理，经过透视投影变换的 z 值得以保留，用作深度测试等。实际上，屏幕坐标系和 z 坐标一起构成了 一个坐标系，叫做**窗口坐标系 (Window Space**)。这些值会一起被传递到光栅化阶段 。

接下来，再将顶点浮点坐标转换成屏幕定点坐标 (**定点转换**)：

 $\begin{align} d&=floor(c)\\ c&=d+0.5 \end{align}$

需要注意的是，不同图形 API 的屏幕坐标系也存在差异。 OpenGL 把屏幕的左下角当成最小的窗口坐标值，而 DirectX 则定义了屏幕的左上角为最小的窗口坐标值。

![](<images/1683366278060.png>)

### 光栅化阶段

光栅化阶段也在 GPU 上执行。光栅化阶段的目标是找到处于图元 (三角形) 内部的所有像素，进而将 2D 坐标顶点转为屏幕上的像素，每个像素附带深度和其他着色信息，它们一并传入 pixel。它需要对上一个阶段得到的逐顶点数据 (例如纹理坐标 、顶点颜色等) 进行插值，然后再进行逐像素处理。

光栅化阶段分为两个子阶段：**三角形设置 (Triangle Setup)** 和**三角形遍历 (Triangle Traversal)**。

![](<images/1683366278122.png>)

**三角形设置阶段**

计算三角形网格信息，例如三角形顶点坐标和边界表达式。

**edge 函数**用于确定一个像素中心或其他 sampler 是否在一个三角形内，硬件上会对每个三角形边缘应用一个 edge 函数，它基于直线方程。

![](<images/1683366278256.png>)

GPU 会在三角形设置阶段计算三角形上的常数因子，以便三角形遍历阶段能够有效地进行 (edge 方程的 a, b, c 常量)。并且，还会计算与属性插值相关的常量。 总之，它就是处理前面阶段传递的数据，为三角形遍历阶段做准备。

**三角形遍历阶段**

三角形遍历阶段将会检查每个像素是否被一个三角网格所覆盖。如果被覆盖的话，就会生成一个**片元 (fragment)**。而这样一个找到哪些像素被三角网格覆盖的过程就是三角形遍历，这个阶段也被称为**扫描变换 (Scan Conversion)** 。

在三角形遍历阶段，片元的几何处理阶段传递的值会进行插值。GPU 采用**重心坐标系**来对值进行插值。重心坐标系的性质是，每个值的系数与三角形重心坐标顶点系数相同。因此，GPU 可以通过插值顶点的值来计算任意像素的值，并且这些值在三角形内部会进行插值计算。 重心坐标插值的具体计算这里就不展开了。

![](<images/1683366278379.png>)

### 像素阶段

像素阶段在 GPU 上执行，它主要处理光栅化阶段发送过来的在图元内部的片元序列。GPU 会对每个片元进行像素操作，如颜色和深度的计算、纹理采样、混合等。最终，这些像素被组合成最终的图像。

像素阶段可以分为两个子阶段：**像素着色阶段 (Pixel Shading)** 和**合并阶段 (Merging)**。

![](<images/1683366278462.png>)

**像素着色阶段**

像素着色阶段的任务是使用光栅化阶段传递的插值后的数据以及纹理计算像素颜色。

![](<images/1683366278498.png>)

需要注意的是，纹理可以认为是一种独立于” 插值 “数据的一种资源。由于顶点和像素着色器一般数据都存在更小更快的 **L1 缓存 (L1 Cache)** 中，但纹理存储在更大更慢的 **L2 缓存 (L2 Cache)** 中，因此 **Warp**(线程组，可以简单认为 Shader 程序通过 Warp 单元指令执行)中的指令可以分为两种，不产生延迟的 (寄存器的算数运算) 和产生延迟的(纹理访问)。 为了高效的并行，需要克服内存读取延迟。每个片元的本地寄存器会留出一点存储空间。Warp 首先执行不产生延迟的指令，并将结果存储在 LD/ST 单元中。当遇到产生延迟的指令时，快速切换到其他片元执行其他任务。这个过程会递归进行，直到最后一个片元。然后返回到第一个片元，取出产生延迟指令的结果。 如果 Shader 中使用的寄存器越多，Warp 留给片元的空间就越少。当遇到内存延迟时，可能会出现没有可切换的 Warp 而被迫等待的情况，这种情况称为占用率过高。

**合并阶段**

合并阶段，又称 **ROP 阶段**。它主要完成以下两个任务：

*   决定每个片元的可见性。这涉及了很多测试工作，例如深度测试、模板测试等 。
*   如果一个片元通过了所有的测试，就需要把这个片元的颜色值和已经存储在颜色缓冲区中的颜色进行合并，或者说是混合。

![](<images/1683366278589.png>)

以上所有过程都是高度可配置的，并且测试顺序也不是唯一的。 每种测试具体流程这里就不赘述了。

早期 GPU 的渲染管线中，深度测试是在像素着色器之后才执行的。这种做法会导致很多不可见的像素也会执行像素着色器计算，从而浪费了计算资源。为了避免这种浪费，后来的 GPU 架构采用了 **Early-Z** 技术，将深度测试提前到像素着色器之前 (如下图所示)。这样一来，Early-Z 技术就可以在像素着色器之前剔除很多无效的像素，从而避免它们进入像素着色器，提高了渲染性能。

![](<images/1683366278671.png>)

Early-Z 技术的剔除单位不是像素，而是像素块 (2x2)。在 Early Z 中，渲染器首先进行深度测试，如果像素的深度值小于或等于深度缓冲区中该像素的深度值，则该像素将被保留，并且将执行后续的像素着色器计算。否则，该像素将被丢弃，并且像素着色器将不会被执行。Early Z 的优点是可以减少不必要的像素着色器计算，从而提高渲染效率。 Early-Z 分为 Z Cull 和 Z Check。在 Z Cull 中，渲染器首先执行深度测试，然后对每个三角形进行检查，如果该三角形的所有顶点都被遮挡，则该三角形将被丢弃，不会进入后续的渲染管线。在 Z Check 中，渲染器会对每个像素进行检查，如果像素的深度值小于或等于深度缓冲区中该像素的深度值，则该像素将被认为是可见的，并且将被保留。否则，该像素将被丢弃，并且不会被渲染到屏幕上。

当图元经过上述的计算、测试和混合后，就会显示到屏幕上。我们的屏幕显示的就是颜色缓冲区中的颜色值。 但是， 为了避免我们看到那些正在进行光栅化的图元，GPU 会使用**双重缓冲 (Double Buffering)** 的策略。这意味着， 对场景的渲染是在器后发生的， 即在**后置缓冲 (Back Buffer)** 中。 一旦场景已经被渲染到了后置缓冲中， GPU 就会交换后置缓冲区和**前置缓冲 (Front Buffer)** 中的内容， 而前置缓冲区是之前显示在屏幕上的图像。 由此， 保证了我们看到的图像总是连续的。

# GPU 管线

程序员编写的 shader 是在 SM(流多处理器) 上执行的。每个 SM 包含多个 Core(核心)，用于为线程执行数学运算，例如，一个线程可以是顶点或像素着色器调用。这些 Core 和其他单元由 Warp Scheduler(Warp 编排器) 驱动，Warp Scheduler 管理一组 32 个线程作为 Warp(线程束)，并将要执行的指令移交给 Dispatch Units(指令调度单元)。

GPU 中实际拥有的这些单元数量 (每个 GPC(图形处理簇) 有多少个 SM，每个 SM 包含多少个 Core 等等)取决于芯片的配置本身。

Fermi 架构的渲染流程总览如下：

![](<images/1683366278749.png>)

我们不从 GPU 硬件层入手，而是更高层次的逻辑管线，即更面向程序员的于可编程 / 可配置阶段。

前面的没多大软用，说人话就是我们下面讨论可编程渲染管线。

![](<images/1683366278828.png>)

### GPU 逻辑管线

当 GPU 从 CPU 那里得到渲染命令后，就会进行一系列流水线操作，最终把图元渲染到屏幕上。

将功能性阶段按 GPU 硬件的工作进一步划分，可以得到如下阶段。

![](<images/1683366278896.png>)

GPU 管线接收顶点数据作为输入，这些顶点数据都是应用程序阶段加载到缓存中，再由 Draw Call 指定的。这些数据随后被传入顶点着色器。

### 顶点着色器

**顶点着色器 (Vertex Shader)** 是 GPU 管线的第一个阶段，但在这之前会发生一些数据操作，可以称为**输入装配 (input assembler)**。各种数据流 (stream of data) 可以交织在一起形成沿着管道发送的顶点和基元的集合。 三角形网格由一组顶点表示，顶点数据一定包括模型空间的位置，还可能包括顶点色、法线和切线等。它通过顶点语义得到 CPU 端传递的数据。

顶点着色器的处理单位是顶点，也就是说，输入进来的每个顶点都会调用一次顶点着色器。顶点着色器本身不可以创建或者销毁任何顶点，而且无法得到顶点与顶点之间的关系。例如，我们无法得知两个顶 点是否属于同一个三角网格。但正是因为这样的相互独立性， GPU 可以利用本身的特性并行化处 理每一个顶点 ，这意味着这一阶段的处理速度会很快。

我们可以认为在硬件中执行的是下列处理过程：

```
for(UINT i = 0; i < numVertices; ++i)
    outputVertex[i] = VertexShader(inputVertex[i]);
```

其中顶点着色器函数 (VertexShader) 就是我们要实现的那一部分。因为这一阶段是在 GPU 上执行的，所以速度会很快。

顶点着色器完成的主要工作有：顶点变换和逐顶点光照。 顶点着色器必须完成的一个操作是，将顶点从模型空间变换到齐次裁剪空间。

顶点着色器可以完成以下操作：物体生成 (顶点变换)，角色动画，程序化变形 (旗帜、衣物等)，粒子生成，镜头失真，应用地形高度等。

### [曲面细分阶段]

**曲面细分阶段 (tessellation stages)** 是利用镶嵌化处理技术对网格中三角形进行**细分 (subdivide)**，以此来增加物体表面上的三角形数量。再将这些新的三角形偏移到适当的位置，使网格表现出更加细腻的细节。

曲面细分阶段是可选阶段，使用它能带来如下的好处：

*   实现**细节层次 (level-of-detail, LOD)** 机制。
*   在内存中仅维护**低模 (low-poly)** 网格，再根据需求为它动态地增添额外的三角形，以此节省内存资源。
*   处理动画和物理模拟时采用简单的低模网格，而仅在渲染过程中使用经镶嵌化处理地高模 (high-poly) 网格。

在 DirectX 中，曲面细分着色器有三个阶段，它们分别是**外壳着色器 (hull shader)**，**镶嵌器阶段 (tesslation stage)** 和**域着色器 (domain shader)**。这里简单进行说明。

![](<images/1683366278951.png>)

曲面细分阶段的输入是**面片图元 (patch primitive)**。 外壳着色器是可编程的，它有两个任务。第一个任务是告诉 tessellator 生成三角形的个数及配置，第二个任务是对每个控制点进行处理（控制点类似于 ps 中钢笔工具中控制曲线程度的那个点）。它可以添加或删除控制点。它输出控制点集以及细分因子。 镶嵌器阶段是固定的，它根据外壳着色器的输出，对 patch 进行处理。它通过定义细分因子，将 patch 生成更多的细分控制点和细分后的 patch。细分因子分为内部细分因子和外部细分因子。它向域着色器输出一个 patch 和一组控制点位置。另外，如果外壳着色器阶段送入的曲面细分因子不合法，则会抛弃这个 patch。 域着色器是可编程的。它接收外壳着色器输出的细分因子和控制点，以及镶嵌器阶段输出的顶点 UV(并不是纹理采样 uv，而是镶嵌化处理后的面片域空间 (patch domain space) 顶点位置参数)。它的任务是逐 patch 调用，计算出实际顶点坐标，并变换到齐次裁剪空间中。形成的图元被送入管线下一个阶段。

### [几何着色器]

几何着色器也是可选阶段。 几何着色器可以将基本体转换为其他基本体，而镶嵌阶段无法做到这一点。几何着色器在输入的几何图元 (如点、线段、三角形) 级别上进行操作，并根据需要生成零个、一个或多个输出的新的几何图元。这使得在几何着色器阶段可以实现诸如几何图元的细分、几何的放大缩小、草地生成、粒子系统等各种复杂的效果。几何着色器阶段的输出几何图元会传递给光栅化阶段，经过光栅化处理后，最终会生成像素片段，供像素着色器阶段进行处理。

几何着色器保证按照输入的相同顺序输出图元的结果，这影响性能，因为结果必须保存和排序。同时，它又是完全可编程的。所以通常很少使用，因为它不能很好体现 GPU 优势。在移动设备上，甚至会被阻止。

### 像素着色器

在执行像素着色器之前，GPU 会做如下工作：顶点着色器、细分和几何着色器操作后，几何体会经过裁剪并设置为光栅化。光栅化器会计算覆盖每个像素的三角形的粗略大小，并将其划分为单元格区域，将三角形的一部分或全部称为**片元 (fragment)**。这些过程是不可编程但可配置的。 光栅化阶段实际上并不直接影响屏幕上每个像素的颜色值，而是生成一系列描述三角形覆盖信息的数据。而每个片元负责存储这些数据。

像素着色器的主要输入是经过插值后的顶点信息，包括 z-buffer。根据这些值，像素着色器计算并输出一个或多个颜色值，并有可能修改深度值。通常情况下，无法修改模板缓冲区的值。在像素着色器中，可以使用 clip 指令来丢弃条件小于 0 的像素。

![](<images/1683366279011.png>)

在最初的像素着色器中，**渲染目标 (Render Target)** 目标总是相机的颜色缓冲区，也就是只能输出到合并阶段，以便最终显示像素。随着像素着色器可执行指令数量的增长，引入了多渲染目标 (MRT) 的概念，使像素着色器能够将结果渲染到多个目标，例如渲染纹理等。渲染目标的数量取决于 GPU 的能力。

虽然片元着色器可以完成很多重要效果，但它的局限在于，它仅可以影响单个片元。也就是说，当执行片元着色器时，它不可以将自己的任何结果直接发送给它的邻居们。有一个情况例外，就是片元着色器可以访问到导数信息 (gradient，或者说是 derivative)。 GPU 能够处理导数信息的原因是因为 GPU 需要通过对纹理进行 mipmap 预处理减少带宽，而 mipmap 的等级涉及导数运算。于是 GPU 将 32 个像素线程将会被分成一组，或者说 8 个 2x2 的像素块，这是在**像素着色器上的最小工作单元**，以此来计算 ddx/ddy。

![](<images/1683366279070.png>)

### 合并阶段

通过像素着色器生成的像素片段会被移送至渲染管线的**输出合并 (Output Merger, OM) 阶段**。在此阶段中，一些像素片段可能会被丢弃 (例如，那些未通过深度缓冲区测试或模板缓冲区测试的像素片段)。而后，剩下的像素片段将会被写入后台缓冲区中。**混合 (blend) 操作**也是在此阶段实现的，此技术可令当前处理的像素与后台缓冲区中的对应像素相融合，而不仅是对后者进行完全的覆写。一些如 “透明” 这样的特殊效果，也是由混合技术来实现的。

![](<images/1683366279126.png>)

## 补充

### CPU 与 GPU 的调度

首先我们需要明确的是 GPU 是一个计算设备，一个独立的设备，它不是一个 CPU 线程，所以我们并不能像丢一个 DrawCube() 函数让 GPU 执行。 我们能做的就是把各种数据经过 API 一股脑塞给它：shader，buffer 等。即使是命令，也是要存在**命令缓冲区 (CommandBuffer)** 的**命令队列 (CommandList)** 里。而命令队列本质也只是一个数据容器，本身不会携带任何逻辑或回调。 命令缓冲区使得 CPU 和 GPU 可以相互独立工作。当 CPU 需要渲染一些对象时，它可以向命令缓冲区中添加命令，而当 GPU 完成了上一次的渲染任务后，它就可以从命令队列中再取出一个命令并执行它。 命令缓冲区的命令有很多种，而 **Draw Call** 就是其中一种。其他命令还有改变渲染状态等。

![](<images/1683366279173.png>)

说人话就是，CPU 就像一个什么都会一点的老板，而 GPU 是专精计算的员工。GPU 本身是怠惰的，只有当 CPU 向它发送命令时，才会开始工作。CPU 会命令 GPU：“把目标给我渲染到相机上”，“把相机给我清空”，“给我画一个三角形”。而这个 “给我画一个三角形 " 就是一次 Drawcall。

### DrawCall

DrawCall 是指在应用程序阶段生成的渲染命令，用于绘制一个或多个图元 (如三角形) 的请求。每个 DrawCall 包含了一组渲染状态 (如渲染目标、着色器程序、纹理等) 和要渲染的几何数据。 DrawCall 在**应用程序阶段**生成。在应用程序阶段，应用程序通过调用图形 API 发送渲染命令给图形硬件。这些渲染命令包括绘制调用，即 DrawCall。

具体来说，DrawCall 在渲染管线的不同阶段起着不同的作用：

*   应用程序阶段：应用程序将准备好的几何数据 (如顶点坐标、纹理坐标等) 和渲染状态 (如光照、材质属性等) 通过 DrawCall 发送给图形硬件。应用程序阶段的 DrawCall 将几何数据传递到下一个阶段，即几何处理阶段。
*   几何处理阶段：在几何处理阶段，图形硬件对传入的几何数据进行处理，执行顶点着色器、图元装配和裁剪等操作。每个 DrawCall 会经过几何处理阶段的处理，生成裁剪后的几何图元。
*   光栅化阶段：在光栅化阶段，裁剪后的几何图元被转换为屏幕上的像素。这个阶段包括三角形光栅化、像素插值和面剔除等操作。每个 DrawCall 生成的几何图元会经过光栅化阶段的处理，生成覆盖屏幕上像素的片段。
*   像素阶段：像素阶段是渲染管线的最后一个阶段。在像素阶段，对每个片段进行像素着色器的计算，确定最终像素的颜色、深度和其他属性。每个 DrawCall 生成的片段会经过像素阶段的处理，最终输出到帧缓冲中。

DrawCall 与性能息息相关。例如一个场景中有两个小人，如果在应用程序阶段分别导入，那么就会产生两次 DrawCall。如果将它们**合并 (Batch)**，则只会产生一次 Drawcall。 DrawCall 批次太多会导致 CPU 性能开销过大，一般来说有两种解决方法： - 合批，把模型合成一个大 mesh。 - GPU Instance，用于绘制重复的模型。只需要提交一次模型数据，通过在 GPU 中对 buffer 进行偏移获取本次绘制的计算数据。

## 参考

《Real-Time Rendering 4th》

《DirectX 12 3D 游戏开发实战》

[LearnOpenGL-CN](https://learnopengl-cn.readthedocs.io/zh/latest/)

《Unity Shader 入门精要》

[0 向往 0：深入理解硬件架构及运行机制](https://www.cnblogs.com/timlly/p/11471507.html)